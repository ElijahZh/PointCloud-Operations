{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"Welcome to Point Cloud operations","text":"<p>Welcome to the docs.</p> <ul> <li>This document describes Python-based methods for point cloud processing. Before you begin, make sure the following packages are installed:</li> </ul> <pre><code>pip install numpy torch scipy scikit-learn open3d trimesh pymeshlab matplotlib addict\n</code></pre> <ul> <li>There are different types of methods: Sampling, Coordinate, Normal, Color, Noise et. al.</li> <li>Images showing effects of the methods are generated from the open3d gui, please check the link for how to generating them:  link</li> </ul>"},{"location":"about/","title":"About","text":"<p>The project is majorly based on the Pointcept functions with some extra methods and visualization. If you are interesting, please go check the repo:</p>"},{"location":"color/","title":"Color","text":"<p>Classes for point colors</p>"},{"location":"color/#normalizecolor","title":"NormalizeColor","text":"<p>Normalize point-wise color features into a target value range <code>[low, high]</code>.</p> <p>This transform expects a dictionary containing:</p> <ul> <li><code>\"color\"</code>: NumPy array of shape (N, 3) with point color values.</li> </ul> <p>If <code>range255</code> is True, input colors are assumed to be in <code>[0, 255]</code> and are first scaled to <code>[0, 1]</code> by dividing by 255. Otherwise, they are assumed to already be in <code>[0, 1]</code>.</p> <p>The normalized <code>[0, 1]</code> values are then mapped linearly to <code>[low, high]</code> such that:</p> <ul> <li>0 \u2192 low</li> <li>1 \u2192 high</li> </ul> <p>Parameters:</p> Name Type Description Default <code>low</code> <code>float</code> <p>Lower bound of the target color range. Defaults to -1.0.</p> <code>-1.0</code> <code>high</code> <code>float</code> <p>Upper bound of the target color range. Must be greater than <code>low</code>. Defaults to 1.0.</p> <code>1.0</code> <code>range255</code> <code>bool</code> <p>Whether the input color values are in <code>[0, 255]</code>. If True, values are divided by 255.0 before mapping. If False, values are used as-is (assumed to be in <code>[0, 1]</code>). Defaults to False.</p> <code>False</code>"},{"location":"color/#augmentation_class.NormalizeColor.__call__","title":"<code>__call__(data_dict)</code>","text":"<p>Normalize the <code>\"color\"</code> entry in <code>data_dict</code> into <code>[low, high]</code>.</p> <p>Parameters:</p> Name Type Description Default <code>data_dict</code> <code>dict</code> <p>Input dictionary that must contain a <code>\"color\"</code> key with a NumPy array of shape (N, 3) representing point color values.</p> required <p>Returns:</p> Name Type Description <code>dict</code> <code>dict</code> <p>The same dictionary with <code>\"color\"</code> normalized into <code>[low, high]</code>, if present.</p>"},{"location":"color/#chromaticautocontrast","title":"ChromaticAutoContrast","text":"<p>Apply chromatic auto-contrast to point colors with optional blending.</p> <p>This transform expects a dictionary containing:</p> <ul> <li><code>\"color\"</code>: NumPy array of shape (N, 3) with point color values.</li> </ul> <p>The transform computes per-channel minimum and maximum over the whole point set, linearly stretches each channel to the target range, and then blends this auto-contrasted result with the original colors using a <code>blend_factor</code>.</p> <p>Parameters:</p> Name Type Description Default <code>blend_factor</code> <code>float | None</code> <p>Weight used to blend the original colors with the auto-contrasted colors:</p> <pre><code>out = (1 - blend_factor) * original + blend_factor * contrasted\n</code></pre> <p>If a float in [0, 1], the same value is used for every call. If <code>None</code>, a new random value in [0, 1] is sampled on each call. Defaults to <code>None</code>.</p> <code>None</code> <code>range255</code> <code>bool</code> <p>Whether the input color values are in <code>[0, 255]</code>. If True, the auto-contrast maps into <code>[0, 255]</code>. If False, it maps into <code>[0, 1]</code>. Defaults to False.</p> <code>False</code> <code>apply_p</code> <code>float</code> <p>Probability of applying the auto-contrast. Defaults to 1.0.</p> <code>1.0</code> <p>Chromatic AutoContrast PC Colors</p> <p> </p>"},{"location":"color/#augmentation_class.ChromaticAutoContrast.__call__","title":"<code>__call__(data_dict)</code>","text":"<p>Apply chromatic auto-contrast to the first 3 color channels.</p> <p>Parameters:</p> Name Type Description Default <code>data_dict</code> <code>dict</code> <p>Input dictionary that must contain a <code>\"color\"</code> key with a NumPy array of shape (N, 3) representing point color values.</p> required <p>Returns:</p> Name Type Description <code>dict</code> <code>dict</code> <p>The same dictionary with <code>\"color\"</code> updated in-place, if applied.</p>"},{"location":"color/#chromaticautocontrastpercent","title":"ChromaticAutoContrastPercent","text":"<p>Apply percentile-based chromatic auto-contrast with optional blending.</p> <p>This transform expects a dictionary containing:</p> <ul> <li><code>\"color\"</code>: NumPy array of shape (N, 3) with point color values.</li> </ul> <p>This is similar to <code>ChromaticAutoContrast</code>, but instead of using the absolute min/max per channel, it uses the 1st and 99th percentiles as low/high boundaries. This makes the transform effective even when:</p> <ul> <li>The input already spans the full range (e.g., <code>lo=0.0</code>, <code>hi=1.0</code>), or</li> <li>There are outliers that would otherwise dominate the min/max.</li> </ul> <p>Parameters:</p> Name Type Description Default <code>blend_factor</code> <code>float | None</code> <p>Blending weight between the original and auto-contrasted colors. If a float in [0, 1], the same value is used for every call. If <code>None</code>, a new random value in [0, 1) is sampled on each call. Defaults to <code>None</code>.</p> <code>None</code> <code>range255</code> <code>bool</code> <p>Whether the input color values are in <code>[0, 255]</code>. If True, the auto-contrast maps into <code>[0, 255]</code>. If False, it maps into <code>[0, 1]</code>. Defaults to False.</p> <code>False</code> <code>apply_p</code> <code>float</code> <p>Probability of applying the auto-contrast. Defaults to 1.0.</p> <code>1.0</code> <p>Chromatic AutoContrast Percentage PC Colors</p> <p> </p>"},{"location":"color/#augmentation_class.ChromaticAutoContrastPercent.__call__","title":"<code>__call__(data_dict)</code>","text":"<p>Apply percentile-based chromatic auto-contrast to the point color. Args:     data_dict (dict): Input dictionary that must contain a <code>\"color\"</code> key with a NumPy array of shape (N, 3)         representing point color values.</p> <p>Returns:</p> Name Type Description <code>dict</code> <code>dict</code> <p>The same dictionary with <code>\"color\"</code> updated in-place, if applied.</p>"},{"location":"color/#chromatictranslation","title":"ChromaticTranslation","text":"<p>Apply random global color translation to the point color.</p> <p>This transform expects a dictionary containing:</p> <ul> <li><code>\"color\"</code>: NumPy array of shape (N, 3) with point color values.</li> </ul> <p>For each call (with some probability), it samples a random translation vector <code>tr</code> in a bounded range and adds it to all color values:</p> <pre><code>tr \u2208 [-target_range * ratio, target_range * ratio]^3\n</code></pre> <p>where <code>target_range</code> is 255.0 if <code>range255=True</code>, else 1.0. The result is then clipped back to <code>[0, target_range]</code> and cast to the original dtype.</p> <p>Parameters:</p> Name Type Description Default <code>ratio</code> <code>float</code> <p>Maximum relative translation magnitude as a fraction of the full range. For <code>range255=True</code>, each channel offset lies in:</p> <pre><code>[-255 * ratio, 255 * ratio]\n</code></pre> <p>For <code>range255=False</code>, each channel offset lies in:</p> <pre><code>[-1.0 * ratio, 1.0 * ratio]\n</code></pre> <p>Defaults to 0.05.</p> <code>0.05</code> <code>range255</code> <code>bool</code> <p>Whether the input color values are in <code>[0, 255]</code>. If True, translations and clipping are done in that range. If False, they are done in <code>[0, 1]</code>. Defaults to False.</p> <code>False</code> <code>apply_p</code> <code>float</code> <p>Probability of applying the chromatic translation. Defaults to 1.0.</p> <code>1.0</code> <p>Chromatic Translate PC Colors</p> <p> </p>"},{"location":"color/#augmentation_class.ChromaticTranslation.__call__","title":"<code>__call__(data_dict)</code>","text":"<p>Apply a random color translation to the first 3 channels.</p> <p>Parameters:</p> Name Type Description Default <code>data_dict</code> <code>dict</code> <p>Input dictionary that must contain a <code>\"color\"</code> key with a NumPy array of shape (N, 3) representing point color values.</p> required <p>Returns:</p> Name Type Description <code>dict</code> <code>dict</code> <p>The same dictionary with <code>\"color\"</code> updated in-place, if applied.</p>"},{"location":"color/#chromaticjitter","title":"ChromaticJitter","text":"<p>Add Gaussian noise (jitter) to point colors.</p> <p>This transform expects a dictionary containing:</p> <ul> <li><code>\"color\"</code>: NumPy array of shape (N, 3) with point color values.</li> </ul> <p>It samples per-point, per-channel Gaussian noise and adds it to the channels:</p> <pre><code>noise ~ N(0, (std * target_range)^2)\n</code></pre> <p>where <code>target_range</code> is 255.0 if <code>range255=True</code>, else 1.0. The result is then clipped back to <code>[0, target_range]</code> and cast to the original dtype.</p> <p>Parameters:</p> Name Type Description Default <code>std</code> <code>float</code> <p>Standard deviation of the jitter, expressed as a fraction of the target range. The actual noise standard deviation per channel is:</p> <pre><code>sigma_noise = std * target_range\n</code></pre> <p>For example, with <code>std=0.005</code> and <code>range255=True</code>, the noise standard deviation is <code>0.005 * 255 \u2248 1.275</code>. Defaults to 0.005.</p> <code>0.005</code> <code>range255</code> <code>bool</code> <p>Whether the input color values are in <code>[0, 255]</code>. If True, noise and clipping are done in that range. If False, they are done in <code>[0, 1]</code>. Defaults to False.</p> <code>False</code> <code>apply_p</code> <code>float</code> <p>Probability of applying the chromatic jitter. Defaults to 1.0.</p> <code>1.0</code> <p>Chromatic Jitter PC Colors</p> <p> </p>"},{"location":"color/#augmentation_class.ChromaticJitter.__call__","title":"<code>__call__(data_dict)</code>","text":"<p>Apply Gaussian color jitter to the first 3 channels.</p> <p>Parameters:</p> Name Type Description Default <code>data_dict</code> <code>dict</code> <p>Input dictionary that must contain a <code>\"color\"</code> key with a NumPy array of shape (N, 3) representing point color values.</p> required <p>Returns:</p> Name Type Description <code>dict</code> <code>dict</code> <p>The same dictionary with <code>\"color\"</code> jittered in-place, if applied.</p>"},{"location":"color/#randomcolorgrayscale","title":"RandomColorGrayScale","text":"<p>Randomly convert point colors to grayscale.</p> <p>This transform expects a dictionary containing:</p> <ul> <li><code>\"color\"</code>: NumPy array of shape (N, 3) with point color values.</li> </ul> <p>It converts the <code>\"color\"</code> from RGB to grayscale using an NTSC-style luminance formula, and returns a 3-channel grayscale image (gray copied into R, G, B).</p> <p>Parameters:</p> Name Type Description Default <code>apply_p</code> <code>float</code> <p>Probability of converting colors to grayscale. Defaults to 1.0.</p> <code>1.0</code> <p>Transfer PC Colors into GrayScale</p> <p> </p>"},{"location":"color/#augmentation_class.RandomColorGrayScale.__call__","title":"<code>__call__(data_dict)</code>","text":"<p>Randomly convert <code>\"color\"</code> to grayscale in-place.</p> <p>Parameters:</p> Name Type Description Default <code>data_dict</code> <code>dict</code> <p>Input dictionary that must contain a <code>\"color\"</code> key with a NumPy array of shape (N, 3) representing point color values.</p> required <p>Returns:</p> Name Type Description <code>dict</code> <code>dict</code> <p>The same dictionary with <code>\"color\"</code> converted to 3-channel grayscale, if applied.</p>"},{"location":"color/#randomcolorjitter","title":"RandomColorJitter","text":"<p>Random color jitter for 3D point cloud colors (similar to torchvision).</p> <p>This transform expects a dictionary containing:</p> <ul> <li><code>\"color\"</code>: NumPy array of shape (N, 3) with point color values.</li> </ul> <p>At each call (with probability <code>apply_p</code>), it:</p> <ol> <li>Converts <code>\"color\"</code> to float in the range [0, 1].</li> <li>If <code>range255=True</code>, it divides by 255.</li> <li>Otherwise it assumes values are already in [0, 1] (or compatible).</li> <li>Randomly samples brightness, contrast, saturation, and hue factors within the ranges specified at initialization.</li> <li>Applies a random ordering of these adjustments (brightness, contrast, saturation, hue) to the colors.</li> <li>Clips the result to [0, 1].</li> <li>Converts back to the original dtype (and multiplies by 255 if <code>range255=True</code>).</li> </ol> <p>The argument conventions follow torchvision's <code>ColorJitter</code>:</p> <p>Parameters:</p> Name Type Description Default <code>brightness</code> <code>float | tuple[float, float]</code> <p>How much to jitter brightness.</p> <pre><code>* If a single non-negative float ``b`` is given, the brightness\n  factor is chosen uniformly from ``[max(0, 1 - b), 1 + b]``.\n* If a tuple ``(b_min, b_max)`` is given, the brightness factor is\n  chosen uniformly from ``[b_min, b_max]``.\n* If set to 0 or (1.0, 1.0), no brightness change is applied.\n</code></pre> <p>Defaults to 0.</p> <code>0</code> <code>contrast</code> <code>float | tuple[float, float]</code> <p>How much to jitter contrast. Same semantics as <code>brightness</code> (centered at 1.0). If set to 0 or (1.0, 1.0), no contrast change is applied. Defaults to 0.</p> <code>0</code> <code>saturation</code> <code>float | tuple[float, float]</code> <p>How much to jitter saturation. Same semantics as <code>brightness</code> (centered at 1.0). If set to 0 or (1.0, 1.0), no saturation change is applied. Defaults to 0.</p> <code>0</code> <code>hue</code> <code>float | tuple[float, float]</code> <p>How much to jitter hue.</p> <ul> <li>If a single float <code>h</code> is given, the hue factor is chosen   uniformly from <code>[-h, h]</code>.</li> <li>If a tuple <code>(h_min, h_max)</code> is given, it is chosen uniformly   from <code>[h_min, h_max]</code>.</li> </ul> <p>Values must be in <code>[-0.5, 0.5]</code>. If set to 0 or (0.0, 0.0), no hue change is applied. Defaults to 0.</p> <code>0</code> <code>range255</code> <code>bool</code> <p>Whether the input color values are in <code>[0, 255]</code>. If True, values are converted to float in [0, 1] before jittering and converted back to [0, 255] afterwards. If False, values are treated as floats in [0, 1]. Defaults to False.</p> <code>False</code> <code>apply_p</code> <code>float</code> <p>Probability of applying the color jitter. Defaults to 1.0.</p> <code>1.0</code> <p>Random Jitter PC Colors</p> <p> </p>"},{"location":"color/#augmentation_class.RandomColorJitter.__call__","title":"<code>__call__(data_dict)</code>","text":"<p>Apply random color jitter to the <code>\"color\"</code> entry in <code>data_dict</code>.</p> <p>Parameters:</p> Name Type Description Default <code>data_dict</code> <code>dict</code> <p>Input dictionary that must contain a <code>\"color\"</code> key with a NumPy array of shape (N, 3) representing point color values.</p> required <p>Returns:</p> Name Type Description <code>dict</code> <code>dict</code> <p>The same dictionary with <code>\"color\"</code> updated in-place, if applied.</p>"},{"location":"color/#huesaturationtranslation","title":"HueSaturationTranslation","text":"<p>Randomly shift hue and scale saturation of point colors.</p> <p>This transform expects a dictionary containing:</p> <ul> <li><code>\"color\"</code>: NumPy array of shape (N, 3) with point color values.</li> </ul> <p>For each call (with probability <code>apply_p</code>), it:</p> <ol> <li>Converts <code>\"color\"</code> to float in the range [0, 1].</li> <li>If <code>range255=True</code>, it divides by 255.</li> <li>Otherwise it assumes values are already in [0, 1] (or compatible).</li> <li>Converts the color from RGB to HSV.</li> <li>Samples:</li> <li>a hue shift <code>h ~ U(-hue_max, hue_max)</code> and applies it modulo 1.0,</li> <li>a saturation scale <code>s = 1 + U(-saturation_max, saturation_max)</code> and      multiplies the saturation channel by <code>s</code> (clipped to [0, 1]).</li> <li>Converts HSV back to RGB, clips to [0, 1], and restores the original dtype (multiplying by 255 if needed).</li> </ol> <p>Parameters:</p> Name Type Description Default <code>hue_max</code> <code>float</code> <p>Maximum absolute hue shift. The actual hue offset is sampled uniformly from <code>[-hue_max, hue_max]</code> and added to the hue channel modulo 1.0. Defaults to 0.5.</p> <code>0.5</code> <code>saturation_max</code> <code>float</code> <p>Maximum relative change in saturation. The saturation scale factor is sampled as:</p> <pre><code>s = 1 + U(-saturation_max, saturation_max)\n</code></pre> <p>so saturation can be slightly decreased or increased. Defaults to 0.2.</p> <code>0.2</code> <code>range255</code> <code>bool</code> <p>Whether the input color values are in <code>[0, 255]</code>. If True, values are converted to float in [0, 1] before modification and converted back to [0, 255] afterwards. If False, values are treated as floats in [0, 1]. Defaults to False.</p> <code>False</code> <code>apply_p</code> <code>float</code> <p>Probability of applying the hue/saturation translation. Defaults to 1.0.</p> <code>1.0</code> <p>Hue Saturation Translation PC Colors</p> <p> </p>"},{"location":"color/#augmentation_class.HueSaturationTranslation.__call__","title":"<code>__call__(data_dict)</code>","text":"<p>Apply random hue and saturation translation to <code>\"color\"</code>. Args:     data_dict (dict): Input dictionary that must contain a <code>\"color\"</code> key with a NumPy array of shape (N, 3)         representing point color values.</p> <p>Returns:</p> Name Type Description <code>dict</code> <code>dict</code> <p>The same dictionary with <code>\"color\"</code> updated in-place, if applied.</p>"},{"location":"color/#randomcoloraugment","title":"RandomColorAugment","text":"<p>Apply a simple global color scaling to point colors.</p> <p>This transform expects a dictionary containing:</p> <ul> <li><code>\"color\"</code>: NumPy array of shape (N, 3) with point color values.</li> </ul> <p>It multiplies the color values by <code>color_augment</code> and clips them to a valid range:</p> <ul> <li>If <code>range255=True</code> \u2192 values are clipped to <code>[0, 255]</code>.</li> <li>If <code>range255=False</code> \u2192 values are clipped to <code>[0, 1]</code>.</li> </ul> <p>Parameters:</p> Name Type Description Default <code>color_augment</code> <code>float</code> <p>Multiplicative scaling factor applied to all color channels (e.g., 1.1 to slightly brighten, 0.9 to slightly darken). Defaults to 1.1.</p> <code>1.1</code> <code>range255</code> <code>bool</code> <p>Whether the input color values are in <code>[0, 255]</code>. If True, clipping is done in that range. If False, clipping is done in <code>[0, 1]</code>. Defaults to False.</p> <code>False</code> <code>apply_p</code> <code>float</code> <p>Probability of applying the color scaling. Defaults to 1.0.</p> <code>1.0</code> <p>Random Augment PC Colors</p> <p> </p>"},{"location":"color/#augmentation_class.RandomColorAugment.__call__","title":"<code>__call__(data_dict)</code>","text":"<p>Apply global color scaling to the <code>\"color\"</code> entry in <code>data_dict</code>.</p> <p>Parameters:</p> Name Type Description Default <code>data_dict</code> <code>dict</code> <p>Input dictionary that must contain a <code>\"color\"</code> key with a NumPy array of shape (N, 3) representing point color values.</p> required <p>Returns:</p> Name Type Description <code>dict</code> <code>dict</code> <p>The same dictionary with <code>\"color\"</code> updated in-place, if applied.</p>"},{"location":"coord/","title":"Coordinate","text":"<p>Classes for point coordinates</p>"},{"location":"coord/#normalizecoord","title":"NormalizeCoord","text":"<p>Normalizes the point cloud into a unit sphere, where the center is the mean of the point set.</p> <p>This transform expects a dictionary containing:</p> <ul> <li><code>\"coord\"</code>: NumPy array of shape (N, 3) with point coordinates.</li> </ul> <p>Normalize PC into Unit Sphere Space</p> <p> </p>"},{"location":"coord/#augmentation_class.NormalizeCoord.__call__","title":"<code>__call__(data_dict)</code>","text":"<p>Normalizes point cloud coordinates into unit sphere.</p> <p>Parameters:</p> Name Type Description Default <code>data_dict</code> <code>dict</code> <p>Input dictionary that contains a \"coord\" key with a NumPy array of shape (N, 3) representing point coordinates.</p> required <p>Returns:</p> Name Type Description <code>dict</code> <code>dict</code> <p>The same dictionary with <code>\"coord\"</code> normalized into a unit sphere.</p>"},{"location":"coord/#positiveshift","title":"PositiveShift","text":"<p>Shift point coordinates so all values are non-negative.</p> <p>This transform expects a dictionary containing:</p> <ul> <li><code>\"coord\"</code>: NumPy array of shape (N, 3) with point coordinates.</li> </ul> <p>Positive Shift PC</p> <p> </p>"},{"location":"coord/#augmentation_class.PositiveShift.__call__","title":"<code>__call__(data_dict)</code>","text":"<p>Moves points so that all coordinate values become non-negative.</p> <p>Parameters:</p> Name Type Description Default <code>data_dict</code> <code>dict</code> <p>Input dictionary that must contain a \"coord\" key with a NumPy array of shape (N, 3) representing point coordinates.</p> required <p>Returns:</p> Name Type Description <code>dict</code> <code>dict</code> <p>The same dictionary with \"coord\" shifted so all values are greater than or equal to zero.</p>"},{"location":"coord/#centershift","title":"CenterShift","text":"<p>Translate point coordinates so they are centered around a reference point.</p> <p>This transform expects a dictionary containing:</p> <ul> <li><code>\"coord\"</code>: NumPy array of shape (N, 3) with point coordinates.</li> </ul> <p>It computes a shift vector and subtracts it from all coordinates in place. There are two ways to define the shift:</p> <ul> <li>Mean-based centering (<code>mean=True</code>):</li> <li>The shift is the mean (centroid) of all points along each axis.</li> <li> <p>If <code>apply_z</code> is False, the z-component of the shift is replaced by the minimum z value of the points, so:</p> <ul> <li>x and y are centered by their mean.</li> <li>z is shifted so that the lowest point lies at z = 0.</li> </ul> </li> <li> <p>Bounding-box centering (<code>mean=False</code>):</p> </li> <li>The shift is the center of the axis-aligned bounding box (AABB), i.e., the midpoint between min and max along each axis.</li> <li>If <code>apply_z</code> is False, the z-component of the shift is set to the minimum z value of the points, so the bottom of the bounding box is at z = 0.</li> </ul> <p>Parameters:</p> Name Type Description Default <code>mean</code> <code>bool</code> <p>If True, use the mean of the coordinates as the shift (centroid). If False, use the center of the bounding box. Defaults to False.</p> <code>False</code> <code>apply_z</code> <code>bool</code> <p>If True, apply the same centering logic to the z-axis as x and y. If False, the z shift is always set to the minimum z value, so the lowest point (or bottom of the bounding box) sits at z = 0. Defaults to True.</p> <code>True</code> <p>Center Shift PC</p> <p> </p>"},{"location":"coord/#augmentation_class.CenterShift.__call__","title":"<code>__call__(data_dict)</code>","text":"<p>Center the point cloud coordinates in place.</p> <p>Parameters:</p> Name Type Description Default <code>data_dict</code> <code>dict</code> <p>Input dictionary that must contain a <code>\"coord\"</code> key with a NumPy array of shape (N, 3) representing point coordinates.</p> required <p>Returns:</p> Name Type Description <code>dict</code> <code>dict</code> <p>The same dictionary with <code>\"coord\"</code> translated according to the centering strategy.</p>"},{"location":"coord/#randomshift","title":"RandomShift","text":"<p>Randomly translate point coordinates along the x, y, and z axes.</p> <p>This transform expects a dictionary containing:</p> <ul> <li><code>\"coord\"</code>: NumPy array of shape (N, 3) with point coordinates.</li> </ul> <p>It samples a random shift for each axis from the corresponding interval in <code>shift</code> and adds it to all points in place.</p> <p>Parameters:</p> Name Type Description Default <code>shift</code> <code>tuple[tuple[float, float], tuple[float, float], tuple[float, float]]</code> <p>A tuple of three <code>(min, max)</code> pairs controlling the uniform sampling range of the shift per axis:</p> <ul> <li><code>shift[0]</code> \u2192 (x_min, x_max) for the x-axis shift.</li> <li><code>shift[1]</code> \u2192 (y_min, y_max) for the y-axis shift.</li> <li><code>shift[2]</code> \u2192 (z_min, z_max) for the z-axis shift.</li> </ul> <p>Each shift value is sampled from a uniform distribution: <code>np.random.uniform(min, max)</code>.</p> <p>With the default configuration:</p> <ul> <li>x ~ U(-0.02, 0.02)</li> <li>y ~ U(-0.02, 0.02)</li> <li>z ~ U( 0.02, 0.02)</li> </ul> <p>Defaults to <code>((-0.02, 0.02), (-0.02, 0.02), (0.02, 0.02))</code>.</p> <code>((-0.02, 0.02), (-0.02, 0.02), (0.02, 0.02))</code> <code>apply_p</code> <code>float</code> <p>Probability of applying the random shift. Defaults to 1.0.</p> <code>1.0</code> <p>Random Shift PC</p> <p> </p>"},{"location":"coord/#augmentation_class.RandomShift.__call__","title":"<code>__call__(data_dict)</code>","text":"<p>Apply a random global shift to the point coordinates.</p> <p>Parameters:</p> Name Type Description Default <code>data_dict</code> <code>dict</code> <p>Input dictionary that must contain a <code>\"coord\"</code> key with a NumPy array of shape (N, 3) representing point coordinates.</p> required <p>Returns:</p> Name Type Description <code>dict</code> <code>dict</code> <p>The same dictionary with <code>\"coord\"</code> translated by a random shift vector, if applied.</p>"},{"location":"coord/#randomrotate","title":"RandomRotate","text":"<p>Randomly rotate 3D points (and optionally normals) around a given axis.</p> <p>This transform expects a dictionary containing:</p> <ul> <li><code>\"coord\"</code>: NumPy array of shape (N, 3) with point coordinates.</li> <li>Optionally <code>\"norm\"</code>: NumPy array of shape (N, 3) with normals associated with each point.</li> </ul> <p>The transform samples a rotation angle (in degrees) from <code>angle</code>, builds a rotation matrix around the specified axis, and applies it to the coordinates (and normals, if present). The rotation is applied around a center point:</p> <ul> <li>If <code>center</code> is <code>None</code>, the rotation center is taken as the center of the axis-aligned bounding box (AABB) of the coordinates.</li> <li>If <code>center</code> is provided, it is used directly as the rotation center.</li> </ul> <p>Parameters:</p> Name Type Description Default <code>angle</code> <code>tuple[float, float] | None</code> <p>A <code>(min_deg, max_deg)</code> pair specifying the range of rotation angles in degrees. The actual angle is sampled uniformly from this interval and converted to radians internally. If <code>None</code> (default), it is set to <code>(-180, 180)</code>. For example, <code>angle=(-10, 10)</code> means a random rotation between -10\u00b0 and +10\u00b0. Defaults to None.</p> <code>None</code> <code>center</code> <code>tuple[float, float, float] | ndarray | None</code> <p>Rotation center in 3D, given as a 3-element tuple or NumPy array <code>(cx, cy, cz)</code>. If <code>None</code> (default), the center of the bounding box of <code>data_dict[\"coord\"]</code> is used: <code>center = ((x_min+x_max)/2, (y_min+y_max)/2, (z_min+z_max)/2)</code>. Defaults to None.</p> <code>None</code> <code>axis</code> <code>str</code> <p>Axis (or axes) around which the rotation is applied. One of <code>\"x\"</code>, <code>\"y\"</code>, <code>\"z\"</code>, or <code>\"xyz\"</code>.</p> <ul> <li><code>\"x\"</code>: single rotation around the x-axis.</li> <li><code>\"y\"</code>: single rotation around the y-axis.</li> <li><code>\"z\"</code>: single rotation around the z-axis.</li> <li><code>\"xyz\"</code>: three independent random rotations are sampled   (one for x, one for y, one for z), and the final rotation   matrix is computed as <code>R = R_z @ R_y @ R_x</code>.</li> </ul> <p>In all cases, angles are sampled (in degrees) from the same <code>angle</code> range. Defaults to <code>\"y\"</code>.</p> <code>'y'</code> <code>apply_p</code> <code>float</code> <p>Probability of applying the rotation. Defaults to 1.0.</p> <code>1.0</code> <p>Random Rotate PC</p> <p> </p>"},{"location":"coord/#augmentation_class.RandomRotate.__call__","title":"<code>__call__(data_dict)</code>","text":"<p>Apply a random rotation to coordinates (and normals, if present).</p> <p>Parameters:</p> Name Type Description Default <code>data_dict</code> <code>dict</code> <p>Input dictionary that must contain a <code>\"coord\"</code> key with a NumPy array of shape (N, 3) representing point coordinates. Optionally may contain <code>\"norm\"</code> with a NumPy array of shape (N, 3) representing normal vectors.</p> required <p>Returns:</p> Name Type Description <code>dict</code> <code>dict</code> <p>The same dictionary with <code>\"coord\"</code> rotated around the chosen center, and <code>\"norm\"</code> rotated if present.</p>"},{"location":"coord/#randomscale","title":"RandomScale","text":"<p>Randomly scale 3D coordinates uniformly or per-axis.</p> <p>This transform expects a dictionary containing:</p> <ul> <li><code>\"coord\"</code>: NumPy array of shape (N, 3) with point coordinates.</li> </ul> <p>It samples a scale factor (or factors) from <code>scale</code> and multiplies the coordinates in place.</p> <p>Parameters:</p> Name Type Description Default <code>scale</code> <code>list[float, float] | tuple[float, float]</code> <p>A <code>(min_scale, max_scale)</code> pair used as the uniform sampling range for the scale factor(s). Values are drawn from <code>np.random.uniform(min_scale, max_scale, size=...)</code>.</p> <p>Examples:     * <code>scale=(0.95, 1.05)</code> \u2192 small random resize around 1.0.     * <code>scale=(0.5, 1.5)</code> \u2192 more aggressive zoom in/out.</p> <p>Defaults to <code>(0.95, 1.05)</code>.</p> <code>(0.95, 1.05)</code> <code>anisotropic</code> <code>bool</code> <p>Controls whether scaling is uniform or per-axis.</p> <ul> <li><code>False</code>: Sample a single scalar <code>s</code> and apply <code>coord *= s</code>.</li> <li><code>True</code>: Sample a 3D vector <code>[sx, sy, sz]</code> and apply   <code>coord *= [sx, sy, sz]</code>.</li> </ul> <p>Defaults to <code>False</code>.</p> <code>False</code> <code>apply_p</code> <code>float</code> <p>Probability of applying the random scaling. Defaults to 1.0.</p> <code>1.0</code> <p>Random Scale PC</p> <p> </p>"},{"location":"coord/#augmentation_class.RandomScale.__call__","title":"<code>__call__(data_dict)</code>","text":"<p>Apply a random scaling to the point coordinates.</p> <p>Parameters:</p> Name Type Description Default <code>data_dict</code> <code>dict</code> <p>Input dictionary that must contain a <code>\"coord\"</code> key with a NumPy array of shape (N, 3) representing point coordinates.</p> required <p>Returns:</p> Name Type Description <code>dict</code> <code>dict</code> <p>The same dictionary with <code>\"coord\"</code> scaled by a random factor (uniform or per-axis), if applied.</p>"},{"location":"coord/#randomtranslate","title":"RandomTranslate","text":"<p>Randomly translate 3D coordinates by the same offset vector along x, y, z.</p> <p>This transform expects a dictionary containing:</p> <ul> <li><code>\"coord\"</code>: NumPy array of shape (N, 3) with point coordinates.</li> </ul> <p>It samples a translation vector <code>[tx, ty, tz]</code> from the given range and adds it to all coordinates in place.</p> <p>Parameters:</p> Name Type Description Default <code>translate_range</code> <code>tuple[float, float]</code> <p>A <code>(min_translate, max_translate)</code> pair specifying the uniform sampling range for each axis. The translation vector is drawn as::</p> <p>translate = np.random.uniform(min_translate, max_translate, size=3)</p> <p>That is:</p> <ul> <li><code>tx ~ U(min_translate, max_translate)</code></li> <li><code>ty ~ U(min_translate, max_translate)</code></li> <li><code>tz ~ U(min_translate, max_translate)</code></li> </ul> <p>Defaults to <code>(-0.2, 0.2)</code>.</p> <code>(-0.2, 0.2)</code> <code>apply_p</code> <code>float</code> <p>Probability of applying the translation. Defaults to 1.0.</p> <code>1.0</code> <p>Random Translate PC</p> <p> </p>"},{"location":"coord/#augmentation_class.RandomTranslate.__call__","title":"<code>__call__(data_dict)</code>","text":"<p>Apply a random global translation to the point coordinates.</p> <p>Parameters:</p> Name Type Description Default <code>data_dict</code> <code>dict</code> <p>Input dictionary that must contain a <code>\"coord\"</code> key with a NumPy array of shape (N, 3) representing point coordinates.</p> required <p>Returns:</p> Name Type Description <code>dict</code> <code>dict</code> <p>The same dictionary with <code>\"coord\"</code> translated by a random offset vector, if applied.</p>"},{"location":"coord/#randomjitter","title":"RandomJitter","text":"<p>Add small Gaussian noise to 3D coordinates (point-wise jitter).</p> <p>This transform expects a dictionary containing:</p> <ul> <li><code>\"coord\"</code>: NumPy array of shape (N, 3) with point coordinates.</li> </ul> <p>It samples Gaussian noise for each point and each axis, scales it by <code>sigma</code>, clips it to <code>[-clip, clip]</code>, and adds it to the coordinates in place.</p> <p>Parameters:</p> Name Type Description Default <code>sigma</code> <code>float</code> <p>Standard deviation of the Gaussian noise before clipping. Noise is drawn as:</p> <pre><code>jitter_raw ~ N(0, sigma^2)\n</code></pre> <p>per coordinate. Defaults to 0.01.</p> <code>0.01</code> <code>clip</code> <code>float</code> <p>Maximum absolute value for the jitter. After sampling, the noise is clipped to the range <code>[-clip, clip]</code>:</p> <pre><code>jitter = np.clip(jitter_raw, -clip, clip)\n</code></pre> <p>Must be positive. Defaults to 0.05.</p> <code>0.05</code> <code>apply_p</code> <code>float</code> <p>Probability of applying the jitter. Defaults to 1.0.</p> <code>1.0</code> <p>Random Jitter PC</p> <p> </p>"},{"location":"coord/#augmentation_class.RandomJitter.__call__","title":"<code>__call__(data_dict)</code>","text":"<p>Apply point-wise Gaussian jitter to the point coordinates.</p> <p>Parameters:</p> Name Type Description Default <code>data_dict</code> <code>dict</code> <p>Input dictionary that must contain a <code>\"coord\"</code> key with a NumPy array of shape (N, 3) representing point coordinates.</p> required <p>Returns:</p> Name Type Description <code>dict</code> <code>dict</code> <p>The same dictionary with <code>\"coord\"</code> perturbed by clipped Gaussian noise, if applied.</p>"},{"location":"coord/#randomflip","title":"RandomFlip","text":"<p>Randomly flip point coordinates (and normals) by sign along selected axes.</p> <p>This transform expects a dictionary containing:</p> <ul> <li><code>\"coord\"</code>: NumPy array of shape (N, 3) with point coordinates.</li> <li>Optionally <code>\"norm\"</code>: NumPy array of shape (N, 3) with normals   associated with each point.</li> </ul> <p>Given the axes in <code>flip_axis</code>, each axis may be flipped by multiplying the corresponding coordinate (and normal, if present) by -1.</p> <p>Parameters:</p> Name Type Description Default <code>flip_axis</code> <code>tuple[int, ...]</code> <p>Indices of axes to consider for flipping. Each element must be in <code>{0, 1, 2}</code>:</p> <ul> <li><code>0</code> \u2192 x-axis</li> <li><code>1</code> \u2192 y-axis</li> <li><code>2</code> \u2192 z-axis</li> </ul> <p>For each axis in this tuple, a random decision is made (with probability <code>apply_p</code>) whether to flip that axis.</p> <p>Examples:     * <code>flip_axis=(0,)</code> \u2192 only possible flip is x-axis.     * <code>flip_axis=(1, 2)</code> \u2192 y and z axes may be flipped       independently.</p> <p>Defaults to <code>(0, 2)</code>.</p> <code>(0, 2)</code> <code>apply_p</code> <code>float</code> <p>Probability of flipping each axis. Defaults to 1.0.</p> <code>1.0</code> <p>Random Flip PC</p> <p> </p>"},{"location":"coord/#augmentation_class.RandomFlip.__call__","title":"<code>__call__(data_dict)</code>","text":"<p>Apply random sign flips along selected axes to coords (and normals).</p> <p>Parameters:</p> Name Type Description Default <code>data_dict</code> <code>dict</code> <p>Input dictionary that should contain a <code>\"coord\"</code> key with a NumPy array of shape (N, 3) representing point coordinates. Optionally may contain a <code>\"norm\"</code> key with a NumPy array of shape (N, 3) representing normal vectors.</p> required <p>Returns:</p> Name Type Description <code>dict</code> <code>dict</code> <p>The same dictionary with <code>\"coord\"</code> (and <code>\"norm\"</code> if present) potentially flipped by sign along the specified axes.</p>"},{"location":"coord/#randomdropout","title":"RandomDropout","text":"<p>Randomly drop a subset of points (and aligned per-point attributes).</p> <p>This transform expects a dictionary containing:</p> <ul> <li><code>\"coord\"</code>: NumPy array of shape (N, 3) with point coordinates.</li> <li>Optionally other per-point arrays (e.g., <code>\"norm\"</code>, <code>\"color\"</code>, <code>\"label\"</code>)   that have length N along the first dimension.</li> </ul> <p>Parameters:</p> Name Type Description Default <code>max_dropout_ratio</code> <code>float</code> <p>Maximum fraction of points that may be dropped. The actual dropout ratio is drawn from:</p> <pre><code>ratio ~ U(0, max_dropout_ratio)\n</code></pre> <p>For example, if <code>max_dropout_ratio = 0.2</code>, then up to 20% of points can be removed in any application of this transform. Defaults to 0.2.</p> <code>0.2</code> <code>apply_p</code> <code>float</code> <p>Probability of applying the dropout. Defaults to 1.0.</p> <code>1.0</code> <p>Random Dropout PC</p> <p> </p>"},{"location":"coord/#augmentation_class.RandomDropout.__call__","title":"<code>__call__(data_dict)</code>","text":"<p>Apply random point dropout to coords and aligned attributes.</p> <p>Parameters:</p> Name Type Description Default <code>data_dict</code> <code>dict</code> <p>Input dictionary that must contain a <code>\"coord\"</code> key with a NumPy array of shape (N, 3). Any other entry whose value is a NumPy array or <code>Sequence</code> of length N and whose key does not contain <code>\"origin\"</code> will also be subsampled.</p> required <p>Returns:</p> Name Type Description <code>dict</code> <code>dict</code> <p>The same dictionary with a subset of points (and aligned per-point attributes) kept, if dropout is applied.</p>"},{"location":"coord/#shufflepoint","title":"ShufflePoint","text":"<p>Randomly permute the order of points (and aligned per-point attributes).</p> <p>This transform expects a dictionary containing:</p> <ul> <li><code>\"coord\"</code>: NumPy array of shape (N, 3) with point coordinates.</li> <li>Optionally other per-point arrays (e.g., <code>\"norm\"</code>, <code>\"color\"</code>, <code>\"label\"</code>) that have length N along the first dimension.</li> </ul> <p>All per-point arrays of matching length are shuffled with the same permutation, preserving correspondence between them.</p> <p>Parameters:</p> Name Type Description Default <code>apply_p</code> <code>float</code> <p>Probability of applying the shuffling. Defaults to 1.0.</p> <code>1.0</code>"},{"location":"coord/#augmentation_class.ShufflePoint.__call__","title":"<code>__call__(data_dict)</code>","text":"<p>Shuffle the order of points and aligned per-point attributes.</p> <p>Parameters:</p> Name Type Description Default <code>data_dict</code> <code>dict</code> <p>Input dictionary that must contain a <code>\"coord\"</code> key with a NumPy array of shape (N, 3). Any other entry whose value is a NumPy array or <code>Sequence</code> of length N and whose key does not contain <code>\"origin\"</code> will be permuted with the same shuffle indices.</p> required <p>Returns:</p> Name Type Description <code>dict</code> <code>dict</code> <p>The same dictionary with <code>\"coord\"</code> and aligned per-point attributes shuffled in order, if applied.</p>"},{"location":"coord/#pointclip","title":"PointClip","text":"<p>Randomly clip a local region around a randomly chosen point.</p> <p>This transform expects a dictionary containing:</p> <ul> <li><code>\"coord\"</code>: NumPy array of shape (N, 3) with point coordinates.</li> <li>Optionally other per-point arrays (e.g., <code>\"norm\"</code>, <code>\"color\"</code>, <code>\"label\"</code>)   that have length N along the first dimension.</li> </ul> <p>A random point index is selected and its coordinate is used as the center:</p> <pre><code>center = coord[center_idx]\n</code></pre> <p>Then it builds either:</p> <ul> <li>a spherical region of radius <code>radius</code> around <code>center</code> if <code>use_sphere=True</code>, or</li> <li>an axis-aligned box centered at <code>center</code> with half-extent <code>box_range</code>   if <code>use_sphere=False</code>.</li> </ul> <p>Only points inside this region are kept; all others are dropped. All aligned per-point attributes are filtered with the same mask.</p> <p>Parameters:</p> Name Type Description Default <code>use_sphere</code> <code>bool</code> <p>If True, use a spherical region. For each point <code>p</code>, compute squared distance:</p> <pre><code>dist2 = ||p - center||^2\n</code></pre> <p>and keep points with <code>dist2 &lt;= radius^2</code>. If False, use an axis-aligned box instead. Defaults to True.</p> <code>True</code> <code>radius</code> <code>float</code> <p>Radius of the sphere used when <code>use_sphere=True</code>. The clipped region is:</p> <pre><code>{ p : ||p - center|| &lt;= radius }\n</code></pre> <p>Defaults to 1.0.</p> <code>1.0</code> <code>box_range</code> <code>tuple[float, float, float]</code> <p>Half-extent of the axis-aligned box along each axis, used when <code>use_sphere=False</code>. Interpreted as <code>(rx, ry, rz)</code>. The box is defined as:</p> <ul> <li><code>x_min, y_min, z_min = center - box_range</code></li> <li><code>x_max, y_max, z_max = center + box_range</code></li> </ul> <p>A point <code>p = (x, y, z)</code> is kept if:</p> <pre><code>x_min &lt;= x &lt;= x_max\ny_min &lt;= y &lt;= y_max\nz_min &lt;= z &lt;= z_max\n</code></pre> <p>Defaults to <code>(0.0, 0.0, 0.0)</code>.</p> <code>(0.0, 0.0, 0.0)</code> <code>apply_p</code> <code>float</code> <p>Probability of applying the clipping. Defaults to 1.0.</p> <code>1.0</code> <p>Clip PC</p> <p> </p>"},{"location":"coord/#augmentation_class.PointClip.__call__","title":"<code>__call__(data_dict)</code>","text":"<p>Apply a local region crop (sphere or box) around a random center.</p> <p>Parameters:</p> Name Type Description Default <code>data_dict</code> <code>dict</code> <p>Input dictionary that must contain a <code>\"coord\"</code> key with a NumPy array of shape (N, 3). Any other entry whose value is a NumPy array or <code>Sequence</code> of length N and whose key does not contain <code>\"origin\"</code> will also be masked.</p> required <p>Returns:</p> Name Type Description <code>dict</code> <code>dict</code> <p>The same dictionary with <code>\"coord\"</code> and aligned per-point attributes cropped to a local region, if applied.</p>"},{"location":"coord/#clipgaussianjitter","title":"ClipGaussianJitter","text":"<p>Add clipped multivariate Gaussian noise to 3D coordinates.</p> <p>This transform expects a dictionary containing: * <code>\"coord\"</code>: NumPy array of shape (N, 3) with point coordinates.</p> <p>Unlike a simple per-axis jitter (RandomJitter) with independent 1D Gaussians, this transform uses a multivariate normal distribution, allowing you to encode correlations between axes via the covariance matrix. It samples 3D Gaussian noise from a multivariate normal, normalizes and clips it using a <code>quantile</code> parameter, scales it by <code>scalar</code>, and adds it to the coordinates in place.</p> <p>In the default setting:</p> <ul> <li><code>mean = [0.0, 0.0, 0.0]</code></li> <li><code>cov = I_3</code> (3\u00d73 identity matrix \u2192 isotropic Gaussian)</li> </ul> <p>A raw sample is drawn as:</p> <pre><code>jitter_raw ~ N(mean, cov)\n</code></pre> <p>Then it is transformed as:</p> <pre><code>jitter = scalar * clip(jitter_raw / quantile, -1, 1)\n</code></pre> <p>Intuition:</p> <ul> <li>For a standard normal, most values lie within \u00b1<code>quantile</code>   (e.g., 1.96 \u2248 97.5% quantile).</li> <li>Dividing by <code>quantile</code> and clipping to [-1, 1] effectively bounds   each component before scaling, so typical magnitudes are on the   order of <code>\u00b1scalar</code>.</li> </ul> <p>Parameters:</p> Name Type Description Default <code>quantile</code> <code>float</code> <p>Normalization factor used before clipping. Noise is divided by <code>quantile</code> and then clipped to [-1, 1]. For <code>quantile=1.96</code>, about 95\u201397.5% of standard normal samples fall in [-1.96, 1.96], so after dividing most samples lie in [-1, 1] before clipping. Increasing <code>quantile</code> makes the effective jitter slightly smaller; decreasing it makes it larger (and more aggressively clipped). Defaults to 1.96.</p> <code>1.96</code> <code>scalar</code> <code>float</code> <p>Overall scale factor for the jitter after clipping. Roughly controls the maximum perturbation per coordinate (since final values are typically in approximately<code>[-scalar, scalar]</code>). Defaults to 0.02.</p> <code>0.02</code> <code>apply_p</code> <code>float</code> <p>Probability of applying the jitter. Defaults to 1.0.</p> <code>1.0</code> <p>Clip Gaussian Jitter on PC</p> <p> </p>"},{"location":"coord/#augmentation_class.ClipGaussianJitter.__call__","title":"<code>__call__(data_dict)</code>","text":"<p>Apply clipped multivariate Gaussian jitter to the point coordinates.</p> <p>Parameters:</p> Name Type Description Default <code>data_dict</code> <code>dict</code> <p>Input dictionary that must contain a <code>\"coord\"</code> key with a NumPy array of shape (N, 3) representing point coordinates.</p> required <p>Returns:</p> Name Type Description <code>dict</code> <code>dict</code> <p>The same dictionary with <code>\"coord\"</code> perturbed by clipped multivariate Gaussian noise, if applied.</p>"},{"location":"coord/#elasticdistortion","title":"ElasticDistortion","text":"<p>Apply elastic distortion to 3D point coordinates.</p> <p>This transform expects a dictionary containing:</p> <ul> <li><code>\"coord\"</code>: NumPy array of shape (N, 3) with point coordinates.</li> </ul> <p>The distortion is implemented by:</p> <ol> <li>Creating a coarse 3D grid of Gaussian noise with resolution determined    by <code>granularity</code>.</li> <li>Smoothing the noise with separable 3D convolutions.</li> <li>Trilinearly interpolating the smoothed noise at each input coordinate.</li> <li>Adding the interpolated noise (scaled by <code>magnitude</code>) to the original    coordinates.</li> </ol> <p>Multiple <code>(granularity, magnitude)</code> pairs can be applied sequentially to produce multi-scale elastic deformations.</p> <p>Parameters:</p> Name Type Description Default <code>distortion_params</code> <code>list[list[float]] | list[tuple[float, float]] | None</code> <p>List of <code>(granularity, magnitude)</code> pairs controlling the elastic fields to apply. Each pair is:</p> <ul> <li><code>granularity</code> (float):     Size of the noise grid in the same units as the coordinates (e.g., meters or centimeters).     Larger values \u2192 smoother, more global distortions.</li> <li><code>magnitude</code> (float):     Amplitude of the noise displacement added to the coordinates.</li> </ul> <p>If <code>None</code>, a default two-scale configuration is used: <code>[[0.2, 0.4], [0.8, 1.6]]</code>. Defaults to <code>None</code>.</p> <code>None</code> <code>apply_p</code> <code>float</code> <p>Probability of applying the elastic Defaults to 1.0.</p> <code>1.0</code> <p>Elastic Distortion on PC</p> <p> </p>"},{"location":"coord/#augmentation_class.ElasticDistortion.__call__","title":"<code>__call__(data_dict)</code>","text":"<p>Apply elastic distortion(s) to <code>\"coord\"</code> in <code>data_dict</code>.</p> <p>Parameters:</p> Name Type Description Default <code>data_dict</code> <code>dict</code> <p>Input dictionary that must contain a <code>\"coord\"</code> key with a NumPy array of shape (N, 3) representing point coordinates.</p> required <p>Returns:</p> Name Type Description <code>dict</code> <code>dict</code> <p>The same dictionary with <code>\"coord\"</code> distorted in place, if applied.</p>"},{"location":"noise/","title":"Noise","text":"<p>Classes for adding noise into point cloud</p>"},{"location":"noise/#addoutlier","title":"AddOutlier","text":"<p>Add synthetic outlier points (and attributes) around a point cloud.</p> <p>This transform expects a dictionary containing:</p> <ul> <li><code>\"coord\"</code>: NumPy array of shape (N, 3) with point coordinates.</li> <li>Optionally <code>\"norm\"</code>: per-point normals of shape (N, 3).</li> <li>Optionally <code>\"color\"</code>: per-point colors of shape (N, C).</li> <li>Optionally <code>\"noise_index\"</code>: 1D array of length N indicating noise labels (existing noise index).</li> </ul> <p>It augments the point cloud by sampling additional points in a spherical shell around the existing point cloud and appends them (and their attributes) to the existing arrays.</p> <p>The N number of outliers is:</p> <pre><code>N = int(max_ratio * n_pts)\n</code></pre> <p>where <code>n_pts</code> is the original number of points. If this is 0, the transform does nothing.</p> <p>Behavior of <code>fixed</code>:</p> <ul> <li>If <code>fixed=False</code>:</li> <li>Use all <code>N</code> generated outliers.</li> <li>If <code>fixed=True</code>:</li> <li> <p>Randomly choose a subset of the outliers with size:</p> <pre><code>N_used \u223c Uniform{ N // 2, ..., N }\n</code></pre> <p>and only append this subset.</p> </li> </ul> <p>Outliers are sampled inside a spherical shell defined from the centroid and bounding radius:</p> <ol> <li> <p>Compute the centroid:</p> <p>center = mean(coord, axis=0)</p> </li> <li> <p>Compute the maximum radius from the centroid:</p> <p>r_max = max(||coord[i] - center||)</p> </li> <li> <p>Define a spherical shell with inner radius:</p> <p>r_min = radius_min * r_max</p> </li> </ol> <p>and outer radius:</p> <pre><code>   r_max_shell = r_max\n</code></pre> <ol> <li>Sample directions uniformly on the sphere and radii uniformly in volume within <code>[r_min, r_max_shell]</code>,    then map back to world coordinates.</li> </ol> <p>For each outlier point, a random unit normal is generated (if <code>\"norm\"</code> exists), and random colors are generated (if <code>\"color\"</code> exists).</p> <p>The <code>\"noise_index\"</code> field is updated as follows:</p> <ul> <li>If <code>\"noise_index\"</code> does not exist:</li> <li>A new array of length <code>N + N_used</code> is created, filled with 0 for original points and 3   (indication of outlier type noise) for new outliers.</li> <li>If <code>\"noise_index\"</code> exists:</li> <li>It is extended to length <code>N + N_used</code>, keeping existing values and setting all new entries to 3.</li> </ul> <p>Parameters:</p> Name Type Description Default <code>max_ratio</code> <code>float</code> <p>Maximum ratio of outliers to original points. The N number of generated outliers is:</p> <pre><code>N = int(max_ratio * n_pts)\n</code></pre> <p>where n_pts is the original point count. Defaults to 0.2.</p> <code>0.2</code> <code>fixed</code> <code>bool</code> <p>Controls whether to subsample the generated outliers:</p> <ul> <li>False \u2192 use all generated outliers (<code>N</code>).</li> <li>True \u2192 randomly select a subset of size between <code>N // 2</code> and <code>N</code> (inclusive). Defaults to False.</li> </ul> <code>False</code> <code>radius_min</code> <code>float</code> <p>Fraction of the maximum radius used as the inner radius of the sampling shell. The shell is defined as <code>[radius_min * r_max, r_max]</code>. Defaults to 0.5.</p> <code>0.5</code> <code>range255</code> <code>bool</code> <p>Whether <code>\"color\"</code> values are in <code>[0, 255]</code>. If True, outlier colors are sampled as integers in <code>[0, 255]</code>. If False, they are sampled as floats in <code>[0, 1]</code>. Defaults to False.</p> <code>False</code> <code>apply_p</code> <code>float</code> <p>Probability of applying the adding outliers. Defaults to 1.0.</p> <code>1.0</code> <p>Adding Outlier Noise</p> <p> </p>"},{"location":"noise/#augmentation_class.AddOutlier.__call__","title":"<code>__call__(data_dict)</code>","text":"<p>Add outlier points and update aligned per-point attributes.</p> <p>Parameters:</p> Name Type Description Default <code>data_dict</code> <code>dict</code> <p>Input dictionary containing <code>\"coord\"</code> and optionally <code>\"norm\"</code>, <code>\"color\"</code>, and <code>\"noise_index\"</code>.</p> required <p>Returns:</p> Name Type Description <code>dict</code> <code>dict</code> <p>The same dictionary with additional outlier points and updated attributes, if adding outliers is applied.</p>"},{"location":"noise/#addbackgroundnoise","title":"AddBackgroundNoise","text":"<p>Add structured background noise patches around a point cloud.</p> <p>This transform expects a dictionary containing:</p> <ul> <li><code>\"coord\"</code>: NumPy array of shape (N, 3) with point coordinates.</li> <li>Optionally <code>\"norm\"</code>: per-point normals of shape (N, 3).</li> <li>Optionally <code>\"color\"</code>: per-point colors of shape (N, C).</li> <li>Optionally <code>\"noise_index\"</code>: 1D array of length N indicating noise labels (existing noise index).</li> </ul> <p>It generates several small 3D regions (up to <code>max_regions</code>), each containing up to <code>region_max_k</code> random points. These regions are anchored to the bounding box of the (non-noise) point cloud and then added as background clutter:</p> <pre><code>1. Compute the axis-aligned bounding box (AABB) from points with ``noise_index == 0`` (or all points if ``noise_index`` is absent).\n2. Sample up to ``max_regions`` random centers inside the box (with behavior controlled by ``mode``).\n3. For each region, sample points uniformly in a cube of side length ``region_size`` around the center.\n4. Snap one coordinate of each region to one face of the bounding box, so that noise patches lie on or around the box surface.\n5. Generate random unit normals for these noise points.\n6. Optionally subsample a random subset of regions/points when ``fixed=False``.\n7. Concatenate noise coordinates, normals, and colors (if present) to the existing arrays, and update ``noise_index`` to mark them asbackground noise (label 2).\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>max_regions</code> <code>int</code> <p>Maximum number of noise regions to generate. Each region is a local cube of sampled noise points. Defaults to 8.</p> <code>8</code> <code>region_max_k</code> <code>int</code> <p>Maximum number of points per region before optional subsampling. Total initial noise points are roughly <code>max_regions * region_max_k</code> before any reduction. Defaults to 128.</p> <code>128</code> <code>region_size</code> <code>float</code> <p>Side length of each cubic noise region. Points are sampled uniformly in a cube of side <code>region_size</code> centered at each region center. Defaults to 0.5.</p> <code>0.5</code> <code>fixed</code> <code>bool</code> <p>Controls randomness and subsampling of the generated noise: * If <code>False</code>:   - Randomly choose a number of regions between 1 and <code>max_regions</code>.   - Flatten all noise points from those regions.   - Randomly select a subset of points, with size between roughly 1/8 of all region points and the full set. * If <code>True</code>:   - Use all <code>max_regions * region_max_k</code> points (no region or point subsampling).</p> <p>Defaults to False.</p> <code>False</code> <code>range255</code> <code>bool</code> <p>Whether color values are in the range <code>[0, 255]</code>. If True, noise colors are sampled as integers in <code>[0, 255]</code>. If False, noise colors are sampled as floats in <code>[0, 1]</code>. Defaults to False.</p> <code>False</code> <code>mode</code> <code>{outside, inside}</code> <p>Controls how the region centers are chosen relative to the bounding box:</p> <ul> <li><code>\"inside\"</code>:</li> <li>Region centers are chosen so that the entire noise cube (of side <code>region_size</code>) lies strictly inside the bounding     box, as much as possible. This ensures all noise points stay on/within the box volume.</li> <li><code>\"outside\"</code>:</li> <li>Region centers are sampled anywhere inside the bounding box, and one coordinate of each region is snapped to a box face.     Some noise points may lie slightly outside the box, mimicking more realistic background clutter.</li> </ul> <p>Defaults to <code>\"outside\"</code>.</p> <code>'outside'</code> <code>apply_p</code> <code>float</code> <p>Probability of applying the background Defaults to 1.0.</p> <code>1.0</code> <p>Adding Background Noise</p> <p> </p>"},{"location":"noise/#augmentation_class.AddBackgroundNoise.__call__","title":"<code>__call__(data_dict)</code>","text":"<p>Add background noise regions and update aligned per-point attributes.</p> <p>Parameters:</p> Name Type Description Default <code>data_dict</code> <code>dict</code> <p>Input dictionary containing at least <code>\"coord\"</code>. May also contain <code>\"norm\"</code>, <code>\"color\"</code>, and <code>\"noise_index\"</code>. Any existing <code>\"noise_index\" &gt; 0</code> points are excluded when computing the bounding box used to place new regions.</p> required <p>Returns:</p> Name Type Description <code>dict</code> <code>dict</code> <p>The same dictionary with added background noise points (coords, normals, colors if present) and an updated</p> <code>dict</code> <p><code>\"noise_index\"</code> marking these new points with label 2.</p>"},{"location":"noise/#addnoise","title":"AddNoise","text":"<p>Add local noise clusters around randomly chosen points.</p> <p>This transform expects a dictionary containing:</p> <ul> <li><code>\"coord\"</code>: NumPy array of shape (N, 3) with point coordinates.</li> <li>Optionally <code>\"norm\"</code>: per-point normals of shape (N, 3), required if   <code>method=\"custom\"</code>.</li> <li>Optionally <code>\"color\"</code>: per-point colors of shape (N, C).</li> <li>Optionally <code>\"noise_index\"</code>: 1D array of length N indicating existing noise labels.</li> </ul> <p>The transform works by:</p> <ol> <li> <p>Selecting a subset of points as noise centers.    The number of centers is:</p> <p>noise_center_count = int(N * noise_size_ratio)</p> </li> </ol> <p>(clamped to <code>[1, N]</code>). If this is 0, no noise is added. 2. For each center, generating up to <code>noise_max_k</code> noise points in its    local neighborhood (cluster), according to the chosen <code>method</code> and <code>boundary</code>. 3. Optionally subsampling the generated noise when <code>fixed=False</code>. 4. Mapping the local offsets to world coordinates and appending them (and their normals/colors) to the existing arrays. 5. Updating <code>noise_index</code> to mark the new points as local noise (value 1).</p> <p>Noise generation is controlled by two knobs:</p> <ul> <li><code>method</code>: defines how offsets are sampled:<ul> <li><code>\"uniform\"</code>:</li> <li>If <code>boundary=\"sphere\"</code>: sample directions uniformly and radii uniformly in volume within a ball of radius <code>ball_r</code>.</li> <li>If <code>boundary=\"cube\"</code>: sample coordinates uniformly in <code>[low, high]^3</code>.</li> <li><code>\"gaussian\"</code>:</li> <li>If <code>boundary=\"sphere\"</code>: Gaussian around the center, clamped to lie within a ball of radius <code>ball_r</code>.</li> <li>If <code>boundary=\"cube\"</code>: Gaussian in a cube, then clipped to the interval <code>[low, high]</code> per axis.</li> <li><code>\"custom\"</code>:</li> <li>Requires a <code>\"norm\"</code> field.</li> <li>For each center, uses its normal as a base direction and applies directional + radial jitter (using <code>ball_r</code> as scale) to create     offsets in a \u201ctube-like\u201d pattern around the surface.</li> </ul> </li> <li><code>boundary</code>: defines the shape of the local region:<ul> <li><code>\"sphere\"</code>: offsets lie in or near a ball of radius <code>ball_r</code>.</li> <li><code>\"cube\"</code>: offsets lie in or near a cube with side approximately <code>high - low</code> (for uniform/gaussian).</li> </ul> </li> </ul> <p>Colors for noise points are derived from the center colors:</p> <ul> <li>For <code>\"uniform\"</code> and <code>\"gaussian\"</code> methods:</li> <li>Noise points inherit exactly the color of their center.</li> <li>For <code>\"custom\"</code>:</li> <li>Optionally add Gaussian jitter in color space (scale depends on whether <code>range255</code> is True or False),   then clip to valid range.</li> </ul> <p>The number of final noise points is controlled by <code>fixed</code>:</p> <ul> <li>If <code>fixed=True</code>:</li> <li>Use all generated noise: <code>noise_center_count * noise_max_k</code> points.</li> <li>If <code>fixed=False</code>:</li> <li>Randomly shuffle all noise points and keep a random subset of size     between approximately one-eighth and the full generated count.</li> </ul> <p>Parameters:</p> Name Type Description Default <code>noise_size_ratio</code> <code>float</code> <p>Fraction of non-noise points to use as noise centers. The number of centers is:</p> <pre><code>noise_center_count = int(N * noise_size_ratio)\n</code></pre> <p>Defaults to 1./64.</p> <code>1.0 / 64</code> <code>noise_max_k</code> <code>int</code> <p>Maximum number of noise points generated per center before optional subsampling. Defaults to 16.</p> <code>16</code> <code>fixed</code> <code>bool</code> <p>Whether to keep all generated noise points or randomly subsample them:</p> <ul> <li>True  \u2192 keep all <code>noise_center_count * noise_max_k</code> noise points.</li> <li>False \u2192 shuffle and randomly keep a subset of those points.</li> </ul> <p>Defaults to True.</p> <code>True</code> <code>method</code> <code>{uniform, gaussian, custom}</code> <p>Noise sampling strategy. See above for details. <code>\"custom\"</code> requires <code>\"norm\"</code> in <code>data_dict</code>. Defaults to <code>\"uniform\"</code>.</p> <code>'uniform'</code> <code>boundary</code> <code>{sphere, cube}</code> <p>Shape of the local region in which noise is sampled. Interacts with <code>method</code> as described above. Defaults to <code>\"sphere\"</code>.</p> <code>'sphere'</code> <code>low</code> <code>float</code> <p>Lower bound for cube-based offsets (used for <code>boundary=\"cube\"</code> in <code>\"uniform\"</code> and <code>\"gaussian\"</code>). Defaults to -0.1.</p> <code>-0.1</code> <code>high</code> <code>float</code> <p>Upper bound for cube-based offsets. Defaults to 0.1.</p> <code>0.1</code> <code>ball_r</code> <code>float</code> <p>Radius of the spherical neighborhood for <code>boundary=\"sphere\"</code> methods; also used as a scale for radial jitter in the <code>\"custom\"</code> method. Defaults to 0.1.</p> <code>0.1</code> <code>range255</code> <code>bool</code> <p>Whether colors are stored in <code>[0, 255]</code> (integer-like). If True, color jitter in the <code>\"custom\"</code> method is done in that range. If False, colors are assumed in <code>[0, 1]</code>. Defaults to False.</p> <code>False</code> <code>apply_p</code> <code>float</code> <p>Probability of applying the noise Defaults to 1.0.</p> <code>1.0</code> <p>Adding Noise</p> <p> </p>"},{"location":"noise/#augmentation_class.AddNoise.__call__","title":"<code>__call__(data_dict)</code>","text":"<p>Apply local noise cluster augmentation to a point cloud dictionary.</p> <p>Parameters:</p> Name Type Description Default <code>data_dict</code> <code>dict</code> <p>Input dictionary containing at least <code>\"coord\"</code> (NumPy array of shape (N, 3)). May also contain <code>\"norm\"</code>, <code>\"color\"</code>, and <code>\"noise_index\"</code>. For <code>method=\"custom\"</code>, <code>\"norm\"</code> must be present.</p> required <p>Returns:</p> Name Type Description <code>dict</code> <code>dict</code> <p>The same dictionary with additional noise points appended to the relevant per-point fields and an updated <code>\"noise_index\"</code> marking newly added noise points with label 1.</p>"},{"location":"norm/","title":"Normal","text":"<p>Classes for point normal</p>"},{"location":"norm/#normalizenormal","title":"NormalizeNormal","text":"<p>Normalize normal vectors to unit length for a point cloud.</p> <p>This transform expects a dictionary containing: * <code>\"coord\"</code>: NumPy array of shape (N, 3) with point coordinates.</p>"},{"location":"norm/#augmentation_class.NormalizeNormal.__call__","title":"<code>__call__(data_dict)</code>","text":"<p>Normalizes normal vectors to unit length. Args:     data_dict (dict): Input dictionary that must contain a \"norm\" key                 with a NumPy array of shape (N, 3) representing normal vectors.</p> <p>Returns:</p> Name Type Description <code>dict</code> <code>dict</code> <p>The same dictionary with \"norm\" normalized to unit length.</p>"},{"location":"sample/","title":"SamplingPC","text":"<p>Classes for point cloud sampling</p>"},{"location":"sample/#sampling","title":"Sampling","text":"<p>Subsample points (and aligned attributes) using random or FPS-based indices.</p> <p>This transform expects a dictionary containing:</p> <ul> <li><code>\"coord\"</code>: NumPy array of shape (N, 3) with point coordinates.</li> <li>Optionally other per-point arrays (e.g., <code>\"norm\"</code>, <code>\"color\"</code>, <code>\"label\"</code>) that have length N along the first dimension.</li> <li>For FPS-based methods (<code>\"random_fps\"</code> and <code>\"fps\"</code>), a key <code>\"fps_index\"</code> is also required, containing a 1D array of   precomputed farthest-point-sampling indices into <code>\"coord\"</code>.</li> </ul> <p>If the requested number of points <code>n_pts</code> is less than the current number of points <code>N</code>, it selects a subset of indices and applies the same index selection to all aligned per-point fields (except keys containing <code>\"origin\"</code>). If <code>n_pts &gt;= N</code>, no subsampling is applied.</p> <p>The sampling strategy is controlled by <code>method</code>:</p> <ul> <li><code>\"random\"</code>:</li> <li>Uniformly sample <code>n_pts</code> indices from <code>[0, N)</code> without replacement.</li> <li><code>\"random_fps\"</code>:</li> <li>Sample <code>n_pts</code> indices from <code>fps_index</code> without replacement, then map the index to get the final subset.   (it is for better augmentation instead of fixed fps index each time despite not guarantee perfect uniform coverage)</li> <li><code>\"fps\"</code>:</li> <li>Directly use the first <code>n_pts</code> entries from <code>data_dict[\"fps_index\"]</code>.</li> </ul> <p>Parameters:</p> Name Type Description Default <code>n_pts</code> <code>int</code> <p>Target number of points after sampling. If <code>n_pts &gt;= N</code>, no sampling is applied. Defaults to 1024.</p> <code>1024</code> <code>method</code> <code>str</code> <p>Sampling strategy. One of:</p> <ul> <li><code>\"random\"</code>: uniform random sampling.</li> <li><code>\"random_fps\"</code>: random subset of precomputed FPS indices.</li> <li><code>\"fps\"</code>: first <code>n_pts</code> precomputed FPS indices.</li> </ul> <p>Defaults to <code>\"fps\"</code>.</p> <code>'fps'</code> <p>FPS PC with 4096 points</p> <p> </p>"},{"location":"sample/#augmentation_class.Sampling.__call__","title":"<code>__call__(data_dict)</code>","text":"<p>Subsample points and aligned fields according to the chosen method.</p> <p>Parameters:</p> Name Type Description Default <code>data_dict</code> <code>dict</code> <p>Input dictionary that must contain a <code>\"coord\"</code> key with a NumPy array of shape (N, 3). Any other entry whose value is a NumPy array or <code>Sequence</code> of length N and whose key does not contain <code>\"origin\"</code> will be permuted with the same shuffle indices.</p> required <p>Returns:</p> Name Type Description <code>dict</code> <code>dict</code> <p>The same dictionary with <code>\"coord\"</code> and aligned per-point attributes subsampled to at most <code>n_pts</code> points, if applied.</p>"},{"location":"sample/#samplingdynamic","title":"SamplingDynamic","text":"<p>Dynamically choose the number of sampled points based on a scalar attribute.</p> <p>This transform expects a dictionary containing:</p> <ul> <li><code>\"coord\"</code>: NumPy array of shape (N, 3) with point coordinates.</li> <li>Optionally other per-point arrays (e.g., <code>\"norm\"</code>, <code>\"color\"</code>, <code>\"label\"</code>) that have length N along the first dimension.</li> <li><code>\"fps_index\"</code>: 1D NumPy array of precomputed farthest-point-sampling indices into <code>\"coord\"</code>.</li> <li>A scalar entry <code>key</code> (default <code>\"area\"</code>) used to determine how many points to sample.</li> </ul> <p>The number of target points is computed as:</p> <pre><code>pts = int(data_dict[key] * pts_ratio)\n</code></pre> <p>Then, from <code>\"fps_index\"</code> it selects:</p> <ul> <li>The first <code>pts</code> indices if <code>len(fps_index) &gt; pts</code>, or</li> <li>All of <code>fps_index</code> otherwise.</li> </ul> <p>All per-point arrays of length <code>N</code> (except those whose key contains <code>\"origin\"</code>) are then indexed with this subset.</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>str</code> <p>Name of the scalar field in <code>data_dict</code> used to determine the dynamic number of points. Common choices might include <code>\"area\"</code>, <code>\"volume\"</code>, etc. Defaults to <code>\"area\"</code>.</p> <code>'area'</code> <code>pts_ratio</code> <code>float</code> <p>Multiplicative factor that maps the scalar value <code>data_dict[key]</code> to a target number of points:</p> <pre><code>pts = int(data_dict[key] * pts_ratio)\n</code></pre> <p>For example, if <code>data_dict[\"area\"] = 1.8</code> and <code>pts_ratio</code> is <code>8192 / 1.8</code>, then <code>pts \u2248 8192</code>. Defaults to <code>8192 / 1.8</code>.</p> <code>8192 / 1.8</code> <p>FPS PC with surface area adjusted points</p> <p> </p>"},{"location":"sample/#augmentation_class.SamplingDynamic.__call__","title":"<code>__call__(data_dict)</code>","text":"<p>Apply dynamic FPS-based subsampling to <code>\"coord\"</code> and aligned fields.</p> <p>Parameters:</p> Name Type Description Default <code>data_dict</code> <code>dict</code> <p>Input dictionary containing at least <code>\"coord\"</code>, <code>self.key</code>, and <code>\"fps_index\"</code>.</p> required <p>Returns:</p> Name Type Description <code>dict</code> <code>dict</code> <p>The same dictionary with <code>\"coord\"</code> and aligned per-point attributes subsampled according to the</p> <code>dict</code> <p>dynamically chosen number of points.</p>"},{"location":"sample/#spherecrop","title":"SphereCrop","text":"<p>Crop a point cloud to a fixed number of points using a spherical region.</p> <p>This transform expects a dictionary containing:</p> <ul> <li><code>\"coord\"</code>: NumPy array of shape (N, 3) with point coordinates.</li> <li>Optionally other per-point arrays (e.g., <code>\"norm\"</code>, <code>\"color\"</code>, <code>\"label\"</code>) that have length N along the first dimension.</li> </ul> <p>The target number of points can be controlled either by an absolute cap (<code>point_max</code>) or a relative rate (<code>sample_rate</code>):</p> <ul> <li>If <code>sample_rate</code> is not <code>None</code>, the effective maximum is <code>point_max_eff = int(sample_rate * N)</code>.</li> <li>Otherwise, the fixed <code>point_max</code> value is used.</li> </ul> <p>The center of the crop is chosen according to <code>mode</code>:</p> <ul> <li><code>\"random\"</code>: use a randomly selected point as center.</li> <li><code>\"center\"</code>: use the point at index <code>N // 2</code> as center (e.g., middle in   the current ordering).</li> </ul> <p>If <code>N &lt;= point_max_eff</code>, no cropping is applied.</p> <p>Parameters:</p> Name Type Description Default <code>point_max</code> <code>int</code> <p>Maximum number of points to keep if<code>sample_rate</code> is <code>None</code>. Defaults to 80,000.</p> <code>80000</code> <code>sample_rate</code> <code>float | None</code> <p>If provided, the effective maximum number of points is computed as:</p> <pre><code>point_max_eff = int(sample_rate * N)\n</code></pre> <p>where <code>N</code> is the current number of points. This allows dataset-dependent cropping. If <code>None</code>, the fixed <code>point_max</code> is used instead. Defaults to <code>None</code>.</p> <code>None</code> <code>mode</code> <code>str</code> <p>Strategy to select the crop center. Must be <code>\"random\"</code> or <code>\"center\"</code>.</p> <ul> <li><code>\"random\"</code>: center is a random point from <code>\"coord\"</code>.</li> <li><code>\"center\"</code>: center is <code>coord[N // 2]</code>.</li> </ul> <p>Defaults to <code>\"random\"</code>.</p> <code>'random'</code> <p>Sphere Crop PC</p> <p> </p>"},{"location":"sample/#augmentation_class.SphereCrop.__call__","title":"<code>__call__(data_dict)</code>","text":"<p>Apply spherical cropping to the <code>\"coord\"</code> entry in <code>data_dict</code>.</p> <p>Parameters:</p> Name Type Description Default <code>data_dict</code> <code>dict</code> <p>Input dictionary that must contain a <code>\"coord\"</code> key with a NumPy array of shape (N, 3). Any other entry whose value is a NumPy array or <code>Sequence</code> of length N and whose key does not contain <code>\"origin\"</code> will be permuted with the same shuffle indices.</p> required <p>Returns:</p> Name Type Description <code>dict</code> <code>dict</code> <p>The same dictionary with <code>\"coord\"</code> and aligned per-point attributes cropped to at most <code>point_max_eff</code></p> <code>dict</code> <p>points, if applied.</p>"},{"location":"sample/#gridsample","title":"GridSample","text":"<p>Grid-based voxelization and optional per-voxel sampling/pooling.</p> <p>This transform expects a dictionary containing:</p> <ul> <li><code>\"coord\"</code>: NumPy array of shape (N, 3) with point coordinates.</li> <li>Optionally per-point attributes (e.g. <code>\"norm\"</code>, <code>\"color\"</code>, <code>\"label\"</code>) that have length N along the first dimension.</li> </ul> <p>It first normalizes coordinates by subtracting the global minimum so that all coordinates are non-negative, then assigns each point to a 3D grid cell (voxel) either by:</p> <ul> <li>a fixed cell size (<code>grid_size</code>), or</li> <li>a fixed number of cells per axis (<code>grid_number</code>).</li> </ul> <p>The per-point integer voxel index is stored in <code>\"grid_coord\"</code>.</p> <p>Optionally, it can:</p> <ul> <li> <p>Store per-point relative coordinates within each voxel in <code>\"relative_coord\"</code>, normalized to approximately <code>[-1, 1]</code> per axis.</p> </li> <li> <p>Perform voxel-level sampling/aggregation:</p> </li> <li> <p><code>method=\"random\"</code>:</p> <ul> <li><code>mode=\"train\"</code>: pick one random point per voxel.</li> <li><code>mode=\"test\"</code>: generate up to <code>max_count</code> \u201cviews\u201d, each view containing one point per voxel (cycling through the points in each voxel). Returns a list of dictionaries.</li> </ul> </li> <li> <p><code>method=\"mean\"</code>:</p> <ul> <li>Average features per voxel and replace <code>\"coord\"</code>, <code>\"norm\"</code>, <code>\"color\"</code> accordingly.</li> <li>For <code>\"label\"</code>:</li> <li>If integer dtype \u2192 take majority vote per voxel.</li> <li>Else \u2192 average values per voxel.</li> </ul> </li> </ul> <p>Parameters:</p> Name Type Description Default <code>grid_size</code> <code>float</code> <p>Fixed grid cell size along each axis when <code>grid_number</code> is <code>None</code>. The same size is used for x, y, z. Coordinates are voxelized as:</p> <pre><code>grid_coord = floor((coord - coord_min) / grid_size)\n</code></pre> <p>Defaults to 0.02.</p> <code>0.02</code> <code>grid_number</code> <code>tuple[int] | None</code> <p>If not <code>None</code>, use a fixed number of cells per axis instead of a fixed size. In that case, the effective grid size is computed as:</p> <pre><code>grid_size = coord_norm.max(axis=0) / grid_number\n</code></pre> <p>and voxel indices are clipped to <code>[0, grid_number-1]</code>. Defaults to <code>None</code>.</p> <code>None</code> <code>sampling</code> <code>bool</code> <p>Whether to perform per-voxel sampling or pooling. If False, the transform only computes <code>\"grid_coord\"</code> (and <code>\"relative_coord\"</code> if <code>return_relative=True</code>) and does not change the number of points. Defaults to True.</p> <code>True</code> <code>method</code> <code>str</code> <p>Sampling/pooling strategy when <code>sampling=True</code>. Supported values:</p> <ul> <li><code>\"random\"</code>: per-voxel random selection.</li> <li><code>\"mean\"</code>: per-voxel averaging of features (and label fusion).</li> </ul> <p>Defaults to <code>\"random\"</code>.</p> <code>'random'</code> <code>return_relative</code> <code>bool</code> <p>If True, adds <code>\"relative_coord\"</code> to <code>data_dict</code>, containing per-point offsets relative to the voxel center, normalized to approximately <code>[-1, 1]</code> per axis. Defaults to False.</p> <code>False</code> <code>mode</code> <code>str</code> <p>Behavior mode for <code>method=\"random\"</code>. * <code>\"train\"</code>: returns a single dictionary, selecting one random point per voxel. * <code>\"test\"</code>: returns a list of dictionaries, each containing one point per voxel, cycling through all points within each voxel.</p> <p>Defaults to <code>\"train\"</code>.</p> <code>'train'</code> <p>Grid Sample on PC</p> <p>Original PC vs Grid Sample (random select, fixed grid size)</p> <p> </p> <p>Grid Sample (random select, fixed grid numbers) vs Grid Sample (mean, fixed grid size)</p> <p> </p>"},{"location":"sample/#augmentation_class.GridSample.__call__","title":"<code>__call__(data_dict)</code>","text":"<p>Apply grid voxelization and optional voxel-wise sampling/pooling.</p> <p>Parameters:</p> Name Type Description Default <code>data_dict</code> <code>dict</code> <p>Input dictionary that must contain <code>\"coord\"</code>. Optionally <code>\"norm\"</code>, <code>\"color\"</code>, <code>\"label\"</code>, etc.</p> required <p>Returns:</p> Type Description <code>dict | list</code> <p>dict | list[dict]: * If <code>sampling=False</code> or <code>method=\"mean\"</code> or <code>mode=\"train\"</code>:   returns a single modified <code>data_dict</code>. * If <code>method=\"random\"</code> and <code>mode=\"test\"</code>: returns a list of dictionaries, each representing a   different per-voxel sampling pass.</p>"},{"location":"sample_mesh/","title":"SamplingMesh","text":"<p>Functions to sample point cloud from the mesh</p>"},{"location":"sample_mesh/#farthest_point_sample","title":"farthest_point_sample","text":"<p>Select points using Farthest Point Sampling (FPS).</p> <p>This function selects <code>npoint</code> indices from an input point cloud such that each newly selected point is as far as possible (in Euclidean distance) from the already selected set. Only the first three dimensions of <code>point</code> are used as XYZ coordinates.</p> <p>Parameters:</p> Name Type Description Default <code>point</code> <code>ndarray</code> <p>np.ndarray Point cloud array of shape (N, D). Only the first three columns are interpreted as XYZ coordinates, so D must be at least 3.</p> required <code>npoint</code> <code>int</code> <p>np.ndarray Number of points to sample. Must satisfy 1 &lt;= npoint &lt;= N.</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>np.ndarray: Array of shape (npoint,) containing the indices of the sampled points (dtype int32).</p> <p>Raises:</p> Type Description <code>AssertionError</code> <p>If <code>npoint</code> is greater than the number of input points N.</p> Source code in <code>src\\utils.py</code> <pre><code>def farthest_point_sample(point: np.ndarray, npoint: int) -&gt; np.ndarray:\n    \"\"\"Select points using Farthest Point Sampling (FPS).\n\n    This function selects `npoint` indices from an input point cloud such that\n    each newly selected point is as far as possible (in Euclidean distance)\n    from the already selected set. Only the first three dimensions of\n    `point` are used as XYZ coordinates.\n\n    Args:\n        point: np.ndarray\n            Point cloud array of shape (N, D). Only the first three columns\n            are interpreted as XYZ coordinates, so D must be at least 3.\n        npoint: np.ndarray\n            Number of points to sample. Must satisfy 1 &lt;= npoint &lt;= N.\n\n    Returns:\n        np.ndarray:\n            Array of shape (npoint,) containing the indices of the\n            sampled points (dtype int32).\n\n    Raises:\n        AssertionError: If `npoint` is greater than the number of input points N.\n    \"\"\"\n    N, D = point.shape\n    assert N &gt;= npoint\n    xyz = point[:, :3]\n    centroids = np.zeros((npoint,))\n    distance = np.ones((N,)) * 1e10\n    farthest = np.random.randint(0, N)\n\n    for i in range(npoint):\n        centroids[i] = farthest\n        centroid = xyz[farthest, :]\n        dist = np.sum((xyz - centroid) ** 2, -1)\n        mask = dist &lt; distance\n        distance[mask] = dist[mask]\n        farthest = np.argmax(distance, -1)\n\n    return centroids.astype(np.int32)\n</code></pre> <p>View source on GitHub</p>"},{"location":"sample_mesh/#area_and_normal","title":"area_and_normal","text":"<p>Compute per-face normals and areas for a triangular mesh.</p> <p>Given mesh vertices and triangular faces, this function computes the outward face normals (unit vectors) and the corresponding face areas. Faces with zero area (degenerate triangles) receive a zero normal.</p> <p>Parameters:</p> Name Type Description Default <code>vertices</code> <code>ndarray</code> <p>np.ndarray Array of shape (N, 3) containing vertex coordinates (XYZ).</p> required <code>faces</code> <code>ndarray</code> <p>np.ndarray Array of shape (M, 3) containing vertex indices for each triangular face. Each row is a triplet of integer indices into <code>vertices</code>.</p> required <p>Returns:</p> Type Description <code>tuple[ndarray, ndarray]</code> <p>tuple[np.ndarray, np.ndarray]: - face_normals: Array of shape (M, 3) with unit normal vectors   for each face. Degenerate faces have a zero vector. - face_areas: Array of shape (M,) with the area of each face.</p> Source code in <code>src\\utils.py</code> <pre><code>def area_and_normal(vertices: np.ndarray, faces: np.ndarray) -&gt; tuple[np.ndarray, np.ndarray]:\n    \"\"\"Compute per-face normals and areas for a triangular mesh.\n\n    Given mesh vertices and triangular faces, this function computes the\n    outward face normals (unit vectors) and the corresponding face areas.\n    Faces with zero area (degenerate triangles) receive a zero normal.\n\n    Args:\n        vertices: np.ndarray\n            Array of shape (N, 3) containing vertex coordinates (XYZ).\n        faces: np.ndarray\n            Array of shape (M, 3) containing vertex indices for each\n            triangular face. Each row is a triplet of integer indices into ``vertices``.\n\n    Returns:\n        tuple[np.ndarray, np.ndarray]:\n            - face_normals: Array of shape (M, 3) with unit normal vectors\n              for each face. Degenerate faces have a zero vector.\n            - face_areas: Array of shape (M,) with the area of each face.\n    \"\"\"\n    cross_product = np.cross(vertices[faces[:, 1]] - vertices[faces[:, 0]],\n                             vertices[faces[:, 2]] - vertices[faces[:, 1]])   # [M, 3]\n    cross_product_normal = np.sqrt(np.sum(cross_product ** 2, axis=1))        # [M, ]\n    cross_product_normal_broadcast = cross_product_normal[:, np.newaxis]      # [M, 1]\n    # if cross product normal is 0, the result is zero\n    face_normals = np.divide(cross_product, cross_product_normal_broadcast,\n                             out=np.zeros_like(cross_product), where=cross_product_normal_broadcast != 0)   # [M ,3]\n    face_areas = cross_product_normal * 0.5   # [M, ]\n    return face_normals, face_areas\n</code></pre>"},{"location":"sample_mesh/#sample_points_with_normal_features","title":"sample_points_with_normal_features","text":"<p>Sample points on a mesh surface with associated face normals.</p> <p>Points are sampled on the triangular mesh defined by <code>vertices</code> and <code>faces</code>. Triangles are chosen with probability proportional to their surface area, and points are sampled uniformly within each selected triangle using random barycentric coordinates. The function returns both the sampled 3D points and the corresponding per-point normals, taken from the face normals.</p> <p>Parameters:</p> Name Type Description Default <code>vertices</code> <code>ndarray</code> <p>Array of shape (V, 3) containing the mesh vertex coordinates (XYZ).</p> required <code>faces</code> <code>ndarray</code> <p>Array of shape (F, 3) containing vertex indices for each triangular face. Each row is a triplet of integer indices into <code>vertices</code>.</p> required <code>face_normals</code> <code>ndarray</code> <p>Array of shape (F, 3) with the normal vector for each face, typically unit-length.</p> required <code>face_areas</code> <code>ndarray</code> <p>Array of shape (F,) with the area of each face.</p> required <code>n_points</code> <code>int</code> <p>Number of points to sample on the mesh surface.</p> required <p>Returns:</p> Type Description <code>tuple[ndarray, ndarray]</code> <p>tuple[np.ndarray, np.ndarray]: - sampled_points: Array of shape (n_points, 3) with the sampled   XYZ coordinates on the mesh surface. - sampled_normals: Array of shape (n_points, 3) with the   corresponding normal vectors (one per sampled point), copied   from the selected face normals.</p> Source code in <code>src\\utils.py</code> <pre><code>def sample_points_with_normal_features(vertices: np.ndarray, faces: np.ndarray, face_normals: np.ndarray,\n                                       face_areas: np.ndarray, n_points: int) -&gt; tuple[np.ndarray, np.ndarray]:\n    \"\"\"Sample points on a mesh surface with associated face normals.\n\n        Points are sampled on the triangular mesh defined by ``vertices`` and\n        ``faces``. Triangles are chosen with probability proportional to their\n        surface area, and points are sampled uniformly within each selected\n        triangle using random barycentric coordinates. The function returns\n        both the sampled 3D points and the corresponding per-point normals,\n        taken from the face normals.\n\n        Args:\n            vertices: Array of shape (V, 3) containing the mesh vertex\n                coordinates (XYZ).\n            faces: Array of shape (F, 3) containing vertex indices for each\n                triangular face. Each row is a triplet of integer indices into\n                ``vertices``.\n            face_normals: Array of shape (F, 3) with the normal vector for\n                each face, typically unit-length.\n            face_areas: Array of shape (F,) with the area of each face.\n            n_points: Number of points to sample on the mesh surface.\n\n        Returns:\n            tuple[np.ndarray, np.ndarray]:\n                - sampled_points: Array of shape (n_points, 3) with the sampled\n                  XYZ coordinates on the mesh surface.\n                - sampled_normals: Array of shape (n_points, 3) with the\n                  corresponding normal vectors (one per sampled point), copied\n                  from the selected face normals.\n        \"\"\"\n    prob = face_areas / np.sum(face_areas)\n    index = np.random.choice(faces.shape[0], size=n_points, replace=True, p=prob)\n    sampled_faces = faces[index]\n    sampled_face_normals = face_normals[index]  # [n_points, 3]\n\n    sampled_points = []\n    for sampled_face in sampled_faces:\n        v1_idx, v2_idx, v3_idx = sampled_face\n        v1, v2, v3 = vertices[v1_idx], vertices[v2_idx], vertices[v3_idx]\n        s, t = sorted([random.random(), random.random()])\n        f_v = lambda i: s * v1[i] + (t - s) * v2[i] + (1 - t) * v3[i]\n\n        sampled_points.append([f_v(0), f_v(1), f_v(2)])\n    sampled_points = np.array(sampled_points)\n    return sampled_points, sampled_face_normals\n</code></pre>"},{"location":"sample_mesh/#process_file","title":"process_file","text":"Source code in <code>src\\create_pc.py</code> <pre><code>def process_file(file_path, saved_folder, degrees=None, n_pts=10000, scale=10.0):\n    file_id = \"tmp\"\n    saved_path = os.path.join(str(saved_folder), f\"{file_id}.pth\")\n    ms = simple_clean(file_path)\n    ms.apply_filter(\"compute_matrix_from_scaling_or_normalization\",\n                    uniformflag=True, axisx=1. / scale, axisy=1. / scale, axisz=1. / scale, scalecenter=\"origin\")\n    ms.apply_filter(\"apply_matrix_freeze\")\n\n    data = meshlab_to_open3d(ms)\n    data.orient_triangles()\n    data.remove_unreferenced_vertices()\n    # center and rotate\n    data = move_to_center(data, middle=True, in_place=True)\n    if degrees:\n        for d in degrees:\n            data = rotate_data_3d(data, degrees=d, in_place=True)\n    data = move_to_center(data, middle=True, in_place=True)\n\n    vertices = np.array(data.vertices)\n    faces = np.array(data.triangles)\n    data.compute_vertex_normals()\n    normals = np.array(data.vertex_normals)\n    data.compute_triangle_normals()\n    face_normals = np.array(data.triangle_normals)\n    surface_area = data.get_surface_area()\n    _, face_areas = area_and_normal(vertices, faces)\n\n\n    N = vertices.shape[0]\n    original_index = np.arange(N)\n    if N &lt; n_pts:\n        sampled_points, sampled_face_normals = sample_points_with_normal_features(vertices, faces, face_normals, face_areas, n_points=n_pts - N)\n        coord = np.concatenate((vertices, sampled_points), axis=0)\n        norm = np.concatenate((normals, sampled_face_normals), axis=0)\n\n    else:\n        coord = vertices\n        norm = normals\n    # fps\n    fps_index = farthest_point_sample(coord, n_pts)\n    norm = preprocessing.normalize(norm, norm='l2')\n    res = dict(coord=coord, norm=norm, fps_index=fps_index, original_index=original_index, area=surface_area)\n    torch.save(res, saved_path)\n</code></pre> <p>Extract PC from Mesh</p> <p> </p>"},{"location":"tensor/","title":"Tensor","text":"<p>Classes for transferring point cloud (NumPy) -&gt; PyTorch Tensor</p>"},{"location":"tensor/#totensor","title":"ToTensor","text":"<p>Recursively convert NumPy arrays, scalars, and container structures to PyTorch tensors.</p> <p>This transform is designed to work on:</p> <ul> <li>Individual values:</li> <li><code>torch.Tensor</code>: returned as-is.</li> <li><code>int</code> \u2192 <code>LongTensor([value])</code>.</li> <li><code>float</code> \u2192 <code>FloatTensor([value])</code>.</li> <li><code>str</code>: returned as-is (strings are not converted).</li> <li><code>np.ndarray</code> with:<ul> <li>boolean dtype \u2192 <code>torch.from_numpy(arr)</code> (bool tensor),</li> <li>integer dtype \u2192 <code>torch.from_numpy(arr).long()</code>,</li> <li>float dtype \u2192 <code>torch.from_numpy(arr).float()</code>.</li> </ul> </li> <li>Containers:</li> <li><code>Mapping</code> (e.g. <code>dict</code>): converts each value recursively, preserving keys.</li> <li><code>Sequence</code> (e.g. <code>list</code>, <code>tuple</code>): converts each element recursively and     returns a Python <code>list</code> of tensors/converted items.</li> </ul> <p>Any unsupported type will raise a <code>TypeError</code>.</p> <p>Typical usage is at the end of a preprocessing pipeline, to convert a nested sample dictionary (coords, features, labels) from NumPy to tensors.</p>"},{"location":"tensor/#augmentation_class.ToTensor.__call__","title":"<code>__call__(data)</code>","text":"<p>Convert input data (and nested contents) to PyTorch tensors. Args:     data: Arbitrary input to convert. Can be a scalar, NumPy array,         tensor, mapping (e.g. dict), or sequence (e.g. list/tuple).</p> <p>Returns:</p> Type Description <code>Any</code> <p>Converted object where all supported leaves are PyTorch tensors,</p> <code>Any</code> <p>and the original container structure (dict/list) is preserved.</p> <p>Raises:</p> Type Description <code>TypeError</code> <p>If <code>data</code> (or some nested leaf) has a type that cannot be converted to a tensor.</p>"},{"location":"tensor/#finalfeatures","title":"FinalFeatures","text":"<p>Assemble a final feature tensor and manage bookkeeping fields in a sample dict.</p> <p>This transform is typically used at the end of a preprocessing pipeline to:</p> <ol> <li>Build a unified feature array under the key <code>\"feat\"</code> by selecting and    concatenating one or more existing fields from <code>data_dict</code>.</li> <li>Optionally remove some intermediate fields (e.g., <code>\"norm\"</code>,    auxiliary features) to save memory.</li> <li>Optionally add offset fields (<code>\"offset\"</code>, <code>\"fps_offset\"</code>) that are    useful when batching variable-length point clouds.</li> </ol> <p>Behavior:</p> <ul> <li>Feature construction:</li> <li>If <code>feat</code> is a string, <code>data_dict[\"feat\"]</code> is set to <code>data_dict[feat]</code>.</li> <li>If <code>feat</code> is a list/tuple of strings, the corresponding arrays are concatenated along the last dimension:<pre><code>feat = np.concatenate([data_dict[name] for name in feat], axis=-1)\n</code></pre> </li> </ul> <p>All specified feature names must exist in <code>data_dict</code>.</p> <ul> <li>Field removal:</li> <li>If <code>remove</code> is a string, that key is deleted from <code>data_dict</code>.</li> <li>If <code>remove</code> is a list/tuple of strings, each corresponding key is deleted.</li> <li> <p>All specified keys must exist in <code>data_dict</code>.</p> </li> <li> <p>Offsets:</p> </li> <li> <p>If <code>add_offset</code> is True and <code>\"offset\"</code> is not already present, then:</p> <pre><code>data_dict[\"offset\"] = len(data_dict[\"coord\"])\n</code></pre> <p>This is often interpreted as the number of points in this sample.   - If <code>add_fps_offset</code> is True and <code>\"fps_offset\"</code> is not present but <code>\"fps_index\"</code> exists, then:</p> <pre><code>data_dict[\"fps_offset\"] = len(data_dict[\"fps_index\"])\n</code></pre> <p>This is typically the number of FPS (farthest-point sampling) indices for this sample.</p> </li> </ul> <p>Parameters:</p> Name Type Description Default <code>feat</code> <code>str or sequence of str</code> <p>Name(s) of fields in <code>data_dict</code> to be used as final features. If a sequence, the corresponding arrays are concatenated along the last dimension and stored in <code>data_dict[\"feat\"]</code>. If <code>None</code>, no feature tensor is constructed. Defaults to <code>\"coord\"</code>.</p> <code>'coord'</code> <code>remove</code> <code>str or sequence of str</code> <p>Name(s) of fields to delete from <code>data_dict</code> after (optional) feature construction. This is useful to drop intermediate fields (e.g., <code>\"norm\"</code>) that are no longer needed. If <code>None</code>, no keys are removed. Defaults to <code>\"norm\"</code>.</p> <code>'norm'</code> <code>add_offset</code> <code>bool</code> <p>If True and <code>\"offset\"</code> is not already present, add an integer offset equal to <code>len(data_dict[\"coord\"])</code>. Defaults to True.</p> <code>True</code> <code>add_fps_offset</code> <code>bool</code> <p>If True, <code>\"fps_offset\"</code> is not present, and <code>\"fps_index\"</code> exists, add an integer offset equal to <code>len(data_dict[\"fps_index\"])</code>. Defaults to True.</p> <code>True</code>"},{"location":"tensor/#augmentation_class.FinalFeatures.__call__","title":"<code>__call__(data_dict)</code>","text":"<p>Construct the final feature array and update bookkeeping fields.</p> <p>Parameters:</p> Name Type Description Default <code>data_dict</code> <code>dict</code> <p>Sample dictionary containing at least the keys referenced by <code>self.feat</code> (if not <code>None</code>), plus <code>\"coord\"</code> (used for <code>offset</code>) and optionally <code>\"fps_index\"</code> (used for <code>fps_offset</code>).</p> required <p>Returns:</p> Name Type Description <code>dict</code> <code>dict</code> <p>The same dictionary, with: * a new <code>\"feat\"</code> field (if requested), * selected keys removed, * and optional <code>\"offset\"</code> / <code>\"fps_offset\"</code> fields added.</p>"}]}