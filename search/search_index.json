{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"Welcome to Point Cloud operations","text":"<p>Welcome to the docs.</p> <ul> <li>This document describes Python-based methods for point cloud processing. Before you begin, make sure the following packages are installed:</li> </ul> <pre><code>pip install numpy torch scipy scikit-learn open3d trimesh pymeshlab matplotlib addict\n</code></pre> <ul> <li>There are different types of methods: Sampling, Coordinate, Normal, Color, Noise etc.</li> <li>Example result images are included in the documentation to illustrate how each transform affects the point cloud. Images are generated from the open3d gui with screenshot.</li> </ul>"},{"location":"about/","title":"About","text":"<p>This project is majorly based on the functions and design ideas from Pointcept, with:</p> <ul> <li> <p>A subset of their point cloud operation utilities</p> </li> <li> <p>Some extra methods specific to this project</p> </li> <li> <p>Added visualization and documentation for easier review</p> </li> </ul> <p>If you\u2019re interested in a more complete and large-scale point cloud framework, please check out the original Pointcept repository.</p>"},{"location":"color/","title":"Color","text":"<p>Classes for point colors</p>"},{"location":"color/#normalizecolor","title":"NormalizeColor","text":"<p>Normalize point-wise color features into a target value range <code>[low, high]</code>.</p> <p>This transform expects a dictionary containing:</p> <ul> <li><code>\"color\"</code>: NumPy array of shape (N, 3) with point color values.</li> </ul> <p>If <code>range255</code> is True, input colors are assumed to be in <code>[0, 255]</code> and are first scaled to <code>[0, 1]</code> by dividing by 255. Otherwise, they are assumed to already be in <code>[0, 1]</code>.</p> <p>The normalized <code>[0, 1]</code> values are then mapped linearly to <code>[low, high]</code> such that:</p> <ul> <li>0 \u2192 low</li> <li>1 \u2192 high</li> </ul> <p>Parameters:</p> Name Type Description Default <code>low</code> <code>float</code> <p>Lower bound of the target color range. Defaults to -1.0.</p> <code>-1.0</code> <code>high</code> <code>float</code> <p>Upper bound of the target color range. Must be greater than <code>low</code>. Defaults to 1.0.</p> <code>1.0</code> <code>range255</code> <code>bool</code> <p>Whether the input color values are in <code>[0, 255]</code>. If True, values are divided by 255.0 before mapping. If False, values are used as-is (assumed to be in <code>[0, 1]</code>). Defaults to False.</p> <code>False</code> Source code in <code>src\\augmentation_class.py</code> <pre><code>@TRANSFORMS.register()\nclass NormalizeColor:\n    \"\"\"Normalize point-wise color features into a target value range ``[low, high]``.\n\n    This transform expects a dictionary containing:\n\n    * `\"color\"`: NumPy array of shape (N, 3) with point color values.\n\n    If `range255` is True, input colors are assumed to be in `[0, 255]` and are\n    first scaled to `[0, 1]` by dividing by 255. Otherwise, they are assumed\n    to already be in `[0, 1]`.\n\n    The normalized `[0, 1]` values are then mapped linearly to `[low, high]`\n    such that:\n\n    * 0 \u2192 low\n    * 1 \u2192 high\n\n    Args:\n        low (float, optional):\n            Lower bound of the target color range.\n            Defaults to -1.0.\n        high (float, optional):\n            Upper bound of the target color range. Must be greater than `low`.\n            Defaults to 1.0.\n        range255 (bool, optional):\n            Whether the input color values are in `[0, 255]`. If True, values are divided by 255.0 before mapping.\n            If False, values are used as-is (assumed to be in `[0, 1]`).\n            Defaults to False.\n    \"\"\"\n    def __init__(self, low: float = -1., high: float = 1., range255=False):\n        assert high &gt; low\n        self.low = low\n        self.high = high\n        self.range255 = range255\n\n    def __call__(self, data_dict: dict) -&gt; dict:\n        \"\"\"Normalize the `\"color\"` entry in `data_dict` into `[low, high]`.\n\n        Args:\n            data_dict (dict): Input dictionary that must contain a `\"color\"` key with a NumPy array of shape (N, 3)\n                representing point color values.\n\n        Returns:\n            dict: The same dictionary with `\"color\"` normalized into `[low, high]`, if present.\n        \"\"\"\n        if \"color\" in data_dict.keys():\n            # data_dict[\"color\"] = data_dict[\"color\"] / 127.5 - 1\n            normalized_color = data_dict[\"color\"] / 255. if self.range255 else data_dict[\"color\"]  # [0, 1]\n            tmp = (self.high - self.low)\n            data_dict[\"color\"] = (normalized_color - 1.0) * tmp + self.high\n        return data_dict\n</code></pre>"},{"location":"color/#augmentation_class.NormalizeColor.__call__","title":"<code>__call__(data_dict)</code>","text":"<p>Normalize the <code>\"color\"</code> entry in <code>data_dict</code> into <code>[low, high]</code>.</p> <p>Parameters:</p> Name Type Description Default <code>data_dict</code> <code>dict</code> <p>Input dictionary that must contain a <code>\"color\"</code> key with a NumPy array of shape (N, 3) representing point color values.</p> required <p>Returns:</p> Name Type Description <code>dict</code> <code>dict</code> <p>The same dictionary with <code>\"color\"</code> normalized into <code>[low, high]</code>, if present.</p> Source code in <code>src\\augmentation_class.py</code> <pre><code>def __call__(self, data_dict: dict) -&gt; dict:\n    \"\"\"Normalize the `\"color\"` entry in `data_dict` into `[low, high]`.\n\n    Args:\n        data_dict (dict): Input dictionary that must contain a `\"color\"` key with a NumPy array of shape (N, 3)\n            representing point color values.\n\n    Returns:\n        dict: The same dictionary with `\"color\"` normalized into `[low, high]`, if present.\n    \"\"\"\n    if \"color\" in data_dict.keys():\n        # data_dict[\"color\"] = data_dict[\"color\"] / 127.5 - 1\n        normalized_color = data_dict[\"color\"] / 255. if self.range255 else data_dict[\"color\"]  # [0, 1]\n        tmp = (self.high - self.low)\n        data_dict[\"color\"] = (normalized_color - 1.0) * tmp + self.high\n    return data_dict\n</code></pre>"},{"location":"color/#chromaticautocontrast","title":"ChromaticAutoContrast","text":"<p>Apply chromatic auto-contrast to point colors with optional blending.</p> <p>This transform expects a dictionary containing:</p> <ul> <li><code>\"color\"</code>: NumPy array of shape (N, 3) with point color values.</li> </ul> <p>The transform computes per-channel minimum and maximum over the whole point set, linearly stretches each channel to the target range, and then blends this auto-contrasted result with the original colors using a <code>blend_factor</code>.</p> <p>Parameters:</p> Name Type Description Default <code>blend_factor</code> <code>float | None</code> <p>Weight used to blend the original colors with the auto-contrasted colors:</p> <pre><code>out = (1 - blend_factor) * original + blend_factor * contrasted\n</code></pre> <p>If a float in [0, 1], the same value is used for every call. If <code>None</code>, a new random value in [0, 1] is sampled on each call. Defaults to <code>None</code>.</p> <code>None</code> <code>range255</code> <code>bool</code> <p>Whether the input color values are in <code>[0, 255]</code>. If True, the auto-contrast maps into <code>[0, 255]</code>. If False, it maps into <code>[0, 1]</code>. Defaults to False.</p> <code>False</code> <code>apply_p</code> <code>float</code> <p>Probability of applying the auto-contrast. Defaults to 1.0.</p> <code>1.0</code> Source code in <code>src\\augmentation_class.py</code> <pre><code>@TRANSFORMS.register()\nclass ChromaticAutoContrast:\n    \"\"\"Apply chromatic auto-contrast to point colors with optional blending.\n\n    This transform expects a dictionary containing:\n\n    * `\"color\"`: NumPy array of shape (N, 3) with point color values.\n\n    The transform computes per-channel minimum and maximum over the whole point set,\n    linearly stretches each channel to the target range, and then blends this auto-contrasted\n    result with the original colors using a `blend_factor`.\n\n    Args:\n        blend_factor (float | None, optional):\n            Weight used to blend the original colors with the auto-contrasted colors:\n\n                out = (1 - blend_factor) * original + blend_factor * contrasted\n\n            If a float in [0, 1], the same value is used for every call. If ``None``, a new random\n            value in [0, 1] is sampled on each call.\n            Defaults to ``None``.\n        range255 (bool, optional):\n            Whether the input color values are in `[0, 255]`. If True, the auto-contrast maps into `[0, 255]`. If\n            False, it maps into `[0, 1]`.\n            Defaults to False.\n        apply_p (float, optional):\n            Probability of applying the auto-contrast.\n            Defaults to 1.0.\n    \"\"\"\n    def __init__(self, blend_factor: float = None, range255=False, apply_p: float = 1.0):\n        self.blend_factor = blend_factor\n        self.range255 = range255\n        self.apply_p = apply_p\n\n\n    def __call__(self, data_dict: dict) -&gt; dict:\n        \"\"\"Apply chromatic auto-contrast to the first 3 color channels.\n\n        Args:\n            data_dict (dict): Input dictionary that must contain a `\"color\"` key with a NumPy array of shape (N, 3)\n                representing point color values.\n\n        Returns:\n            dict: The same dictionary with `\"color\"` updated in-place, if applied.\n        \"\"\"\n\n        if random.random() &gt; self.apply_p:\n            return data_dict\n\n        if \"color\" in data_dict.keys():\n            dtype = data_dict[\"color\"].dtype\n            if self.range255:\n                target_range = 255.0\n            else:\n                target_range = 1.0\n\n            # choose blend for this call\n            blend_factor = np.random.rand() if self.blend_factor is None else self.blend_factor\n\n            # Apply autocontrast calculation\n            lo = np.min(data_dict[\"color\"], axis=0, keepdims=True)\n            hi = np.max(data_dict[\"color\"], axis=0, keepdims=True)\n\n            # Prevent division by zero if hi == lo\n            scale = target_range / (hi - lo + 1e-6)  # Add small epsilon for stability\n\n            # Apply contrast adjustment to the first 3 color channels\n            contrast_feat = (data_dict[\"color\"][:, :3] - lo[:, :3]) * scale[:, :3]\n\n            # Blend the original with the contrasted feature\n            # Ensure the blending maintains the data type\n            blended_color = (1 - blend_factor) * data_dict[\"color\"][:, :3] + blend_factor * contrast_feat\n\n            # Clip values to ensure they stay within the target range [0, target_range]\n            # and convert to the appropriate data type\n            data_dict[\"color\"][:, :3] = np.clip(blended_color, 0, target_range).astype(dtype)\n\n        return data_dict\n</code></pre> <p>Chromatic AutoContrast PC Colors</p> <p> </p>"},{"location":"color/#augmentation_class.ChromaticAutoContrast.__call__","title":"<code>__call__(data_dict)</code>","text":"<p>Apply chromatic auto-contrast to the first 3 color channels.</p> <p>Parameters:</p> Name Type Description Default <code>data_dict</code> <code>dict</code> <p>Input dictionary that must contain a <code>\"color\"</code> key with a NumPy array of shape (N, 3) representing point color values.</p> required <p>Returns:</p> Name Type Description <code>dict</code> <code>dict</code> <p>The same dictionary with <code>\"color\"</code> updated in-place, if applied.</p> Source code in <code>src\\augmentation_class.py</code> <pre><code>def __call__(self, data_dict: dict) -&gt; dict:\n    \"\"\"Apply chromatic auto-contrast to the first 3 color channels.\n\n    Args:\n        data_dict (dict): Input dictionary that must contain a `\"color\"` key with a NumPy array of shape (N, 3)\n            representing point color values.\n\n    Returns:\n        dict: The same dictionary with `\"color\"` updated in-place, if applied.\n    \"\"\"\n\n    if random.random() &gt; self.apply_p:\n        return data_dict\n\n    if \"color\" in data_dict.keys():\n        dtype = data_dict[\"color\"].dtype\n        if self.range255:\n            target_range = 255.0\n        else:\n            target_range = 1.0\n\n        # choose blend for this call\n        blend_factor = np.random.rand() if self.blend_factor is None else self.blend_factor\n\n        # Apply autocontrast calculation\n        lo = np.min(data_dict[\"color\"], axis=0, keepdims=True)\n        hi = np.max(data_dict[\"color\"], axis=0, keepdims=True)\n\n        # Prevent division by zero if hi == lo\n        scale = target_range / (hi - lo + 1e-6)  # Add small epsilon for stability\n\n        # Apply contrast adjustment to the first 3 color channels\n        contrast_feat = (data_dict[\"color\"][:, :3] - lo[:, :3]) * scale[:, :3]\n\n        # Blend the original with the contrasted feature\n        # Ensure the blending maintains the data type\n        blended_color = (1 - blend_factor) * data_dict[\"color\"][:, :3] + blend_factor * contrast_feat\n\n        # Clip values to ensure they stay within the target range [0, target_range]\n        # and convert to the appropriate data type\n        data_dict[\"color\"][:, :3] = np.clip(blended_color, 0, target_range).astype(dtype)\n\n    return data_dict\n</code></pre>"},{"location":"color/#chromaticautocontrastpercent","title":"ChromaticAutoContrastPercent","text":"<p>Apply percentile-based chromatic auto-contrast with optional blending.</p> <p>This transform expects a dictionary containing:</p> <ul> <li><code>\"color\"</code>: NumPy array of shape (N, 3) with point color values.</li> </ul> <p>This is similar to <code>ChromaticAutoContrast</code>, but instead of using the absolute min/max per channel, it uses the 1st and 99th percentiles as low/high boundaries. This makes the transform effective even when:</p> <ul> <li>The input already spans the full range (e.g., <code>lo=0.0</code>, <code>hi=1.0</code>), or</li> <li>There are outliers that would otherwise dominate the min/max.</li> </ul> <p>Parameters:</p> Name Type Description Default <code>blend_factor</code> <code>float | None</code> <p>Blending weight between the original and auto-contrasted colors. If a float in [0, 1], the same value is used for every call. If <code>None</code>, a new random value in [0, 1) is sampled on each call. Defaults to <code>None</code>.</p> <code>None</code> <code>range255</code> <code>bool</code> <p>Whether the input color values are in <code>[0, 255]</code>. If True, the auto-contrast maps into <code>[0, 255]</code>. If False, it maps into <code>[0, 1]</code>. Defaults to False.</p> <code>False</code> <code>apply_p</code> <code>float</code> <p>Probability of applying the auto-contrast. Defaults to 1.0.</p> <code>1.0</code> Source code in <code>src\\augmentation_class.py</code> <pre><code>@TRANSFORMS.register()\nclass ChromaticAutoContrastPercent:\n    \"\"\"Apply percentile-based chromatic auto-contrast with optional blending.\n\n    This transform expects a dictionary containing:\n\n    * `\"color\"`: NumPy array of shape (N, 3) with point color values.\n\n    This is similar to ``ChromaticAutoContrast``, but instead of using the absolute min/max per channel,\n    it uses the 1st and 99th percentiles as low/high boundaries. This makes the transform effective even when:\n\n    * The input already spans the full range (e.g., `lo=0.0`, `hi=1.0`), or\n    * There are outliers that would otherwise dominate the min/max.\n\n\n    Args:\n        blend_factor (float | None, optional):\n            Blending weight between the original and auto-contrasted colors. If a float in [0, 1], the\n            same value is used for every call. If ``None``, a new random value in [0, 1) is sampled on each call.\n            Defaults to ``None``.\n        range255 (bool, optional):\n            Whether the input color values are in `[0, 255]`. If True, the auto-contrast maps into `[0, 255]`.\n            If False, it maps into `[0, 1]`.\n            Defaults to False.\n        apply_p (float, optional):\n            Probability of applying the auto-contrast.\n            Defaults to 1.0.\n    \"\"\"\n    def __init__(self, blend_factor: float = None, range255=False, apply_p: float = 1.0):\n        self.blend_factor = blend_factor\n        self.range255 = range255\n        self.apply_p = apply_p\n\n\n    def __call__(self, data_dict: dict) -&gt; dict:\n        \"\"\"Apply percentile-based chromatic auto-contrast to the point color.\n        Args:\n            data_dict (dict): Input dictionary that must contain a `\"color\"` key with a NumPy array of shape (N, 3)\n                representing point color values.\n\n        Returns:\n            dict: The same dictionary with `\"color\"` updated in-place, if applied.\n        \"\"\"\n        if random.random() &gt; self.apply_p:\n            return data_dict\n\n        if \"color\" in data_dict.keys():\n            dtype = data_dict[\"color\"].dtype\n            if self.range255:\n                target_range = 255.0\n            else:\n                target_range = 1.0\n            blend_factor = np.random.rand() if self.blend_factor is None else self.blend_factor\n\n            # Apply autocontrast calculation, calculate 1% and 99% of the value among each channels\n            low_p, high_p = 1, 99\n            lo = np.percentile(data_dict[\"color\"][:, :3], low_p, axis=0, keepdims=True)\n            hi = np.percentile(data_dict[\"color\"][:, :3], high_p, axis=0, keepdims=True)\n\n            # Prevent division by zero if hi == lo\n            scale = target_range / (hi - lo + 1e-6)  # Add small epsilon for stability\n\n            # Apply contrast adjustment to the first 3 color channels\n            contrast_feat = (data_dict[\"color\"][:, :3] - lo[:, :3]) * scale[:, :3]\n\n            # Blend the original with the contrasted feature\n            # Ensure the blending maintains the data type\n            blended_color = (1 - blend_factor) * data_dict[\"color\"][:, :3] + blend_factor * contrast_feat\n\n            # Clip values to ensure they stay within the target range [0, target_range]\n            # and convert to the appropriate data type\n            data_dict[\"color\"][:, :3] = np.clip(blended_color, 0, target_range).astype(dtype)\n\n        return data_dict\n</code></pre> <p>Chromatic AutoContrast Percentage PC Colors</p> <p> </p>"},{"location":"color/#augmentation_class.ChromaticAutoContrastPercent.__call__","title":"<code>__call__(data_dict)</code>","text":"<p>Apply percentile-based chromatic auto-contrast to the point color. Args:     data_dict (dict): Input dictionary that must contain a <code>\"color\"</code> key with a NumPy array of shape (N, 3)         representing point color values.</p> <p>Returns:</p> Name Type Description <code>dict</code> <code>dict</code> <p>The same dictionary with <code>\"color\"</code> updated in-place, if applied.</p> Source code in <code>src\\augmentation_class.py</code> <pre><code>def __call__(self, data_dict: dict) -&gt; dict:\n    \"\"\"Apply percentile-based chromatic auto-contrast to the point color.\n    Args:\n        data_dict (dict): Input dictionary that must contain a `\"color\"` key with a NumPy array of shape (N, 3)\n            representing point color values.\n\n    Returns:\n        dict: The same dictionary with `\"color\"` updated in-place, if applied.\n    \"\"\"\n    if random.random() &gt; self.apply_p:\n        return data_dict\n\n    if \"color\" in data_dict.keys():\n        dtype = data_dict[\"color\"].dtype\n        if self.range255:\n            target_range = 255.0\n        else:\n            target_range = 1.0\n        blend_factor = np.random.rand() if self.blend_factor is None else self.blend_factor\n\n        # Apply autocontrast calculation, calculate 1% and 99% of the value among each channels\n        low_p, high_p = 1, 99\n        lo = np.percentile(data_dict[\"color\"][:, :3], low_p, axis=0, keepdims=True)\n        hi = np.percentile(data_dict[\"color\"][:, :3], high_p, axis=0, keepdims=True)\n\n        # Prevent division by zero if hi == lo\n        scale = target_range / (hi - lo + 1e-6)  # Add small epsilon for stability\n\n        # Apply contrast adjustment to the first 3 color channels\n        contrast_feat = (data_dict[\"color\"][:, :3] - lo[:, :3]) * scale[:, :3]\n\n        # Blend the original with the contrasted feature\n        # Ensure the blending maintains the data type\n        blended_color = (1 - blend_factor) * data_dict[\"color\"][:, :3] + blend_factor * contrast_feat\n\n        # Clip values to ensure they stay within the target range [0, target_range]\n        # and convert to the appropriate data type\n        data_dict[\"color\"][:, :3] = np.clip(blended_color, 0, target_range).astype(dtype)\n\n    return data_dict\n</code></pre>"},{"location":"color/#chromatictranslation","title":"ChromaticTranslation","text":"<p>Apply random global color translation to the point color.</p> <p>This transform expects a dictionary containing:</p> <ul> <li><code>\"color\"</code>: NumPy array of shape (N, 3) with point color values.</li> </ul> <p>For each call (with some probability), it samples a random translation vector <code>tr</code> in a bounded range and adds it to all color values:</p> <pre><code>tr \u2208 [-target_range * ratio, target_range * ratio]^3\n</code></pre> <p>where <code>target_range</code> is 255.0 if <code>range255=True</code>, else 1.0. The result is then clipped back to <code>[0, target_range]</code> and cast to the original dtype.</p> <p>Parameters:</p> Name Type Description Default <code>ratio</code> <code>float</code> <p>Maximum relative translation magnitude as a fraction of the full range. For <code>range255=True</code>, each channel offset lies in:</p> <pre><code>[-255 * ratio, 255 * ratio]\n</code></pre> <p>For <code>range255=False</code>, each channel offset lies in:</p> <pre><code>[-1.0 * ratio, 1.0 * ratio]\n</code></pre> <p>Defaults to 0.05.</p> <code>0.05</code> <code>range255</code> <code>bool</code> <p>Whether the input color values are in <code>[0, 255]</code>. If True, translations and clipping are done in that range. If False, they are done in <code>[0, 1]</code>. Defaults to False.</p> <code>False</code> <code>apply_p</code> <code>float</code> <p>Probability of applying the chromatic translation. Defaults to 1.0.</p> <code>1.0</code> Source code in <code>src\\augmentation_class.py</code> <pre><code>@TRANSFORMS.register()\nclass ChromaticTranslation:\n    \"\"\"Apply random global color translation to the point color.\n\n    This transform expects a dictionary containing:\n\n    * `\"color\"`: NumPy array of shape (N, 3) with point color values.\n\n    For each call (with some probability), it samples a random translation\n    vector `tr` in a bounded range and adds it to all color values:\n\n        tr \u2208 [-target_range * ratio, target_range * ratio]^3\n\n    where `target_range` is 255.0 if `range255=True`, else 1.0. The result is\n    then clipped back to `[0, target_range]` and cast to the original dtype.\n\n    Args:\n        ratio (float, optional):\n            Maximum relative translation magnitude as a fraction of the full range. For `range255=True`, each channel\n            offset lies in:\n\n                [-255 * ratio, 255 * ratio]\n\n            For `range255=False`, each channel offset lies in:\n\n                [-1.0 * ratio, 1.0 * ratio]\n\n            Defaults to 0.05.\n        range255 (bool, optional):\n            Whether the input color values are in `[0, 255]`. If True, translations and clipping are done in that\n            range. If False, they are done in `[0, 1]`.\n            Defaults to False.\n        apply_p (float, optional):\n            Probability of applying the chromatic translation.\n            Defaults to 1.0.\n    \"\"\"\n    def __init__(self, ratio: float = 0.05, range255=False, apply_p: float = 1.0):\n        self.ratio = ratio\n        self.range255 = range255\n        self.apply_p = apply_p\n\n    def __call__(self, data_dict: dict) -&gt; dict:\n        \"\"\"Apply a random color translation to the first 3 channels.\n\n        Args:\n            data_dict (dict): Input dictionary that must contain a `\"color\"` key with a NumPy array of shape (N, 3)\n                representing point color values.\n\n        Returns:\n            dict: The same dictionary with `\"color\"` updated in-place, if applied.\n        \"\"\"\n        if random.random() &gt; self.apply_p:\n            return data_dict\n\n        if \"color\" in data_dict.keys():\n            dtype = data_dict[\"color\"].dtype\n            if self.range255:\n                target_range = 255.0\n            else:\n                target_range = 1.0\n\n            tr = (np.random.rand(1, 3) - 0.5) * target_range * 2 * self.ratio  # [-255 * ratio, 255 * ratio]\n            data_dict[\"color\"][:, :3] = np.clip(tr + data_dict[\"color\"][:, :3], 0, target_range).astype(dtype)\n\n        return data_dict\n</code></pre> <p>Chromatic Translate PC Colors</p> <p> </p>"},{"location":"color/#augmentation_class.ChromaticTranslation.__call__","title":"<code>__call__(data_dict)</code>","text":"<p>Apply a random color translation to the first 3 channels.</p> <p>Parameters:</p> Name Type Description Default <code>data_dict</code> <code>dict</code> <p>Input dictionary that must contain a <code>\"color\"</code> key with a NumPy array of shape (N, 3) representing point color values.</p> required <p>Returns:</p> Name Type Description <code>dict</code> <code>dict</code> <p>The same dictionary with <code>\"color\"</code> updated in-place, if applied.</p> Source code in <code>src\\augmentation_class.py</code> <pre><code>def __call__(self, data_dict: dict) -&gt; dict:\n    \"\"\"Apply a random color translation to the first 3 channels.\n\n    Args:\n        data_dict (dict): Input dictionary that must contain a `\"color\"` key with a NumPy array of shape (N, 3)\n            representing point color values.\n\n    Returns:\n        dict: The same dictionary with `\"color\"` updated in-place, if applied.\n    \"\"\"\n    if random.random() &gt; self.apply_p:\n        return data_dict\n\n    if \"color\" in data_dict.keys():\n        dtype = data_dict[\"color\"].dtype\n        if self.range255:\n            target_range = 255.0\n        else:\n            target_range = 1.0\n\n        tr = (np.random.rand(1, 3) - 0.5) * target_range * 2 * self.ratio  # [-255 * ratio, 255 * ratio]\n        data_dict[\"color\"][:, :3] = np.clip(tr + data_dict[\"color\"][:, :3], 0, target_range).astype(dtype)\n\n    return data_dict\n</code></pre>"},{"location":"color/#chromaticjitter","title":"ChromaticJitter","text":"<p>Add Gaussian noise (jitter) to point colors.</p> <p>This transform expects a dictionary containing:</p> <ul> <li><code>\"color\"</code>: NumPy array of shape (N, 3) with point color values.</li> </ul> <p>It samples per-point, per-channel Gaussian noise and adds it to the channels:</p> <pre><code>noise ~ N(0, (std * target_range)^2)\n</code></pre> <p>where <code>target_range</code> is 255.0 if <code>range255=True</code>, else 1.0. The result is then clipped back to <code>[0, target_range]</code> and cast to the original dtype.</p> <p>Parameters:</p> Name Type Description Default <code>std</code> <code>float</code> <p>Standard deviation of the jitter, expressed as a fraction of the target range. The actual noise standard deviation per channel is:</p> <pre><code>sigma_noise = std * target_range\n</code></pre> <p>For example, with <code>std=0.005</code> and <code>range255=True</code>, the noise standard deviation is <code>0.005 * 255 \u2248 1.275</code>. Defaults to 0.005.</p> <code>0.005</code> <code>range255</code> <code>bool</code> <p>Whether the input color values are in <code>[0, 255]</code>. If True, noise and clipping are done in that range. If False, they are done in <code>[0, 1]</code>. Defaults to False.</p> <code>False</code> <code>apply_p</code> <code>float</code> <p>Probability of applying the chromatic jitter. Defaults to 1.0.</p> <code>1.0</code> Source code in <code>src\\augmentation_class.py</code> <pre><code>@TRANSFORMS.register()\nclass ChromaticJitter:\n    \"\"\"Add Gaussian noise (jitter) to point colors.\n\n    This transform expects a dictionary containing:\n\n    * `\"color\"`: NumPy array of shape (N, 3) with point color values.\n\n    It samples per-point, per-channel Gaussian noise and adds it to the channels:\n\n        noise ~ N(0, (std * target_range)^2)\n\n    where `target_range` is 255.0 if `range255=True`, else 1.0. The result is then clipped back to `[0, target_range]`\n    and cast to the original dtype.\n\n    Args:\n        std (float, optional):\n            Standard deviation of the jitter, expressed as a fraction of the target range. The actual noise standard\n            deviation per channel is:\n\n                sigma_noise = std * target_range\n\n            For example, with `std=0.005` and `range255=True`, the noise standard deviation is `0.005 * 255 \u2248 1.275`.\n            Defaults to 0.005.\n        range255 (bool, optional):\n            Whether the input color values are in `[0, 255]`. If True, noise and clipping are done in that range.\n            If False, they are done in `[0, 1]`.\n            Defaults to False.\n        apply_p (float, optional):\n            Probability of applying the chromatic jitter.\n            Defaults to 1.0.\n    \"\"\"\n    def __init__(self, std: float = 0.005, range255=False, apply_p: float = 1.0):\n        self.std = std\n        self.range255 = range255\n        self.apply_p = apply_p\n\n    def __call__(self, data_dict: dict) -&gt; dict:\n        \"\"\"Apply Gaussian color jitter to the first 3 channels.\n\n        Args:\n            data_dict (dict): Input dictionary that must contain a `\"color\"` key with a NumPy array of shape (N, 3)\n                representing point color values.\n\n        Returns:\n            dict: The same dictionary with `\"color\"` jittered in-place, if applied.\n        \"\"\"\n        if random.random() &gt; self.apply_p:\n            return data_dict\n\n        if \"color\" in data_dict.keys():\n            dtype = data_dict[\"color\"].dtype\n            if self.range255:\n                target_range = 255.0\n            else:\n                target_range = 1.0\n\n            noise = np.random.randn(data_dict[\"color\"].shape[0], 3)\n            noise = noise * self.std * target_range\n            data_dict[\"color\"][:, :3] = np.clip(noise + data_dict[\"color\"][:, :3], 0, target_range).astype(dtype)\n\n        return data_dict\n</code></pre> <p>Chromatic Jitter PC Colors</p> <p> </p>"},{"location":"color/#augmentation_class.ChromaticJitter.__call__","title":"<code>__call__(data_dict)</code>","text":"<p>Apply Gaussian color jitter to the first 3 channels.</p> <p>Parameters:</p> Name Type Description Default <code>data_dict</code> <code>dict</code> <p>Input dictionary that must contain a <code>\"color\"</code> key with a NumPy array of shape (N, 3) representing point color values.</p> required <p>Returns:</p> Name Type Description <code>dict</code> <code>dict</code> <p>The same dictionary with <code>\"color\"</code> jittered in-place, if applied.</p> Source code in <code>src\\augmentation_class.py</code> <pre><code>def __call__(self, data_dict: dict) -&gt; dict:\n    \"\"\"Apply Gaussian color jitter to the first 3 channels.\n\n    Args:\n        data_dict (dict): Input dictionary that must contain a `\"color\"` key with a NumPy array of shape (N, 3)\n            representing point color values.\n\n    Returns:\n        dict: The same dictionary with `\"color\"` jittered in-place, if applied.\n    \"\"\"\n    if random.random() &gt; self.apply_p:\n        return data_dict\n\n    if \"color\" in data_dict.keys():\n        dtype = data_dict[\"color\"].dtype\n        if self.range255:\n            target_range = 255.0\n        else:\n            target_range = 1.0\n\n        noise = np.random.randn(data_dict[\"color\"].shape[0], 3)\n        noise = noise * self.std * target_range\n        data_dict[\"color\"][:, :3] = np.clip(noise + data_dict[\"color\"][:, :3], 0, target_range).astype(dtype)\n\n    return data_dict\n</code></pre>"},{"location":"color/#randomcolorgrayscale","title":"RandomColorGrayScale","text":"<p>Randomly convert point colors to grayscale.</p> <p>This transform expects a dictionary containing:</p> <ul> <li><code>\"color\"</code>: NumPy array of shape (N, 3) with point color values.</li> </ul> <p>It converts the <code>\"color\"</code> from RGB to grayscale using an NTSC-style luminance formula, and returns a 3-channel grayscale image (gray copied into R, G, B).</p> <p>Parameters:</p> Name Type Description Default <code>apply_p</code> <code>float</code> <p>Probability of converting colors to grayscale. Defaults to 1.0.</p> <code>1.0</code> Source code in <code>src\\augmentation_class.py</code> <pre><code>@TRANSFORMS.register()\nclass RandomColorGrayScale:\n    \"\"\"Randomly convert point colors to grayscale.\n\n    This transform expects a dictionary containing:\n\n    * `\"color\"`: NumPy array of shape (N, 3) with point color values.\n\n    It converts the `\"color\"` from RGB to grayscale using an NTSC-style luminance formula, and returns\n    a 3-channel grayscale image (gray copied into R, G, B).\n\n    Args:\n        apply_p (float, optional):\n            Probability of converting colors to grayscale.\n            Defaults to 1.0.\n    \"\"\"\n    def __init__(self, apply_p: float = 1.0):\n        self.apply_p = apply_p\n\n    @staticmethod\n    def rgb_to_grayscale(color: np.ndarray, num_output_channels=1) -&gt; np.ndarray:\n        \"\"\"Convert RGB colors to grayscale using an NTSC-style formula.\n\n        Uses the luminance computation:\n\n            gray = 0.2999 * R + 0.587 * G + 0.114 * B\n\n        Args:\n            color (np.ndarray):\n                Input color array with shape (..., C), where C \u2265 3 and the last dimension contains RGB channels\n                in positions 0, 1, 2.\n            num_output_channels (int, optional):\n                Number of channels in the output. Must be 1 or 3.\n\n                * 1 \u2192 returns a single-channel grayscale array.\n                * 3 \u2192 returns a 3-channel array with the grayscale value broadcast to R, G, B.\n\n                Defaults to 1.\n\n        Returns:\n            gray (np.ndarray):\n                Grayscale array with the same dtype as `color` and either 1 or 3 channels in the last dimension.\n        \"\"\"\n        assert color.shape[-1] &gt;= 3\n        assert num_output_channels in (1, 3)\n        r, g, b = color[..., 0], color[..., 1], color[..., 2]\n        # NTSC formula\n        gray = (0.2999 * r + 0.587 * g + 0.114 * b).astype(color.dtype)\n        gray = np.expand_dims(gray, axis=-1)\n        if num_output_channels == 3:\n            gray = np.broadcast_to(gray, color.shape)\n\n        return gray\n\n    def __call__(self, data_dict: dict) -&gt; dict:\n        \"\"\"Randomly convert `\"color\"` to grayscale in-place.\n\n        Args:\n            data_dict (dict): Input dictionary that must contain a `\"color\"` key with a NumPy array of shape (N, 3)\n                representing point color values.\n\n        Returns:\n            dict: The same dictionary with `\"color\"` converted to 3-channel grayscale, if applied.\n        \"\"\"\n        if random.random() &gt; self.apply_p:\n            return data_dict\n\n        if \"color\" in data_dict.keys():\n            data_dict[\"color\"] = self.rgb_to_grayscale(data_dict[\"color\"], 3)\n        return data_dict\n</code></pre> <p>Transfer PC Colors into GrayScale</p> <p> </p>"},{"location":"color/#augmentation_class.RandomColorGrayScale.__call__","title":"<code>__call__(data_dict)</code>","text":"<p>Randomly convert <code>\"color\"</code> to grayscale in-place.</p> <p>Parameters:</p> Name Type Description Default <code>data_dict</code> <code>dict</code> <p>Input dictionary that must contain a <code>\"color\"</code> key with a NumPy array of shape (N, 3) representing point color values.</p> required <p>Returns:</p> Name Type Description <code>dict</code> <code>dict</code> <p>The same dictionary with <code>\"color\"</code> converted to 3-channel grayscale, if applied.</p> Source code in <code>src\\augmentation_class.py</code> <pre><code>def __call__(self, data_dict: dict) -&gt; dict:\n    \"\"\"Randomly convert `\"color\"` to grayscale in-place.\n\n    Args:\n        data_dict (dict): Input dictionary that must contain a `\"color\"` key with a NumPy array of shape (N, 3)\n            representing point color values.\n\n    Returns:\n        dict: The same dictionary with `\"color\"` converted to 3-channel grayscale, if applied.\n    \"\"\"\n    if random.random() &gt; self.apply_p:\n        return data_dict\n\n    if \"color\" in data_dict.keys():\n        data_dict[\"color\"] = self.rgb_to_grayscale(data_dict[\"color\"], 3)\n    return data_dict\n</code></pre>"},{"location":"color/#randomcolorjitter","title":"RandomColorJitter","text":"<p>Random color jitter for 3D point cloud colors (similar to torchvision).</p> <p>This transform expects a dictionary containing:</p> <ul> <li><code>\"color\"</code>: NumPy array of shape (N, 3) with point color values.</li> </ul> <p>At each call (with probability <code>apply_p</code>), it:</p> <ol> <li>Converts <code>\"color\"</code> to float in the range [0, 1].</li> <li>If <code>range255=True</code>, it divides by 255.</li> <li>Otherwise it assumes values are already in [0, 1] (or compatible).</li> <li>Randomly samples brightness, contrast, saturation, and hue factors within the ranges specified at initialization.</li> <li>Applies a random ordering of these adjustments (brightness, contrast, saturation, hue) to the colors.</li> <li>Clips the result to [0, 1].</li> <li>Converts back to the original dtype (and multiplies by 255 if <code>range255=True</code>).</li> </ol> <p>The argument conventions follow torchvision's <code>ColorJitter</code>:</p> <p>Parameters:</p> Name Type Description Default <code>brightness</code> <code>float | tuple[float, float]</code> <p>How much to jitter brightness.</p> <pre><code>* If a single non-negative float ``b`` is given, the brightness\n  factor is chosen uniformly from ``[max(0, 1 - b), 1 + b]``.\n* If a tuple ``(b_min, b_max)`` is given, the brightness factor is\n  chosen uniformly from ``[b_min, b_max]``.\n* If set to 0 or (1.0, 1.0), no brightness change is applied.\n</code></pre> <p>Defaults to 0.</p> <code>0</code> <code>contrast</code> <code>float | tuple[float, float]</code> <p>How much to jitter contrast. Same semantics as <code>brightness</code> (centered at 1.0). If set to 0 or (1.0, 1.0), no contrast change is applied. Defaults to 0.</p> <code>0</code> <code>saturation</code> <code>float | tuple[float, float]</code> <p>How much to jitter saturation. Same semantics as <code>brightness</code> (centered at 1.0). If set to 0 or (1.0, 1.0), no saturation change is applied. Defaults to 0.</p> <code>0</code> <code>hue</code> <code>float | tuple[float, float]</code> <p>How much to jitter hue.</p> <ul> <li>If a single float <code>h</code> is given, the hue factor is chosen   uniformly from <code>[-h, h]</code>.</li> <li>If a tuple <code>(h_min, h_max)</code> is given, it is chosen uniformly   from <code>[h_min, h_max]</code>.</li> </ul> <p>Values must be in <code>[-0.5, 0.5]</code>. If set to 0 or (0.0, 0.0), no hue change is applied. Defaults to 0.</p> <code>0</code> <code>range255</code> <code>bool</code> <p>Whether the input color values are in <code>[0, 255]</code>. If True, values are converted to float in [0, 1] before jittering and converted back to [0, 255] afterwards. If False, values are treated as floats in [0, 1]. Defaults to False.</p> <code>False</code> <code>apply_p</code> <code>float</code> <p>Probability of applying the color jitter. Defaults to 1.0.</p> <code>1.0</code> Source code in <code>src\\augmentation_class.py</code> <pre><code>@TRANSFORMS.register()\nclass RandomColorJitter:\n    \"\"\"Random color jitter for 3D point cloud colors (similar to torchvision).\n\n    This transform expects a dictionary containing:\n\n    * `\"color\"`: NumPy array of shape (N, 3) with point color values.\n\n    At each call (with probability ``apply_p``), it:\n\n    1. Converts `\"color\"` to float in the range [0, 1].\n       - If ``range255=True``, it divides by 255.\n       - Otherwise it assumes values are already in [0, 1] (or compatible).\n    2. Randomly samples brightness, contrast, saturation, and hue factors within the ranges specified at initialization.\n    3. Applies a random ordering of these adjustments (brightness, contrast, saturation, hue) to the colors.\n    4. Clips the result to [0, 1].\n    5. Converts back to the original dtype (and multiplies by 255 if ``range255=True``).\n\n    The argument conventions follow torchvision's ``ColorJitter``:\n\n    Args:\n        brightness (float | tuple[float, float], optional):\n            How much to jitter brightness.\n\n                * If a single non-negative float ``b`` is given, the brightness\n                  factor is chosen uniformly from ``[max(0, 1 - b), 1 + b]``.\n                * If a tuple ``(b_min, b_max)`` is given, the brightness factor is\n                  chosen uniformly from ``[b_min, b_max]``.\n                * If set to 0 or (1.0, 1.0), no brightness change is applied.\n\n            Defaults to 0.\n        contrast (float | tuple[float, float], optional):\n            How much to jitter contrast. Same semantics as ``brightness`` (centered at 1.0).\n            If set to 0 or (1.0, 1.0), no contrast change is applied.\n            Defaults to 0.\n        saturation (float | tuple[float, float], optional):\n            How much to jitter saturation. Same semantics as ``brightness`` (centered at 1.0).\n            If set to 0 or (1.0, 1.0), no saturation change is applied.\n            Defaults to 0.\n        hue (float | tuple[float, float], optional):\n            How much to jitter hue.\n\n            * If a single float ``h`` is given, the hue factor is chosen\n              uniformly from ``[-h, h]``.\n            * If a tuple ``(h_min, h_max)`` is given, it is chosen uniformly\n              from ``[h_min, h_max]``.\n\n            Values must be in ``[-0.5, 0.5]``. If set to 0 or (0.0, 0.0), no hue change is applied.\n            Defaults to 0.\n        range255 (bool, optional):\n            Whether the input color values are in ``[0, 255]``. If True, values are converted to float in [0, 1]\n            before jittering and converted back to [0, 255] afterwards. If False, values are treated as floats in [0, 1].\n            Defaults to False.\n        apply_p (float, optional):\n            Probability of applying the color jitter.\n            Defaults to 1.0.\n    \"\"\"\n    def __init__(self, brightness=0, contrast=0, saturation=0, hue=0, range255=False, apply_p=1.0):\n        self.brightness = self._check_input(brightness, \"brightness\")\n        self.contrast = self._check_input(contrast, \"contrast\")\n        self.saturation = self._check_input(saturation, \"saturation\")\n        self.hue = self._check_input(hue, \"hue\", center=0, bound=(-0.5, 0.5), clip_first_on_zero=False)\n        self.range255 = range255\n        self.apply_p = apply_p\n\n    @staticmethod\n    def _check_input(value: int | float | tuple | list, name: str, center: float = 1, bound: tuple = (0, float(\"inf\")),\n                     clip_first_on_zero: bool = True):\n        \"\"\"Normalize jitter argument into a (min, max) interval or None.\n\n        This helper follows torchvision's ``ColorJitter._check_input`` logic.\n\n        Args:\n            value (int | float | tuple | list):\n                Jitter specification.\n                    * Single number: interpreted as symmetric range around ``center``, i.e.\n                    ``[center - value, center + value]``.\n                    * Tuple/list of length 2: interpreted as explicit ``(min, max)``.\n            name (str):\n                Name of the parameter (for error messages).\n            center (float, optional):\n                Center value. Usually 1 for brightness/contrast/saturation, 0 for hue.\n                Defaults to 1.\n            bound (tuple[float, float], optional):\n                Allowed bounds for the resulting interval.\n                Defaults to ``(0, inf)``.\n            clip_first_on_zero (bool, optional):\n                If True and value is scalar, the lower bound is clipped at 0.0 (for cases like brightness or contrast).\n                For hue, this is False.\n                Defaults to True.\n\n        Returns:\n            value (list[float] | None):\n                A 2-element list ``[min, max]`` if the range is non-trivial, or ``None`` if no change should be applied\n                for this parameter.\n        \"\"\"\n        if isinstance(value, (int, float)):\n            if value &lt; 0:\n                raise ValueError(f\"If {name} is a single number, it must be non negative.\")\n            value = [center - float(value), center + float(value)]\n            if clip_first_on_zero:\n                value[0] = max(value[0], 0.0)\n        elif isinstance(value, (tuple, list)) and len(value) == 2:\n            if not bound[0] &lt;= value[0] &lt;= value[1] &lt;= bound[1]:\n                raise ValueError(f\"{name} values should be between {bound}\")\n        else:\n            raise TypeError(f\"{name} should be a single number or a list/tuple with length 2.\")\n\n        # if value is 0 or (1., 1.) for brightness/contrast/saturation\n        # or (0., 0.) for hue, do nothing\n        if value[0] == value[1] == center:\n            value = None\n        return value\n\n    @staticmethod\n    def blend(color1, color2, ratio):\n        \"\"\"Blend two color tensors with a given ratio.\n\n        Computes:\n\n            out = ratio * color1 + (1 - ratio) * color2\n\n        and clips the result to [0, 1].\n\n        Args:\n            color1 (np.ndarray):\n                First color array in [0, 1].\n            color2 (np.ndarray):\n                Second color array, broadcastable to color1.\n            ratio (float):\n                Blend ratio. 1.0 means all ``color1``, 0.0 means all ``color2``.\n\n        Returns:\n            np.ndarray:\n                Blended color array with same dtype as ``color1``.\n        \"\"\"\n        ratio = float(ratio)\n        return (ratio * color1 + (1.0 - ratio) * color2).clip(0, 1.0).astype(color1.dtype)\n\n    @staticmethod\n    def rgb2hsv(rgb):\n        \"\"\"Convert RGB colors in [0, 1] to HSV.\n\n        Args:\n            rgb (np.ndarray):\n            Array of shape (..., 3) with RGB channels in the last dimension.\n\n        Returns:\n            np.ndarray:\n            Array of shape (..., 3) with HSV channels in the last dimension.\n        \"\"\"\n        r, g, b = rgb[..., 0], rgb[..., 1], rgb[..., 2]\n        maxc = np.max(rgb, axis=-1)\n        minc = np.min(rgb, axis=-1)\n        eqc = maxc == minc\n        cr = maxc - minc\n        s = cr / (np.ones_like(maxc) * eqc + maxc * (1 - eqc))\n        cr_divisor = np.ones_like(maxc) * eqc + cr * (1 - eqc)\n        rc = (maxc - r) / cr_divisor\n        gc = (maxc - g) / cr_divisor\n        bc = (maxc - b) / cr_divisor\n\n        hr = (maxc == r) * (bc - gc)\n        hg = ((maxc == g) &amp; (maxc != r)) * (2.0 + rc - bc)\n        hb = ((maxc != g) &amp; (maxc != r)) * (4.0 + gc - rc)\n        h = hr + hg + hb\n        h = (h / 6.0 + 1.0) % 1.0\n        return np.stack((h, s, maxc), axis=-1)\n\n    @staticmethod\n    def hsv2rgb(hsv):\n        \"\"\"Convert HSV colors in [0, 1] to RGB.\n\n        Args:\n            hsv (np.ndarray):\n                Array of shape (..., 3) with HSV channels in the last dimension.\n\n        Returns:\n            np.ndarray:\n                Array of shape (..., 3) with RGB channels in the last dimension.\n        \"\"\"\n        h, s, v = hsv[..., 0], hsv[..., 1], hsv[..., 2]\n        i = np.floor(h * 6.0)\n        f = (h * 6.0) - i\n        i = i.astype(np.int32)\n\n        p = np.clip((v * (1.0 - s)), 0.0, 1.0)\n        q = np.clip((v * (1.0 - s * f)), 0.0, 1.0)\n        t = np.clip((v * (1.0 - s * (1.0 - f))), 0.0, 1.0)\n        i = i % 6\n        mask = np.expand_dims(i, axis=-1) == np.arange(6)\n\n        a1 = np.stack((v, q, p, p, t, v), axis=-1)\n        a2 = np.stack((t, v, v, q, p, p), axis=-1)\n        a3 = np.stack((p, p, t, v, v, q), axis=-1)\n        a4 = np.stack((a1, a2, a3), axis=-1)\n\n        return np.einsum(\"...na, ...nab -&gt; ...nb\", mask.astype(hsv.dtype), a4)\n\n    def adjust_brightness(self, color, brightness_factor):\n        \"\"\"Adjust brightness of a color tensor.\n\n        Args:\n            color (np.ndarray):\n                Color array in [0, 1].\n            brightness_factor (float):\n                Non-negative brightness scaling factor. 0 means all black, 1 means no change, &gt;1 makes it brighter.\n\n        Returns:\n            np.ndarray:\n                Brightness-adjusted color array in [0, 1].\n        \"\"\"\n        if brightness_factor &lt; 0:\n            raise ValueError(f\"brightness_factor ({brightness_factor}) is not non-negative.\")\n        # color and zeros are in [0,1] float\n        return self.blend(color, np.zeros_like(color), brightness_factor)\n\n    def adjust_contrast(self, color, contrast_factor):\n        \"\"\"Adjust contrast of a color tensor.\n\n        Args:\n            color (np.ndarray):\n                Color array in [0, 1].\n            contrast_factor (float):\n                Non-negative contrast scaling factor. 0 means the colors at mean intensity (from grayscale value),\n                1 means no change, &gt;1 increases contrast.\n\n        Returns:\n            np.ndarray:\n                Contrast-adjusted color array in [0, 1].\n        \"\"\"\n        if contrast_factor &lt; 0:\n            raise ValueError(f\"contrast_factor ({contrast_factor}) is not non-negative.\")\n        mean = np.mean(RandomColorGrayScale.rgb_to_grayscale(color))\n        return self.blend(color, mean, contrast_factor)\n\n    def adjust_saturation(self, color, saturation_factor):\n        \"\"\"Adjust saturation of a color tensor.\n\n        Args:\n            color (np.ndarray):\n                Color array in [0, 1].\n            saturation_factor (float):\n                Non-negative saturation scaling factor. 0 means grayscale, 1 means no change, &gt;1 increases saturation.\n\n        Returns:\n            np.ndarray:\n                Saturation-adjusted color array in [0, 1].\n        \"\"\"\n        if saturation_factor &lt; 0:\n            raise ValueError(f\"saturation_factor ({saturation_factor}) is not non-negative.\")\n        gray = RandomColorGrayScale.rgb_to_grayscale(color)\n        return self.blend(color, gray, saturation_factor)\n\n    def adjust_hue(self, color, hue_factor):\n        \"\"\"Adjust hue of a color tensor.\n\n        Args:\n            color (np.ndarray):\n                Color array in [0, 1].\n            hue_factor (float):\n                Hue shift factor in [-0.5, 0.5]. The hue channel (in HSV) is shifted by this amount modulo 1.\n\n        Returns:\n            np.ndarray:\n                Hue-adjusted color array in [0, 1].\n        \"\"\"\n        # color in (0, 1.0) range\n        if not (-0.5 &lt;= hue_factor &lt;= 0.5):\n            raise ValueError(f\"hue_factor ({hue_factor}) is not in [-0.5, 0.5].\")\n        hsv = self.rgb2hsv(color)\n        h, s, v = hsv[..., 0], hsv[..., 1], hsv[..., 2]\n        h = (h + hue_factor) % 1.0\n        hsv = np.stack((h, s, v), axis=-1)\n        return self.hsv2rgb(hsv)\n\n    @staticmethod\n    def get_params(brightness, contrast, saturation, hue):\n        \"\"\"Sample random jitter parameters and a random order of operations.\n\n        Args:\n            brightness: Parsed brightness range from ``_check_input`` or ``None``.\n            contrast: Parsed contrast range from ``_check_input`` or ``None``.\n            saturation: Parsed saturation range from ``_check_input`` or ``None``.\n            hue: Parsed hue range from ``_check_input`` or ``None``.\n\n        Returns:\n            tuple:\n                ``(fn_idx, b, c, s, h)`` where:\n\n                * ``fn_idx`` is a permutation of [0, 1, 2, 3] indicating the\n                  order in which brightness/contrast/saturation/hue will be\n                  applied.\n                * ``b, c, s, h`` are the sampled scalar factors (or ``None`` if\n                  the corresponding transform is disabled).\n        \"\"\"\n        fn_idx = np.arange(4)\n        np.random.shuffle(fn_idx)\n        b = (None if brightness is None else np.random.uniform(brightness[0], brightness[1]))\n        c = None if contrast is None else np.random.uniform(contrast[0], contrast[1])\n        s = (None if saturation is None else np.random.uniform(saturation[0], saturation[1]))\n        h = None if hue is None else np.random.uniform(hue[0], hue[1])\n        return fn_idx, b, c, s, h\n\n    def __call__(self, data_dict: dict) -&gt; dict:\n        \"\"\"Apply random color jitter to the `\"color\"` entry in `data_dict`.\n\n        Args:\n            data_dict (dict): Input dictionary that must contain a `\"color\"` key with a NumPy array of shape (N, 3)\n                representing point color values.\n\n        Returns:\n            dict: The same dictionary with `\"color\"` updated in-place, if applied.\n        \"\"\"\n        if random.random() &gt; self.apply_p:\n            return data_dict\n\n        if \"color\" in data_dict.keys():\n            # make sure color range is [0, 1.0]\n            dtype = data_dict[\"color\"].dtype\n            if self.range255:\n                data_dict[\"color\"] = data_dict[\"color\"].astype(np.float32) / 255.\n            else:\n                data_dict[\"color\"] = data_dict[\"color\"].astype(np.float32)\n\n\n            fn_idx, brightness_factor, contrast_factor, saturation_factor, hue_factor = self.get_params(self.brightness,\n                                                                                                        self.contrast,\n                                                                                                        self.saturation,\n                                                                                                        self.hue)\n            for fn_id in fn_idx:\n                if fn_id == 0 and brightness_factor is not None:\n                    data_dict[\"color\"] = self.adjust_brightness(data_dict[\"color\"], brightness_factor)\n                elif fn_id == 1 and contrast_factor is not None:\n                    data_dict[\"color\"] = self.adjust_contrast(data_dict[\"color\"], contrast_factor)\n                elif fn_id == 2 and saturation_factor is not None:\n                    data_dict[\"color\"] = self.adjust_saturation(data_dict[\"color\"], saturation_factor)\n                elif fn_id == 3 and hue_factor is not None:\n                    data_dict[\"color\"] = self.adjust_hue(data_dict[\"color\"], hue_factor)\n\n\n            data_dict[\"color\"] = np.clip(data_dict[\"color\"], 0.0, 1.0)\n            # convert back to original dtype / range\n            if self.range255:\n                data_dict[\"color\"] = (data_dict[\"color\"] * 255.).round().astype(dtype)\n            else:\n                data_dict[\"color\"] = data_dict[\"color\"].astype(dtype)\n\n        return data_dict\n</code></pre> <p>Random Jitter PC Colors</p> <p> </p>"},{"location":"color/#augmentation_class.RandomColorJitter.__call__","title":"<code>__call__(data_dict)</code>","text":"<p>Apply random color jitter to the <code>\"color\"</code> entry in <code>data_dict</code>.</p> <p>Parameters:</p> Name Type Description Default <code>data_dict</code> <code>dict</code> <p>Input dictionary that must contain a <code>\"color\"</code> key with a NumPy array of shape (N, 3) representing point color values.</p> required <p>Returns:</p> Name Type Description <code>dict</code> <code>dict</code> <p>The same dictionary with <code>\"color\"</code> updated in-place, if applied.</p> Source code in <code>src\\augmentation_class.py</code> <pre><code>def __call__(self, data_dict: dict) -&gt; dict:\n    \"\"\"Apply random color jitter to the `\"color\"` entry in `data_dict`.\n\n    Args:\n        data_dict (dict): Input dictionary that must contain a `\"color\"` key with a NumPy array of shape (N, 3)\n            representing point color values.\n\n    Returns:\n        dict: The same dictionary with `\"color\"` updated in-place, if applied.\n    \"\"\"\n    if random.random() &gt; self.apply_p:\n        return data_dict\n\n    if \"color\" in data_dict.keys():\n        # make sure color range is [0, 1.0]\n        dtype = data_dict[\"color\"].dtype\n        if self.range255:\n            data_dict[\"color\"] = data_dict[\"color\"].astype(np.float32) / 255.\n        else:\n            data_dict[\"color\"] = data_dict[\"color\"].astype(np.float32)\n\n\n        fn_idx, brightness_factor, contrast_factor, saturation_factor, hue_factor = self.get_params(self.brightness,\n                                                                                                    self.contrast,\n                                                                                                    self.saturation,\n                                                                                                    self.hue)\n        for fn_id in fn_idx:\n            if fn_id == 0 and brightness_factor is not None:\n                data_dict[\"color\"] = self.adjust_brightness(data_dict[\"color\"], brightness_factor)\n            elif fn_id == 1 and contrast_factor is not None:\n                data_dict[\"color\"] = self.adjust_contrast(data_dict[\"color\"], contrast_factor)\n            elif fn_id == 2 and saturation_factor is not None:\n                data_dict[\"color\"] = self.adjust_saturation(data_dict[\"color\"], saturation_factor)\n            elif fn_id == 3 and hue_factor is not None:\n                data_dict[\"color\"] = self.adjust_hue(data_dict[\"color\"], hue_factor)\n\n\n        data_dict[\"color\"] = np.clip(data_dict[\"color\"], 0.0, 1.0)\n        # convert back to original dtype / range\n        if self.range255:\n            data_dict[\"color\"] = (data_dict[\"color\"] * 255.).round().astype(dtype)\n        else:\n            data_dict[\"color\"] = data_dict[\"color\"].astype(dtype)\n\n    return data_dict\n</code></pre>"},{"location":"color/#huesaturationtranslation","title":"HueSaturationTranslation","text":"<p>Randomly shift hue and scale saturation of point colors.</p> <p>This transform expects a dictionary containing:</p> <ul> <li><code>\"color\"</code>: NumPy array of shape (N, 3) with point color values.</li> </ul> <p>For each call (with probability <code>apply_p</code>), it:</p> <ol> <li>Converts <code>\"color\"</code> to float in the range [0, 1].</li> <li>If <code>range255=True</code>, it divides by 255.</li> <li>Otherwise it assumes values are already in [0, 1] (or compatible).</li> <li>Converts the color from RGB to HSV.</li> <li>Samples:</li> <li>a hue shift <code>h ~ U(-hue_max, hue_max)</code> and applies it modulo 1.0,</li> <li>a saturation scale <code>s = 1 + U(-saturation_max, saturation_max)</code> and      multiplies the saturation channel by <code>s</code> (clipped to [0, 1]).</li> <li>Converts HSV back to RGB, clips to [0, 1], and restores the original dtype (multiplying by 255 if needed).</li> </ol> <p>Parameters:</p> Name Type Description Default <code>hue_max</code> <code>float</code> <p>Maximum absolute hue shift. The actual hue offset is sampled uniformly from <code>[-hue_max, hue_max]</code> and added to the hue channel modulo 1.0. Defaults to 0.5.</p> <code>0.5</code> <code>saturation_max</code> <code>float</code> <p>Maximum relative change in saturation. The saturation scale factor is sampled as:</p> <pre><code>s = 1 + U(-saturation_max, saturation_max)\n</code></pre> <p>so saturation can be slightly decreased or increased. Defaults to 0.2.</p> <code>0.2</code> <code>range255</code> <code>bool</code> <p>Whether the input color values are in <code>[0, 255]</code>. If True, values are converted to float in [0, 1] before modification and converted back to [0, 255] afterwards. If False, values are treated as floats in [0, 1]. Defaults to False.</p> <code>False</code> <code>apply_p</code> <code>float</code> <p>Probability of applying the hue/saturation translation. Defaults to 1.0.</p> <code>1.0</code> Source code in <code>src\\augmentation_class.py</code> <pre><code>@TRANSFORMS.register()\nclass HueSaturationTranslation:\n    \"\"\"Randomly shift hue and scale saturation of point colors.\n\n    This transform expects a dictionary containing:\n\n    * `\"color\"`: NumPy array of shape (N, 3) with point color values.\n\n    For each call (with probability ``apply_p``), it:\n\n    1. Converts `\"color\"` to float in the range [0, 1].\n       - If ``range255=True``, it divides by 255.\n       - Otherwise it assumes values are already in [0, 1] (or compatible).\n    2. Converts the color from RGB to HSV.\n    3. Samples:\n       - a hue shift ``h ~ U(-hue_max, hue_max)`` and applies it modulo 1.0,\n       - a saturation scale ``s = 1 + U(-saturation_max, saturation_max)`` and\n         multiplies the saturation channel by ``s`` (clipped to [0, 1]).\n    4. Converts HSV back to RGB, clips to [0, 1], and restores the original dtype (multiplying by 255 if needed).\n\n    Args:\n        hue_max (float, optional):\n            Maximum absolute hue shift. The actual hue offset is sampled uniformly from ``[-hue_max, hue_max]`` and added\n            to the hue channel modulo 1.0.\n            Defaults to 0.5.\n        saturation_max (float, optional):\n            Maximum relative change in saturation. The saturation scale factor is sampled as:\n\n                s = 1 + U(-saturation_max, saturation_max)\n\n            so saturation can be slightly decreased or increased.\n            Defaults to 0.2.\n        range255 (bool, optional):\n            Whether the input color values are in ``[0, 255]``. If True, values are converted to float in [0, 1]\n            before modification and converted back to [0, 255] afterwards. If False, values are treated as floats in [0, 1].\n            Defaults to False.\n        apply_p (float, optional):\n            Probability of applying the hue/saturation translation.\n            Defaults to 1.0.\n    \"\"\"\n    def __init__(self, hue_max=0.5, saturation_max=0.2, range255=False, apply_p=1.0):\n        self.hue_max = hue_max\n        self.saturation_max = saturation_max\n        self.range255 = range255\n        self.apply_p = apply_p\n\n    def __call__(self, data_dict: dict) -&gt; dict:\n        \"\"\"Apply random hue and saturation translation to `\"color\"`.\n        Args:\n            data_dict (dict): Input dictionary that must contain a `\"color\"` key with a NumPy array of shape (N, 3)\n                representing point color values.\n\n        Returns:\n            dict: The same dictionary with `\"color\"` updated in-place, if applied.\n        \"\"\"\n        if random.random() &gt; self.apply_p:\n            return data_dict\n\n        if \"color\" in data_dict.keys():\n\n            # make sure color range is [0, 1.0]\n            dtype = data_dict[\"color\"].dtype\n            if self.range255:\n                data_dict[\"color\"] = data_dict[\"color\"].astype(np.float32) / 255.\n            else:\n                data_dict[\"color\"] = data_dict[\"color\"].astype(np.float32)\n\n            hsv = RandomColorJitter.rgb2hsv(data_dict[\"color\"][:, :3])\n            hue_val = np.random.uniform(-self.hue_max, self.hue_max)\n            sat_ratio = 1 + np.random.uniform(-self.saturation_max, self.saturation_max)\n            hsv[..., 0] = np.remainder(hue_val + hsv[..., 0] + 1, 1)\n            hsv[..., 1] = np.clip(sat_ratio * hsv[..., 1], 0, 1)\n\n            data_dict[\"color\"][:, :3] = np.clip(RandomColorJitter.hsv2rgb(hsv), 0, 1.0)\n            if self.range255:\n                data_dict[\"color\"] = (data_dict[\"color\"] * 255.).round().astype(dtype)\n            else:\n                data_dict[\"color\"] = data_dict[\"color\"].astype(dtype)\n\n        return data_dict\n</code></pre> <p>Hue Saturation Translation PC Colors</p> <p> </p>"},{"location":"color/#augmentation_class.HueSaturationTranslation.__call__","title":"<code>__call__(data_dict)</code>","text":"<p>Apply random hue and saturation translation to <code>\"color\"</code>. Args:     data_dict (dict): Input dictionary that must contain a <code>\"color\"</code> key with a NumPy array of shape (N, 3)         representing point color values.</p> <p>Returns:</p> Name Type Description <code>dict</code> <code>dict</code> <p>The same dictionary with <code>\"color\"</code> updated in-place, if applied.</p> Source code in <code>src\\augmentation_class.py</code> <pre><code>def __call__(self, data_dict: dict) -&gt; dict:\n    \"\"\"Apply random hue and saturation translation to `\"color\"`.\n    Args:\n        data_dict (dict): Input dictionary that must contain a `\"color\"` key with a NumPy array of shape (N, 3)\n            representing point color values.\n\n    Returns:\n        dict: The same dictionary with `\"color\"` updated in-place, if applied.\n    \"\"\"\n    if random.random() &gt; self.apply_p:\n        return data_dict\n\n    if \"color\" in data_dict.keys():\n\n        # make sure color range is [0, 1.0]\n        dtype = data_dict[\"color\"].dtype\n        if self.range255:\n            data_dict[\"color\"] = data_dict[\"color\"].astype(np.float32) / 255.\n        else:\n            data_dict[\"color\"] = data_dict[\"color\"].astype(np.float32)\n\n        hsv = RandomColorJitter.rgb2hsv(data_dict[\"color\"][:, :3])\n        hue_val = np.random.uniform(-self.hue_max, self.hue_max)\n        sat_ratio = 1 + np.random.uniform(-self.saturation_max, self.saturation_max)\n        hsv[..., 0] = np.remainder(hue_val + hsv[..., 0] + 1, 1)\n        hsv[..., 1] = np.clip(sat_ratio * hsv[..., 1], 0, 1)\n\n        data_dict[\"color\"][:, :3] = np.clip(RandomColorJitter.hsv2rgb(hsv), 0, 1.0)\n        if self.range255:\n            data_dict[\"color\"] = (data_dict[\"color\"] * 255.).round().astype(dtype)\n        else:\n            data_dict[\"color\"] = data_dict[\"color\"].astype(dtype)\n\n    return data_dict\n</code></pre>"},{"location":"color/#randomcoloraugment","title":"RandomColorAugment","text":"<p>Apply a simple global color scaling to point colors.</p> <p>This transform expects a dictionary containing:</p> <ul> <li><code>\"color\"</code>: NumPy array of shape (N, 3) with point color values.</li> </ul> <p>It multiplies the color values by <code>color_augment</code> and clips them to a valid range:</p> <ul> <li>If <code>range255=True</code> \u2192 values are clipped to <code>[0, 255]</code>.</li> <li>If <code>range255=False</code> \u2192 values are clipped to <code>[0, 1]</code>.</li> </ul> <p>Parameters:</p> Name Type Description Default <code>color_augment</code> <code>float</code> <p>Multiplicative scaling factor applied to all color channels (e.g., 1.1 to slightly brighten, 0.9 to slightly darken). Defaults to 1.1.</p> <code>1.1</code> <code>range255</code> <code>bool</code> <p>Whether the input color values are in <code>[0, 255]</code>. If True, clipping is done in that range. If False, clipping is done in <code>[0, 1]</code>. Defaults to False.</p> <code>False</code> <code>apply_p</code> <code>float</code> <p>Probability of applying the color scaling. Defaults to 1.0.</p> <code>1.0</code> Source code in <code>src\\augmentation_class.py</code> <pre><code>@TRANSFORMS.register()\nclass RandomColorAugment:\n    \"\"\"Apply a simple global color scaling to point colors.\n\n    This transform expects a dictionary containing:\n\n    * `\"color\"`: NumPy array of shape (N, 3) with point color values.\n\n    It multiplies the color values by ``color_augment`` and clips them to a valid range:\n\n    * If ``range255=True`` \u2192 values are clipped to ``[0, 255]``.\n    * If ``range255=False`` \u2192 values are clipped to ``[0, 1]``.\n\n    Args:\n        color_augment (float, optional):\n            Multiplicative scaling factor applied to all color channels (e.g., 1.1 to slightly brighten, 0.9 to slightly darken).\n            Defaults to 1.1.\n        range255 (bool, optional):\n            Whether the input color values are in ``[0, 255]``. If True, clipping is done in that range. If False,\n            clipping is done in ``[0, 1]``.\n            Defaults to False.\n        apply_p (float, optional):\n            Probability of applying the color scaling.\n            Defaults to 1.0.\n    \"\"\"\n    def __init__(self, color_augment: float = 1.1, range255=False, apply_p: float = 1.0):\n        self.color_augment = color_augment\n        self.range255 = range255\n        self.apply_p = apply_p\n\n    def __call__(self, data_dict: dict) -&gt; dict:\n        \"\"\"Apply global color scaling to the `\"color\"` entry in `data_dict`.\n\n        Args:\n            data_dict (dict): Input dictionary that must contain a `\"color\"` key with a NumPy array of shape (N, 3)\n                representing point color values.\n\n        Returns:\n            dict: The same dictionary with `\"color\"` updated in-place, if applied.\n        \"\"\"\n        if random.random() &gt; self.apply_p:\n            return data_dict\n\n        if \"color\" in data_dict.keys():\n            dtype = data_dict[\"color\"].dtype\n            if self.range255:\n                target_range = 255.0\n            else:\n                target_range = 1.0\n\n            data_dict[\"color\"] = np.clip(data_dict[\"color\"] * self.color_augment, 0, target_range).astype(dtype)\n\n        return data_dict\n</code></pre> <p>Random Augment PC Colors</p> <p> </p>"},{"location":"color/#augmentation_class.RandomColorAugment.__call__","title":"<code>__call__(data_dict)</code>","text":"<p>Apply global color scaling to the <code>\"color\"</code> entry in <code>data_dict</code>.</p> <p>Parameters:</p> Name Type Description Default <code>data_dict</code> <code>dict</code> <p>Input dictionary that must contain a <code>\"color\"</code> key with a NumPy array of shape (N, 3) representing point color values.</p> required <p>Returns:</p> Name Type Description <code>dict</code> <code>dict</code> <p>The same dictionary with <code>\"color\"</code> updated in-place, if applied.</p> Source code in <code>src\\augmentation_class.py</code> <pre><code>def __call__(self, data_dict: dict) -&gt; dict:\n    \"\"\"Apply global color scaling to the `\"color\"` entry in `data_dict`.\n\n    Args:\n        data_dict (dict): Input dictionary that must contain a `\"color\"` key with a NumPy array of shape (N, 3)\n            representing point color values.\n\n    Returns:\n        dict: The same dictionary with `\"color\"` updated in-place, if applied.\n    \"\"\"\n    if random.random() &gt; self.apply_p:\n        return data_dict\n\n    if \"color\" in data_dict.keys():\n        dtype = data_dict[\"color\"].dtype\n        if self.range255:\n            target_range = 255.0\n        else:\n            target_range = 1.0\n\n        data_dict[\"color\"] = np.clip(data_dict[\"color\"] * self.color_augment, 0, target_range).astype(dtype)\n\n    return data_dict\n</code></pre>"},{"location":"coord/","title":"Coordinate","text":"<p>Classes for point coordinates</p>"},{"location":"coord/#normalizecoord","title":"NormalizeCoord","text":"<p>Normalizes the point cloud into a unit sphere, where the center is the mean of the point set.</p> <p>This transform expects a dictionary containing:</p> <ul> <li><code>\"coord\"</code>: NumPy array of shape (N, 3) with point coordinates.</li> </ul> Source code in <code>src\\augmentation_class.py</code> <pre><code>@TRANSFORMS.register()\nclass NormalizeCoord:\n    \"\"\"Normalizes the point cloud into a unit sphere, where the center is the mean of the point set.\n\n    This transform expects a dictionary containing:\n\n    * `\"coord\"`: NumPy array of shape (N, 3) with point coordinates.\n    \"\"\"\n    def __call__(self, data_dict: dict) -&gt; dict:\n        \"\"\"Normalizes point cloud coordinates into unit sphere.\n\n        Args:\n            data_dict (dict): Input dictionary that contains a \"coord\" key with a NumPy array of shape (N, 3) representing point coordinates.\n\n        Returns:\n            dict: The same dictionary with `\"coord\"` normalized into a unit sphere.\n        \"\"\"\n        if \"coord\" in data_dict.keys():\n            centroid = np.mean(data_dict[\"coord\"], axis=0)\n            data_dict[\"coord\"] -= centroid\n            # m = np.max(np.sqrt(np.sum(data_dict[\"coord\"] ** 2, axis=1)))\n            m = np.sqrt(np.max(np.sum(data_dict[\"coord\"] ** 2, axis=1)))\n            data_dict[\"coord\"] = data_dict[\"coord\"] / m\n\n        return data_dict\n</code></pre> <p>Normalize PC into Unit Sphere Space</p> <p> </p>"},{"location":"coord/#augmentation_class.NormalizeCoord.__call__","title":"<code>__call__(data_dict)</code>","text":"<p>Normalizes point cloud coordinates into unit sphere.</p> <p>Parameters:</p> Name Type Description Default <code>data_dict</code> <code>dict</code> <p>Input dictionary that contains a \"coord\" key with a NumPy array of shape (N, 3) representing point coordinates.</p> required <p>Returns:</p> Name Type Description <code>dict</code> <code>dict</code> <p>The same dictionary with <code>\"coord\"</code> normalized into a unit sphere.</p> Source code in <code>src\\augmentation_class.py</code> <pre><code>def __call__(self, data_dict: dict) -&gt; dict:\n    \"\"\"Normalizes point cloud coordinates into unit sphere.\n\n    Args:\n        data_dict (dict): Input dictionary that contains a \"coord\" key with a NumPy array of shape (N, 3) representing point coordinates.\n\n    Returns:\n        dict: The same dictionary with `\"coord\"` normalized into a unit sphere.\n    \"\"\"\n    if \"coord\" in data_dict.keys():\n        centroid = np.mean(data_dict[\"coord\"], axis=0)\n        data_dict[\"coord\"] -= centroid\n        # m = np.max(np.sqrt(np.sum(data_dict[\"coord\"] ** 2, axis=1)))\n        m = np.sqrt(np.max(np.sum(data_dict[\"coord\"] ** 2, axis=1)))\n        data_dict[\"coord\"] = data_dict[\"coord\"] / m\n\n    return data_dict\n</code></pre>"},{"location":"coord/#positiveshift","title":"PositiveShift","text":"<p>Shift point coordinates so all values are non-negative.</p> <p>This transform expects a dictionary containing:</p> <ul> <li><code>\"coord\"</code>: NumPy array of shape (N, 3) with point coordinates.</li> </ul> Source code in <code>src\\augmentation_class.py</code> <pre><code>@TRANSFORMS.register()\nclass PositiveShift:\n    \"\"\"Shift point coordinates so all values are non-negative.\n\n    This transform expects a dictionary containing:\n\n    * `\"coord\"`: NumPy array of shape (N, 3) with point coordinates.\n    \"\"\"\n    def __call__(self, data_dict: dict) -&gt; dict:\n        \"\"\"Moves points so that all coordinate values become non-negative.\n\n        Args:\n            data_dict (dict): Input dictionary that must contain a \"coord\" key\n                with a NumPy array of shape (N, 3) representing point\n                coordinates.\n\n        Returns:\n            dict:\n                The same dictionary with \"coord\" shifted so all values are greater than or equal to zero.\n        \"\"\"\n        if \"coord\" in data_dict.keys():\n            coord_min = np.min(data_dict[\"coord\"], axis=0)\n            data_dict[\"coord\"] -= coord_min\n        return data_dict\n</code></pre> <p>Positive Shift PC</p> <p> </p>"},{"location":"coord/#augmentation_class.PositiveShift.__call__","title":"<code>__call__(data_dict)</code>","text":"<p>Moves points so that all coordinate values become non-negative.</p> <p>Parameters:</p> Name Type Description Default <code>data_dict</code> <code>dict</code> <p>Input dictionary that must contain a \"coord\" key with a NumPy array of shape (N, 3) representing point coordinates.</p> required <p>Returns:</p> Name Type Description <code>dict</code> <code>dict</code> <p>The same dictionary with \"coord\" shifted so all values are greater than or equal to zero.</p> Source code in <code>src\\augmentation_class.py</code> <pre><code>def __call__(self, data_dict: dict) -&gt; dict:\n    \"\"\"Moves points so that all coordinate values become non-negative.\n\n    Args:\n        data_dict (dict): Input dictionary that must contain a \"coord\" key\n            with a NumPy array of shape (N, 3) representing point\n            coordinates.\n\n    Returns:\n        dict:\n            The same dictionary with \"coord\" shifted so all values are greater than or equal to zero.\n    \"\"\"\n    if \"coord\" in data_dict.keys():\n        coord_min = np.min(data_dict[\"coord\"], axis=0)\n        data_dict[\"coord\"] -= coord_min\n    return data_dict\n</code></pre>"},{"location":"coord/#centershift","title":"CenterShift","text":"<p>Translate point coordinates so they are centered around a reference point.</p> <p>This transform expects a dictionary containing:</p> <ul> <li><code>\"coord\"</code>: NumPy array of shape (N, 3) with point coordinates.</li> </ul> <p>It computes a shift vector and subtracts it from all coordinates in place. There are two ways to define the shift:</p> <ul> <li>Mean-based centering (<code>mean=True</code>):</li> <li>The shift is the mean (centroid) of all points along each axis.</li> <li> <p>If <code>apply_z</code> is False, the z-component of the shift is replaced by the minimum z value of the points, so:</p> <ul> <li>x and y are centered by their mean.</li> <li>z is shifted so that the lowest point lies at z = 0.</li> </ul> </li> <li> <p>Bounding-box centering (<code>mean=False</code>):</p> </li> <li>The shift is the center of the axis-aligned bounding box (AABB), i.e., the midpoint between min and max along each axis.</li> <li>If <code>apply_z</code> is False, the z-component of the shift is set to the minimum z value of the points, so the bottom of the bounding box is at z = 0.</li> </ul> <p>Parameters:</p> Name Type Description Default <code>mean</code> <code>bool</code> <p>If True, use the mean of the coordinates as the shift (centroid). If False, use the center of the bounding box. Defaults to False.</p> <code>False</code> <code>apply_z</code> <code>bool</code> <p>If True, apply the same centering logic to the z-axis as x and y. If False, the z shift is always set to the minimum z value, so the lowest point (or bottom of the bounding box) sits at z = 0. Defaults to True.</p> <code>True</code> Source code in <code>src\\augmentation_class.py</code> <pre><code>@TRANSFORMS.register()\nclass CenterShift:\n    \"\"\"Translate point coordinates so they are centered around a reference point.\n\n    This transform expects a dictionary containing:\n\n    * `\"coord\"`: NumPy array of shape (N, 3) with point coordinates.\n\n    It computes a shift vector and subtracts it from all coordinates in place.\n    There are two ways to define the shift:\n\n    * Mean-based centering (``mean=True``):\n      - The shift is the mean (centroid) of all points along each axis.\n      - If ``apply_z`` is False, the z-component of the shift is replaced by the minimum z value of the points, so:\n        - x and y are centered by their mean.\n        - z is shifted so that the lowest point lies at z = 0.\n\n    * Bounding-box centering (``mean=False``):\n      - The shift is the center of the axis-aligned bounding box (AABB), i.e., the midpoint between min and max along each axis.\n      - If ``apply_z`` is False, the z-component of the shift is set to the minimum z value of the points, so the bottom of the bounding box is at z = 0.\n\n    Args:\n        mean (bool, optional): If True, use the mean of the coordinates as the\n            shift (centroid). If False, use the center of the bounding box.\n            Defaults to False.\n        apply_z (bool, optional): If True, apply the same centering logic to\n            the z-axis as x and y. If False, the z shift is always set to the\n            minimum z value, so the lowest point (or bottom of the bounding\n            box) sits at z = 0.\n            Defaults to True.\n    \"\"\"\n    def __init__(self, mean: bool = False, apply_z: bool = True):\n        self.mean = mean\n        self.apply_z = apply_z\n\n    def __call__(self, data_dict: dict) -&gt; dict:\n        \"\"\"Center the point cloud coordinates in place.\n\n            Args:\n                data_dict (dict): Input dictionary that must contain a `\"coord\"` key with a NumPy array of shape (N, 3) representing point coordinates.\n\n            Returns:\n                dict: The same dictionary with `\"coord\"` translated according to the centering strategy.\n        \"\"\"\n        if \"coord\" in data_dict.keys():\n            if self.mean:\n                shift = np.mean(data_dict[\"coord\"], axis=0)\n                if not self.apply_z:\n                    shift[2] = data_dict[\"coord\"].min(axis=0)[2]\n            else:\n                x_min, y_min, z_min = data_dict[\"coord\"].min(axis=0)\n                x_max, y_max, z_max = data_dict[\"coord\"].max(axis=0)\n                if self.apply_z:\n                    shift = [(x_min + x_max) / 2, (y_min + y_max) / 2, (z_min + z_max) / 2]\n                else:\n                    shift = [(x_min + x_max) / 2, (y_min + y_max) / 2, z_min]\n            data_dict[\"coord\"] -= shift\n        return data_dict\n</code></pre> <p>Center Shift PC</p> <p> </p>"},{"location":"coord/#augmentation_class.CenterShift.__call__","title":"<code>__call__(data_dict)</code>","text":"<p>Center the point cloud coordinates in place.</p> <p>Parameters:</p> Name Type Description Default <code>data_dict</code> <code>dict</code> <p>Input dictionary that must contain a <code>\"coord\"</code> key with a NumPy array of shape (N, 3) representing point coordinates.</p> required <p>Returns:</p> Name Type Description <code>dict</code> <code>dict</code> <p>The same dictionary with <code>\"coord\"</code> translated according to the centering strategy.</p> Source code in <code>src\\augmentation_class.py</code> <pre><code>def __call__(self, data_dict: dict) -&gt; dict:\n    \"\"\"Center the point cloud coordinates in place.\n\n        Args:\n            data_dict (dict): Input dictionary that must contain a `\"coord\"` key with a NumPy array of shape (N, 3) representing point coordinates.\n\n        Returns:\n            dict: The same dictionary with `\"coord\"` translated according to the centering strategy.\n    \"\"\"\n    if \"coord\" in data_dict.keys():\n        if self.mean:\n            shift = np.mean(data_dict[\"coord\"], axis=0)\n            if not self.apply_z:\n                shift[2] = data_dict[\"coord\"].min(axis=0)[2]\n        else:\n            x_min, y_min, z_min = data_dict[\"coord\"].min(axis=0)\n            x_max, y_max, z_max = data_dict[\"coord\"].max(axis=0)\n            if self.apply_z:\n                shift = [(x_min + x_max) / 2, (y_min + y_max) / 2, (z_min + z_max) / 2]\n            else:\n                shift = [(x_min + x_max) / 2, (y_min + y_max) / 2, z_min]\n        data_dict[\"coord\"] -= shift\n    return data_dict\n</code></pre>"},{"location":"coord/#randomshift","title":"RandomShift","text":"<p>Randomly translate point coordinates along the x, y, and z axes.</p> <p>This transform expects a dictionary containing:</p> <ul> <li><code>\"coord\"</code>: NumPy array of shape (N, 3) with point coordinates.</li> </ul> <p>It samples a random shift for each axis from the corresponding interval in <code>shift</code> and adds it to all points in place.</p> <p>Parameters:</p> Name Type Description Default <code>shift</code> <code>tuple[tuple[float, float], tuple[float, float], tuple[float, float]]</code> <p>A tuple of three <code>(min, max)</code> pairs controlling the uniform sampling range of the shift per axis:</p> <ul> <li><code>shift[0]</code> \u2192 (x_min, x_max) for the x-axis shift.</li> <li><code>shift[1]</code> \u2192 (y_min, y_max) for the y-axis shift.</li> <li><code>shift[2]</code> \u2192 (z_min, z_max) for the z-axis shift.</li> </ul> <p>Each shift value is sampled from a uniform distribution: <code>np.random.uniform(min, max)</code>.</p> <p>With the default configuration:</p> <ul> <li>x ~ U(-0.02, 0.02)</li> <li>y ~ U(-0.02, 0.02)</li> <li>z ~ U( 0.02, 0.02)</li> </ul> <p>Defaults to <code>((-0.02, 0.02), (-0.02, 0.02), (0.02, 0.02))</code>.</p> <code>((-0.02, 0.02), (-0.02, 0.02), (0.02, 0.02))</code> <code>apply_p</code> <code>float</code> <p>Probability of applying the random shift. Defaults to 1.0.</p> <code>1.0</code> Source code in <code>src\\augmentation_class.py</code> <pre><code>@TRANSFORMS.register()\nclass RandomShift:\n    \"\"\"Randomly translate point coordinates along the x, y, and z axes.\n\n    This transform expects a dictionary containing:\n\n    * `\"coord\"`: NumPy array of shape (N, 3) with point coordinates.\n\n    It samples a random shift for each axis from the corresponding interval in `shift` and adds it to all points in place.\n\n    Args:\n        shift (tuple[tuple[float, float], tuple[float, float], tuple[float, float]], optional):\n            A tuple of three `(min, max)` pairs controlling the uniform sampling\n            range of the shift per axis:\n\n            * `shift[0]` \u2192 (x_min, x_max) for the x-axis shift.\n            * `shift[1]` \u2192 (y_min, y_max) for the y-axis shift.\n            * `shift[2]` \u2192 (z_min, z_max) for the z-axis shift.\n\n            Each shift value is sampled from a uniform distribution:\n            `np.random.uniform(min, max)`.\n\n            With the default configuration:\n\n            * x ~ U(-0.02, 0.02)\n            * y ~ U(-0.02, 0.02)\n            * z ~ U( 0.02, 0.02)\n\n            Defaults to `((-0.02, 0.02), (-0.02, 0.02), (0.02, 0.02))`.\n        apply_p (float, optional): Probability of applying the random shift.\n            Defaults to 1.0.\n    \"\"\"\n    def __init__(self, shift: tuple[tuple[float, float]] = ((-0.02, 0.02), (-0.02, 0.02), (0.02, 0.02)), apply_p: float = 1.0):\n        self.shift = shift\n        self.apply_p = apply_p\n\n    def __call__(self, data_dict: dict) -&gt; dict:\n        \"\"\"Apply a random global shift to the point coordinates.\n\n        Args:\n            data_dict (dict): Input dictionary that must contain a `\"coord\"` key\n                with a NumPy array of shape (N, 3) representing point\n                coordinates.\n\n        Returns:\n            dict: The same dictionary with `\"coord\"` translated by a random shift vector, if applied.\n        \"\"\"\n        if random.random() &gt; self.apply_p:\n            return data_dict\n\n        if \"coord\" in data_dict.keys():\n            shift_x = np.random.uniform(self.shift[0][0], self.shift[0][1])\n            shift_y = np.random.uniform(self.shift[1][0], self.shift[1][1])\n            shift_z = np.random.uniform(self.shift[2][0], self.shift[2][1])\n            data_dict[\"coord\"] += [shift_x, shift_y, shift_z]\n        return data_dict\n</code></pre> <p>Random Shift PC</p> <p> </p>"},{"location":"coord/#augmentation_class.RandomShift.__call__","title":"<code>__call__(data_dict)</code>","text":"<p>Apply a random global shift to the point coordinates.</p> <p>Parameters:</p> Name Type Description Default <code>data_dict</code> <code>dict</code> <p>Input dictionary that must contain a <code>\"coord\"</code> key with a NumPy array of shape (N, 3) representing point coordinates.</p> required <p>Returns:</p> Name Type Description <code>dict</code> <code>dict</code> <p>The same dictionary with <code>\"coord\"</code> translated by a random shift vector, if applied.</p> Source code in <code>src\\augmentation_class.py</code> <pre><code>def __call__(self, data_dict: dict) -&gt; dict:\n    \"\"\"Apply a random global shift to the point coordinates.\n\n    Args:\n        data_dict (dict): Input dictionary that must contain a `\"coord\"` key\n            with a NumPy array of shape (N, 3) representing point\n            coordinates.\n\n    Returns:\n        dict: The same dictionary with `\"coord\"` translated by a random shift vector, if applied.\n    \"\"\"\n    if random.random() &gt; self.apply_p:\n        return data_dict\n\n    if \"coord\" in data_dict.keys():\n        shift_x = np.random.uniform(self.shift[0][0], self.shift[0][1])\n        shift_y = np.random.uniform(self.shift[1][0], self.shift[1][1])\n        shift_z = np.random.uniform(self.shift[2][0], self.shift[2][1])\n        data_dict[\"coord\"] += [shift_x, shift_y, shift_z]\n    return data_dict\n</code></pre>"},{"location":"coord/#randomrotate","title":"RandomRotate","text":"<p>Randomly rotate 3D points (and optionally normals) around a given axis.</p> <p>This transform expects a dictionary containing:</p> <ul> <li><code>\"coord\"</code>: NumPy array of shape (N, 3) with point coordinates.</li> <li>Optionally <code>\"norm\"</code>: NumPy array of shape (N, 3) with normals associated with each point.</li> </ul> <p>The transform samples a rotation angle (in degrees) from <code>angle</code>, builds a rotation matrix around the specified axis, and applies it to the coordinates (and normals, if present). The rotation is applied around a center point:</p> <ul> <li>If <code>center</code> is <code>None</code>, the rotation center is taken as the center of the axis-aligned bounding box (AABB) of the coordinates.</li> <li>If <code>center</code> is provided, it is used directly as the rotation center.</li> </ul> <p>Parameters:</p> Name Type Description Default <code>angle</code> <code>tuple[float, float] | None</code> <p>A <code>(min_deg, max_deg)</code> pair specifying the range of rotation angles in degrees. The actual angle is sampled uniformly from this interval and converted to radians internally. If <code>None</code> (default), it is set to <code>(-180, 180)</code>. For example, <code>angle=(-10, 10)</code> means a random rotation between -10\u00b0 and +10\u00b0. Defaults to None.</p> <code>None</code> <code>center</code> <code>tuple[float, float, float] | ndarray | None</code> <p>Rotation center in 3D, given as a 3-element tuple or NumPy array <code>(cx, cy, cz)</code>. If <code>None</code> (default), the center of the bounding box of <code>data_dict[\"coord\"]</code> is used: <code>center = ((x_min+x_max)/2, (y_min+y_max)/2, (z_min+z_max)/2)</code>. Defaults to None.</p> <code>None</code> <code>axis</code> <code>str</code> <p>Axis (or axes) around which the rotation is applied. One of <code>\"x\"</code>, <code>\"y\"</code>, <code>\"z\"</code>, or <code>\"xyz\"</code>.</p> <ul> <li><code>\"x\"</code>: single rotation around the x-axis.</li> <li><code>\"y\"</code>: single rotation around the y-axis.</li> <li><code>\"z\"</code>: single rotation around the z-axis.</li> <li><code>\"xyz\"</code>: three independent random rotations are sampled   (one for x, one for y, one for z), and the final rotation   matrix is computed as <code>R = R_z @ R_y @ R_x</code>.</li> </ul> <p>In all cases, angles are sampled (in degrees) from the same <code>angle</code> range. Defaults to <code>\"y\"</code>.</p> <code>'y'</code> <code>apply_p</code> <code>float</code> <p>Probability of applying the rotation. Defaults to 1.0.</p> <code>1.0</code> Source code in <code>src\\augmentation_class.py</code> <pre><code>@TRANSFORMS.register()\nclass RandomRotate:\n    \"\"\"Randomly rotate 3D points (and optionally normals) around a given axis.\n\n    This transform expects a dictionary containing:\n\n    * `\"coord\"`: NumPy array of shape (N, 3) with point coordinates.\n    * Optionally `\"norm\"`: NumPy array of shape (N, 3) with normals associated with each point.\n\n    The transform samples a rotation angle (in degrees) from `angle`, builds a rotation matrix around the specified axis,\n    and applies it to the coordinates (and normals, if present). The rotation is applied around a center point:\n\n    * If `center` is ``None``, the rotation center is taken as the center of the axis-aligned bounding box (AABB) of the coordinates.\n    * If `center` is provided, it is used directly as the rotation center.\n\n    Args:\n        angle (tuple[float, float] | None, optional):\n            A `(min_deg, max_deg)` pair specifying the range of rotation angles in degrees. The actual angle is sampled\n            uniformly from this interval and converted to radians internally. If ``None`` (default), it is set to\n            `(-180, 180)`. For example, `angle=(-10, 10)` means a random\n            rotation between -10\u00b0 and +10\u00b0.\n            Defaults to None.\n        center (tuple[float, float, float] | np.ndarray | None, optional):\n            Rotation center in 3D, given as a 3-element tuple or NumPy array\n            `(cx, cy, cz)`. If ``None`` (default), the center of the bounding\n            box of `data_dict[\"coord\"]` is used:\n            `center = ((x_min+x_max)/2, (y_min+y_max)/2, (z_min+z_max)/2)`.\n            Defaults to None.\n        axis (str, optional):\n            Axis (or axes) around which the rotation is applied. One of `\"x\"`, `\"y\"`, `\"z\"`, or `\"xyz\"`.\n\n            * `\"x\"`: single rotation around the x-axis.\n            * `\"y\"`: single rotation around the y-axis.\n            * `\"z\"`: single rotation around the z-axis.\n            * `\"xyz\"`: three independent random rotations are sampled\n              (one for x, one for y, one for z), and the final rotation\n              matrix is computed as `R = R_z @ R_y @ R_x`.\n\n            In all cases, angles are sampled (in degrees) from the same\n            `angle` range.\n            Defaults to `\"y\"`.\n        apply_p (float, optional): Probability of applying the rotation.\n            Defaults to 1.0.\n        \"\"\"\n    def __init__(self,\n                 angle: tuple = None,\n                 center: tuple | np.ndarray = None,\n                 axis: str = 'y',\n                 apply_p: float = 1.0,\n                 ) -&gt; None:\n\n        self.angle = (-180, 180) if angle is None else angle\n        self.center = np.array(center) if center is not None else center\n        self.axis = axis\n        self.apply_p = apply_p\n\n    def __call__(self, data_dict: dict) -&gt; dict:\n        \"\"\"Apply a random rotation to coordinates (and normals, if present).\n\n        Args:\n            data_dict (dict): Input dictionary that must contain a `\"coord\"` key with a NumPy array of shape (N, 3)\n                representing point coordinates. Optionally may contain `\"norm\"` with a NumPy array of shape (N, 3)\n                representing normal vectors.\n\n        Returns:\n            dict: The same dictionary with `\"coord\"` rotated around the chosen center, and `\"norm\"` rotated if present.\n        \"\"\"\n        if random.random() &gt; self.apply_p:\n            return data_dict\n\n        # angle = np.random.uniform(self.angle[0], self.angle[1]) * np.pi\n        angle = np.random.uniform(self.angle[0], self.angle[1])\n        angle = np.deg2rad(angle)\n        rot_cos, rot_sin = np.cos(angle), np.sin(angle)\n        if self.axis == 'x':\n            rot_t = np.array([[1, 0, 0], [0, rot_cos, -rot_sin], [0, rot_sin, rot_cos]])\n        elif self.axis == 'y':\n            rot_t = np.array([[rot_cos, 0, rot_sin], [0, 1, 0], [-rot_sin, 0, rot_cos]])\n        elif self.axis == 'z':\n            rot_t = np.array([[rot_cos, -rot_sin, 0], [rot_sin, rot_cos, 0], [0, 0, 1]])\n        elif self.axis == \"xyz\":\n            angle = np.random.uniform(self.angle[0], self.angle[1])\n            angle = np.deg2rad(angle)\n            rot_cos, rot_sin = np.cos(angle), np.sin(angle)\n            rot_x = np.array([[1, 0, 0], [0, rot_cos, -rot_sin], [0, rot_sin, rot_cos]])\n\n            angle = np.random.uniform(self.angle[0], self.angle[1])\n            angle = np.deg2rad(angle)\n            rot_cos, rot_sin = np.cos(angle), np.sin(angle)\n            rot_y = np.array([[rot_cos, 0, rot_sin], [0, 1, 0], [-rot_sin, 0, rot_cos]])\n\n            angle = np.random.uniform(self.angle[0], self.angle[1])\n            angle = np.deg2rad(angle)\n            rot_cos, rot_sin = np.cos(angle), np.sin(angle)\n            rot_z = np.array([[rot_cos, -rot_sin, 0], [rot_sin, rot_cos, 0], [0, 0, 1]])\n            rot_t = rot_z @ rot_y @ rot_x\n        else:\n            raise NotImplementedError\n\n        if \"coord\" in data_dict.keys():\n            if self.center is None:\n                # rotate by the center point\n                x_min, y_min, z_min = data_dict[\"coord\"].min(axis=0)\n                x_max, y_max, z_max = data_dict[\"coord\"].max(axis=0)\n                center = [(x_min + x_max) / 2, (y_min + y_max) / 2, (z_min + z_max) / 2]\n            else:\n                center = self.center\n            data_dict[\"coord\"] -= center\n            data_dict[\"coord\"] = np.dot(data_dict[\"coord\"], np.transpose(rot_t))\n            data_dict[\"coord\"] += center\n\n        if \"norm\" in data_dict.keys():\n            data_dict[\"norm\"] = np.dot(data_dict[\"norm\"], np.transpose(rot_t))\n\n        return data_dict\n</code></pre> <p>Random Rotate PC</p> <p> </p>"},{"location":"coord/#augmentation_class.RandomRotate.__call__","title":"<code>__call__(data_dict)</code>","text":"<p>Apply a random rotation to coordinates (and normals, if present).</p> <p>Parameters:</p> Name Type Description Default <code>data_dict</code> <code>dict</code> <p>Input dictionary that must contain a <code>\"coord\"</code> key with a NumPy array of shape (N, 3) representing point coordinates. Optionally may contain <code>\"norm\"</code> with a NumPy array of shape (N, 3) representing normal vectors.</p> required <p>Returns:</p> Name Type Description <code>dict</code> <code>dict</code> <p>The same dictionary with <code>\"coord\"</code> rotated around the chosen center, and <code>\"norm\"</code> rotated if present.</p> Source code in <code>src\\augmentation_class.py</code> <pre><code>def __call__(self, data_dict: dict) -&gt; dict:\n    \"\"\"Apply a random rotation to coordinates (and normals, if present).\n\n    Args:\n        data_dict (dict): Input dictionary that must contain a `\"coord\"` key with a NumPy array of shape (N, 3)\n            representing point coordinates. Optionally may contain `\"norm\"` with a NumPy array of shape (N, 3)\n            representing normal vectors.\n\n    Returns:\n        dict: The same dictionary with `\"coord\"` rotated around the chosen center, and `\"norm\"` rotated if present.\n    \"\"\"\n    if random.random() &gt; self.apply_p:\n        return data_dict\n\n    # angle = np.random.uniform(self.angle[0], self.angle[1]) * np.pi\n    angle = np.random.uniform(self.angle[0], self.angle[1])\n    angle = np.deg2rad(angle)\n    rot_cos, rot_sin = np.cos(angle), np.sin(angle)\n    if self.axis == 'x':\n        rot_t = np.array([[1, 0, 0], [0, rot_cos, -rot_sin], [0, rot_sin, rot_cos]])\n    elif self.axis == 'y':\n        rot_t = np.array([[rot_cos, 0, rot_sin], [0, 1, 0], [-rot_sin, 0, rot_cos]])\n    elif self.axis == 'z':\n        rot_t = np.array([[rot_cos, -rot_sin, 0], [rot_sin, rot_cos, 0], [0, 0, 1]])\n    elif self.axis == \"xyz\":\n        angle = np.random.uniform(self.angle[0], self.angle[1])\n        angle = np.deg2rad(angle)\n        rot_cos, rot_sin = np.cos(angle), np.sin(angle)\n        rot_x = np.array([[1, 0, 0], [0, rot_cos, -rot_sin], [0, rot_sin, rot_cos]])\n\n        angle = np.random.uniform(self.angle[0], self.angle[1])\n        angle = np.deg2rad(angle)\n        rot_cos, rot_sin = np.cos(angle), np.sin(angle)\n        rot_y = np.array([[rot_cos, 0, rot_sin], [0, 1, 0], [-rot_sin, 0, rot_cos]])\n\n        angle = np.random.uniform(self.angle[0], self.angle[1])\n        angle = np.deg2rad(angle)\n        rot_cos, rot_sin = np.cos(angle), np.sin(angle)\n        rot_z = np.array([[rot_cos, -rot_sin, 0], [rot_sin, rot_cos, 0], [0, 0, 1]])\n        rot_t = rot_z @ rot_y @ rot_x\n    else:\n        raise NotImplementedError\n\n    if \"coord\" in data_dict.keys():\n        if self.center is None:\n            # rotate by the center point\n            x_min, y_min, z_min = data_dict[\"coord\"].min(axis=0)\n            x_max, y_max, z_max = data_dict[\"coord\"].max(axis=0)\n            center = [(x_min + x_max) / 2, (y_min + y_max) / 2, (z_min + z_max) / 2]\n        else:\n            center = self.center\n        data_dict[\"coord\"] -= center\n        data_dict[\"coord\"] = np.dot(data_dict[\"coord\"], np.transpose(rot_t))\n        data_dict[\"coord\"] += center\n\n    if \"norm\" in data_dict.keys():\n        data_dict[\"norm\"] = np.dot(data_dict[\"norm\"], np.transpose(rot_t))\n\n    return data_dict\n</code></pre>"},{"location":"coord/#randomscale","title":"RandomScale","text":"<p>Randomly scale 3D coordinates uniformly or per-axis.</p> <p>This transform expects a dictionary containing:</p> <ul> <li><code>\"coord\"</code>: NumPy array of shape (N, 3) with point coordinates.</li> </ul> <p>It samples a scale factor (or factors) from <code>scale</code> and multiplies the coordinates in place.</p> <p>Parameters:</p> Name Type Description Default <code>scale</code> <code>list[float, float] | tuple[float, float]</code> <p>A <code>(min_scale, max_scale)</code> pair used as the uniform sampling range for the scale factor(s). Values are drawn from <code>np.random.uniform(min_scale, max_scale, size=...)</code>.</p> <p>Examples:     * <code>scale=(0.95, 1.05)</code> \u2192 small random resize around 1.0.     * <code>scale=(0.5, 1.5)</code> \u2192 more aggressive zoom in/out.</p> <p>Defaults to <code>(0.95, 1.05)</code>.</p> <code>(0.95, 1.05)</code> <code>anisotropic</code> <code>bool</code> <p>Controls whether scaling is uniform or per-axis.</p> <ul> <li><code>False</code>: Sample a single scalar <code>s</code> and apply <code>coord *= s</code>.</li> <li><code>True</code>: Sample a 3D vector <code>[sx, sy, sz]</code> and apply   <code>coord *= [sx, sy, sz]</code>.</li> </ul> <p>Defaults to <code>False</code>.</p> <code>False</code> <code>apply_p</code> <code>float</code> <p>Probability of applying the random scaling. Defaults to 1.0.</p> <code>1.0</code> Source code in <code>src\\augmentation_class.py</code> <pre><code>@TRANSFORMS.register()\nclass RandomScale:\n    \"\"\"Randomly scale 3D coordinates uniformly or per-axis.\n\n    This transform expects a dictionary containing:\n\n    * `\"coord\"`: NumPy array of shape (N, 3) with point coordinates.\n\n    It samples a scale factor (or factors) from `scale` and multiplies the coordinates in place.\n\n    Args:\n        scale (list[float, float] | tuple[float, float], optional):\n            A `(min_scale, max_scale)` pair used as the uniform sampling range for the scale factor(s). Values are drawn from\n            `np.random.uniform(min_scale, max_scale, size=...)`.\n\n            Examples:\n                * `scale=(0.95, 1.05)` \u2192 small random resize around 1.0.\n                * `scale=(0.5, 1.5)` \u2192 more aggressive zoom in/out.\n\n            Defaults to `(0.95, 1.05)`.\n        anisotropic (bool, optional): Controls whether scaling is uniform or\n            per-axis.\n\n            * `False`: Sample a single scalar `s` and apply `coord *= s`.\n            * `True`: Sample a 3D vector `[sx, sy, sz]` and apply\n              `coord *= [sx, sy, sz]`.\n\n            Defaults to `False`.\n        apply_p (float, optional):\n            Probability of applying the random scaling.\n            Defaults to 1.0.\n        \"\"\"\n    def __init__(self, scale: list | tuple = (0.95, 1.05), anisotropic: bool = False, apply_p: float = 1.0) -&gt; None:\n        self.scale = scale\n        self.anisotropic = anisotropic  # create separate scale parameters or only one parameter\n        self.apply_p = apply_p\n\n    def __call__(self, data_dict: dict) -&gt; dict:\n        \"\"\"Apply a random scaling to the point coordinates.\n\n        Args:\n            data_dict (dict): Input dictionary that must contain a `\"coord\"` key with a NumPy array of shape (N, 3)\n                representing point coordinates.\n\n        Returns:\n            dict: The same dictionary with `\"coord\"` scaled by a random factor (uniform or per-axis), if applied.\n        \"\"\"\n        if random.random() &gt; self.apply_p:\n            return data_dict\n        if \"coord\" in data_dict.keys():\n            scale = np.random.uniform(self.scale[0], self.scale[1], size=3 if self.anisotropic else 1)\n            # print(scale)\n            data_dict[\"coord\"] *= scale\n        return data_dict\n</code></pre> <p>Random Scale PC</p> <p> </p>"},{"location":"coord/#augmentation_class.RandomScale.__call__","title":"<code>__call__(data_dict)</code>","text":"<p>Apply a random scaling to the point coordinates.</p> <p>Parameters:</p> Name Type Description Default <code>data_dict</code> <code>dict</code> <p>Input dictionary that must contain a <code>\"coord\"</code> key with a NumPy array of shape (N, 3) representing point coordinates.</p> required <p>Returns:</p> Name Type Description <code>dict</code> <code>dict</code> <p>The same dictionary with <code>\"coord\"</code> scaled by a random factor (uniform or per-axis), if applied.</p> Source code in <code>src\\augmentation_class.py</code> <pre><code>def __call__(self, data_dict: dict) -&gt; dict:\n    \"\"\"Apply a random scaling to the point coordinates.\n\n    Args:\n        data_dict (dict): Input dictionary that must contain a `\"coord\"` key with a NumPy array of shape (N, 3)\n            representing point coordinates.\n\n    Returns:\n        dict: The same dictionary with `\"coord\"` scaled by a random factor (uniform or per-axis), if applied.\n    \"\"\"\n    if random.random() &gt; self.apply_p:\n        return data_dict\n    if \"coord\" in data_dict.keys():\n        scale = np.random.uniform(self.scale[0], self.scale[1], size=3 if self.anisotropic else 1)\n        # print(scale)\n        data_dict[\"coord\"] *= scale\n    return data_dict\n</code></pre>"},{"location":"coord/#randomtranslate","title":"RandomTranslate","text":"<p>Randomly translate 3D coordinates by the same offset vector along x, y, z.</p> <p>This transform expects a dictionary containing:</p> <ul> <li><code>\"coord\"</code>: NumPy array of shape (N, 3) with point coordinates.</li> </ul> <p>It samples a translation vector <code>[tx, ty, tz]</code> from the given range and adds it to all coordinates in place.</p> <p>Parameters:</p> Name Type Description Default <code>translate_range</code> <code>tuple[float, float]</code> <p>A <code>(min_translate, max_translate)</code> pair specifying the uniform sampling range for each axis. The translation vector is drawn as::</p> <p>translate = np.random.uniform(min_translate, max_translate, size=3)</p> <p>That is:</p> <ul> <li><code>tx ~ U(min_translate, max_translate)</code></li> <li><code>ty ~ U(min_translate, max_translate)</code></li> <li><code>tz ~ U(min_translate, max_translate)</code></li> </ul> <p>Defaults to <code>(-0.2, 0.2)</code>.</p> <code>(-0.2, 0.2)</code> <code>apply_p</code> <code>float</code> <p>Probability of applying the translation. Defaults to 1.0.</p> <code>1.0</code> Source code in <code>src\\augmentation_class.py</code> <pre><code>@TRANSFORMS.register()\nclass RandomTranslate:\n    \"\"\"Randomly translate 3D coordinates by the same offset vector along x, y, z.\n\n    This transform expects a dictionary containing:\n\n    * `\"coord\"`: NumPy array of shape (N, 3) with point coordinates.\n\n    It samples a translation vector `[tx, ty, tz]` from the given range and adds it to all coordinates in place.\n\n    Args:\n        translate_range (tuple[float, float], optional):\n            A `(min_translate, max_translate)` pair specifying the uniform sampling range for each axis.\n            The translation vector is drawn as::\n\n            translate = np.random.uniform(min_translate, max_translate, size=3)\n\n            That is:\n\n            * `tx ~ U(min_translate, max_translate)`\n            * `ty ~ U(min_translate, max_translate)`\n            * `tz ~ U(min_translate, max_translate)`\n\n            Defaults to `(-0.2, 0.2)`.\n        apply_p (float, optional):\n            Probability of applying the translation.\n            Defaults to 1.0.\n    \"\"\"\n    def __init__(self, translate_range: tuple = (-0.2, 0.2), apply_p: float = 1.0):\n        self.translate_range = translate_range\n        self.apply_p = apply_p\n\n    def __call__(self, data_dict: dict) -&gt; dict:\n        \"\"\"Apply a random global translation to the point coordinates.\n\n        Args:\n            data_dict (dict): Input dictionary that must contain a `\"coord\"` key with a NumPy array of shape (N, 3)\n                representing point coordinates.\n\n        Returns:\n            dict: The same dictionary with `\"coord\"` translated by a random offset vector, if applied.\n        \"\"\"\n        if random.random() &gt; self.apply_p:\n            return data_dict\n\n        if \"coord\" in data_dict.keys():\n            translate = np.random.uniform(self.translate_range[0], self.translate_range[1], size=3)\n            data_dict[\"coord\"] += translate\n        return data_dict\n</code></pre> <p>Random Translate PC</p> <p> </p>"},{"location":"coord/#augmentation_class.RandomTranslate.__call__","title":"<code>__call__(data_dict)</code>","text":"<p>Apply a random global translation to the point coordinates.</p> <p>Parameters:</p> Name Type Description Default <code>data_dict</code> <code>dict</code> <p>Input dictionary that must contain a <code>\"coord\"</code> key with a NumPy array of shape (N, 3) representing point coordinates.</p> required <p>Returns:</p> Name Type Description <code>dict</code> <code>dict</code> <p>The same dictionary with <code>\"coord\"</code> translated by a random offset vector, if applied.</p> Source code in <code>src\\augmentation_class.py</code> <pre><code>def __call__(self, data_dict: dict) -&gt; dict:\n    \"\"\"Apply a random global translation to the point coordinates.\n\n    Args:\n        data_dict (dict): Input dictionary that must contain a `\"coord\"` key with a NumPy array of shape (N, 3)\n            representing point coordinates.\n\n    Returns:\n        dict: The same dictionary with `\"coord\"` translated by a random offset vector, if applied.\n    \"\"\"\n    if random.random() &gt; self.apply_p:\n        return data_dict\n\n    if \"coord\" in data_dict.keys():\n        translate = np.random.uniform(self.translate_range[0], self.translate_range[1], size=3)\n        data_dict[\"coord\"] += translate\n    return data_dict\n</code></pre>"},{"location":"coord/#randomjitter","title":"RandomJitter","text":"<p>Add small Gaussian noise to 3D coordinates (point-wise jitter).</p> <p>This transform expects a dictionary containing:</p> <ul> <li><code>\"coord\"</code>: NumPy array of shape (N, 3) with point coordinates.</li> </ul> <p>It samples Gaussian noise for each point and each axis, scales it by <code>sigma</code>, clips it to <code>[-clip, clip]</code>, and adds it to the coordinates in place.</p> <p>Parameters:</p> Name Type Description Default <code>sigma</code> <code>float</code> <p>Standard deviation of the Gaussian noise before clipping. Noise is drawn as:</p> <pre><code>jitter_raw ~ N(0, sigma^2)\n</code></pre> <p>per coordinate. Defaults to 0.01.</p> <code>0.01</code> <code>clip</code> <code>float</code> <p>Maximum absolute value for the jitter. After sampling, the noise is clipped to the range <code>[-clip, clip]</code>:</p> <pre><code>jitter = np.clip(jitter_raw, -clip, clip)\n</code></pre> <p>Must be positive. Defaults to 0.05.</p> <code>0.05</code> <code>apply_p</code> <code>float</code> <p>Probability of applying the jitter. Defaults to 1.0.</p> <code>1.0</code> Source code in <code>src\\augmentation_class.py</code> <pre><code>@TRANSFORMS.register()\nclass RandomJitter:\n    \"\"\"Add small Gaussian noise to 3D coordinates (point-wise jitter).\n\n    This transform expects a dictionary containing:\n\n    * `\"coord\"`: NumPy array of shape (N, 3) with point coordinates.\n\n    It samples Gaussian noise for each point and each axis, scales it by `sigma`, clips it to `[-clip, clip]`, and\n    adds it to the coordinates in place.\n\n    Args:\n        sigma (float, optional):\n            Standard deviation of the Gaussian noise before clipping. Noise is drawn as:\n\n                jitter_raw ~ N(0, sigma^2)\n\n            per coordinate.\n            Defaults to 0.01.\n        clip (float, optional):\n            Maximum absolute value for the jitter. After sampling, the noise is clipped to the range `[-clip, clip]`:\n\n                jitter = np.clip(jitter_raw, -clip, clip)\n\n            Must be positive.\n            Defaults to 0.05.\n        apply_p (float, optional):\n            Probability of applying the jitter.\n            Defaults to 1.0.\n    \"\"\"\n    def __init__(self, sigma: float = 0.01, clip: float = 0.05, apply_p: float = 1.0):\n        assert (clip &gt; 0)\n        self.sigma = sigma\n        self.clip = clip\n        self.apply_p = apply_p\n\n    def __call__(self, data_dict: dict) -&gt; dict:\n        \"\"\"Apply point-wise Gaussian jitter to the point coordinates.\n\n        Args:\n            data_dict (dict): Input dictionary that must contain a `\"coord\"` key with a NumPy array of shape (N, 3)\n                representing point coordinates.\n\n        Returns:\n            dict: The same dictionary with `\"coord\"` perturbed by clipped Gaussian noise, if applied.\n        \"\"\"\n        if random.random() &gt; self.apply_p:\n            return data_dict\n\n        if \"coord\" in data_dict.keys():\n            jitter = np.clip(self.sigma * np.random.randn(data_dict[\"coord\"].shape[0], 3), -self.clip, self.clip)\n            data_dict[\"coord\"] += jitter\n        return data_dict\n</code></pre> <p>Random Jitter PC</p> <p> </p>"},{"location":"coord/#augmentation_class.RandomJitter.__call__","title":"<code>__call__(data_dict)</code>","text":"<p>Apply point-wise Gaussian jitter to the point coordinates.</p> <p>Parameters:</p> Name Type Description Default <code>data_dict</code> <code>dict</code> <p>Input dictionary that must contain a <code>\"coord\"</code> key with a NumPy array of shape (N, 3) representing point coordinates.</p> required <p>Returns:</p> Name Type Description <code>dict</code> <code>dict</code> <p>The same dictionary with <code>\"coord\"</code> perturbed by clipped Gaussian noise, if applied.</p> Source code in <code>src\\augmentation_class.py</code> <pre><code>def __call__(self, data_dict: dict) -&gt; dict:\n    \"\"\"Apply point-wise Gaussian jitter to the point coordinates.\n\n    Args:\n        data_dict (dict): Input dictionary that must contain a `\"coord\"` key with a NumPy array of shape (N, 3)\n            representing point coordinates.\n\n    Returns:\n        dict: The same dictionary with `\"coord\"` perturbed by clipped Gaussian noise, if applied.\n    \"\"\"\n    if random.random() &gt; self.apply_p:\n        return data_dict\n\n    if \"coord\" in data_dict.keys():\n        jitter = np.clip(self.sigma * np.random.randn(data_dict[\"coord\"].shape[0], 3), -self.clip, self.clip)\n        data_dict[\"coord\"] += jitter\n    return data_dict\n</code></pre>"},{"location":"coord/#randomflip","title":"RandomFlip","text":"<p>Randomly flip point coordinates (and normals) by sign along selected axes.</p> <p>This transform expects a dictionary containing:</p> <ul> <li><code>\"coord\"</code>: NumPy array of shape (N, 3) with point coordinates.</li> <li>Optionally <code>\"norm\"</code>: NumPy array of shape (N, 3) with normals   associated with each point.</li> </ul> <p>Given the axes in <code>flip_axis</code>, each axis may be flipped by multiplying the corresponding coordinate (and normal, if present) by -1.</p> <p>Parameters:</p> Name Type Description Default <code>flip_axis</code> <code>tuple[int, ...]</code> <p>Indices of axes to consider for flipping. Each element must be in <code>{0, 1, 2}</code>:</p> <ul> <li><code>0</code> \u2192 x-axis</li> <li><code>1</code> \u2192 y-axis</li> <li><code>2</code> \u2192 z-axis</li> </ul> <p>For each axis in this tuple, a random decision is made (with probability <code>apply_p</code>) whether to flip that axis.</p> <p>Examples:     * <code>flip_axis=(0,)</code> \u2192 only possible flip is x-axis.     * <code>flip_axis=(1, 2)</code> \u2192 y and z axes may be flipped       independently.</p> <p>Defaults to <code>(0, 2)</code>.</p> <code>(0, 2)</code> <code>apply_p</code> <code>float</code> <p>Probability of flipping each axis. Defaults to 1.0.</p> <code>1.0</code> Source code in <code>src\\augmentation_class.py</code> <pre><code>@TRANSFORMS.register()\nclass RandomFlip:\n    \"\"\"Randomly flip point coordinates (and normals) by sign along selected axes.\n\n    This transform expects a dictionary containing:\n\n    * `\"coord\"`: NumPy array of shape (N, 3) with point coordinates.\n    * Optionally `\"norm\"`: NumPy array of shape (N, 3) with normals\n      associated with each point.\n\n    Given the axes in `flip_axis`, each axis may be flipped by multiplying\n    the corresponding coordinate (and normal, if present) by -1.\n\n    Args:\n        flip_axis (tuple[int, ...], optional):\n            Indices of axes to consider for flipping. Each element must be in `{0, 1, 2}`:\n\n            * `0` \u2192 x-axis\n            * `1` \u2192 y-axis\n            * `2` \u2192 z-axis\n\n            For each axis in this tuple, a random decision is made (with\n            probability `apply_p`) whether to flip that axis.\n\n            Examples:\n                * `flip_axis=(0,)` \u2192 only possible flip is x-axis.\n                * `flip_axis=(1, 2)` \u2192 y and z axes may be flipped\n                  independently.\n\n            Defaults to `(0, 2)`.\n        apply_p (float, optional):\n            Probability of flipping **each** axis.\n            Defaults to 1.0.\n    \"\"\"\n    def __init__(self, flip_axis: tuple = (0, 2), apply_p: float = 1.0) -&gt; None:\n        self.flip_axis = flip_axis\n        self.apply_p = apply_p\n\n    def __call__(self, data_dict: dict) -&gt; dict:\n        \"\"\"Apply random sign flips along selected axes to coords (and normals).\n\n        Args:\n            data_dict (dict): Input dictionary that should contain a `\"coord\"` key with a NumPy array of shape (N, 3)\n                representing point coordinates. Optionally may contain a `\"norm\"` key with a NumPy array of shape (N, 3)\n                representing normal vectors.\n\n        Returns:\n            dict: The same dictionary with `\"coord\"` (and `\"norm\"` if present) potentially flipped by sign along the\n                specified axes.\n        \"\"\"\n        for axis in self.flip_axis:\n            if np.random.rand() &lt; self.apply_p:\n                if \"coord\" in data_dict.keys():\n                    data_dict[\"coord\"][:, axis] = -data_dict[\"coord\"][:, axis]\n                if \"norm\" in data_dict.keys():\n                    data_dict[\"norm\"][:, axis] = -data_dict[\"norm\"][:, axis]\n\n        return data_dict\n</code></pre> <p>Random Flip PC</p> <p> </p>"},{"location":"coord/#augmentation_class.RandomFlip.__call__","title":"<code>__call__(data_dict)</code>","text":"<p>Apply random sign flips along selected axes to coords (and normals).</p> <p>Parameters:</p> Name Type Description Default <code>data_dict</code> <code>dict</code> <p>Input dictionary that should contain a <code>\"coord\"</code> key with a NumPy array of shape (N, 3) representing point coordinates. Optionally may contain a <code>\"norm\"</code> key with a NumPy array of shape (N, 3) representing normal vectors.</p> required <p>Returns:</p> Name Type Description <code>dict</code> <code>dict</code> <p>The same dictionary with <code>\"coord\"</code> (and <code>\"norm\"</code> if present) potentially flipped by sign along the specified axes.</p> Source code in <code>src\\augmentation_class.py</code> <pre><code>def __call__(self, data_dict: dict) -&gt; dict:\n    \"\"\"Apply random sign flips along selected axes to coords (and normals).\n\n    Args:\n        data_dict (dict): Input dictionary that should contain a `\"coord\"` key with a NumPy array of shape (N, 3)\n            representing point coordinates. Optionally may contain a `\"norm\"` key with a NumPy array of shape (N, 3)\n            representing normal vectors.\n\n    Returns:\n        dict: The same dictionary with `\"coord\"` (and `\"norm\"` if present) potentially flipped by sign along the\n            specified axes.\n    \"\"\"\n    for axis in self.flip_axis:\n        if np.random.rand() &lt; self.apply_p:\n            if \"coord\" in data_dict.keys():\n                data_dict[\"coord\"][:, axis] = -data_dict[\"coord\"][:, axis]\n            if \"norm\" in data_dict.keys():\n                data_dict[\"norm\"][:, axis] = -data_dict[\"norm\"][:, axis]\n\n    return data_dict\n</code></pre>"},{"location":"coord/#randomdropout","title":"RandomDropout","text":"<p>Randomly drop a subset of points (and aligned per-point attributes).</p> <p>This transform expects a dictionary containing:</p> <ul> <li><code>\"coord\"</code>: NumPy array of shape (N, 3) with point coordinates.</li> <li>Optionally other per-point arrays (e.g., <code>\"norm\"</code>, <code>\"color\"</code>, <code>\"label\"</code>)   that have length N along the first dimension.</li> </ul> <p>Parameters:</p> Name Type Description Default <code>max_dropout_ratio</code> <code>float</code> <p>Maximum fraction of points that may be dropped. The actual dropout ratio is drawn from:</p> <pre><code>ratio ~ U(0, max_dropout_ratio)\n</code></pre> <p>For example, if <code>max_dropout_ratio = 0.2</code>, then up to 20% of points can be removed in any application of this transform. Defaults to 0.2.</p> <code>0.2</code> <code>apply_p</code> <code>float</code> <p>Probability of applying the dropout. Defaults to 1.0.</p> <code>1.0</code> Source code in <code>src\\augmentation_class.py</code> <pre><code>@TRANSFORMS.register()\nclass RandomDropout:\n    \"\"\"Randomly drop a subset of points (and aligned per-point attributes).\n\n    This transform expects a dictionary containing:\n\n    * `\"coord\"`: NumPy array of shape (N, 3) with point coordinates.\n    * Optionally other per-point arrays (e.g., `\"norm\"`, `\"color\"`, `\"label\"`)\n      that have length N along the first dimension.\n\n    Args:\n        max_dropout_ratio (float, optional):\n            Maximum fraction of points that may be dropped. The actual dropout ratio is drawn from:\n\n                ratio ~ U(0, max_dropout_ratio)\n\n            For example, if `max_dropout_ratio = 0.2`, then up to 20% of\n            points can be removed in any application of this transform.\n            Defaults to 0.2.\n        apply_p (float, optional):\n            Probability of applying the dropout.\n            Defaults to 1.0.\n    \"\"\"\n    def __init__(self, max_dropout_ratio: float = 0.2, apply_p: float = 1.0):\n        self.max_dropout_ratio = max_dropout_ratio\n        self.apply_p = apply_p\n\n    def __call__(self, data_dict: dict) -&gt; dict:\n        \"\"\"Apply random point dropout to coords and aligned attributes.\n\n        Args:\n            data_dict (dict): Input dictionary that must contain a `\"coord\"` key with a NumPy array of shape (N, 3).\n                Any other entry whose value is a NumPy array or `Sequence` of length N and whose key does not contain\n                `\"origin\"` will also be subsampled.\n\n        Returns:\n            dict: The same dictionary with a subset of points (and aligned per-point attributes) kept, if dropout is applied.\n        \"\"\"\n        if random.random() &gt; self.apply_p:\n            return data_dict\n\n        if \"coord\" in data_dict.keys():\n            n = len(data_dict[\"coord\"])\n            ratio = np.random.uniform(0, self.max_dropout_ratio)\n            size = int(n * (1 - ratio))\n            assert size &gt; 0\n            idx = np.random.choice(n, size, replace=False)\n            for key, value in data_dict.items():\n                if isinstance(value, (np.ndarray, Sequence)) and len(value) == n and \"origin\" not in key:\n                    data_dict[key] = value[idx]\n\n        return data_dict\n</code></pre> <p>Random Dropout PC</p> <p> </p>"},{"location":"coord/#augmentation_class.RandomDropout.__call__","title":"<code>__call__(data_dict)</code>","text":"<p>Apply random point dropout to coords and aligned attributes.</p> <p>Parameters:</p> Name Type Description Default <code>data_dict</code> <code>dict</code> <p>Input dictionary that must contain a <code>\"coord\"</code> key with a NumPy array of shape (N, 3). Any other entry whose value is a NumPy array or <code>Sequence</code> of length N and whose key does not contain <code>\"origin\"</code> will also be subsampled.</p> required <p>Returns:</p> Name Type Description <code>dict</code> <code>dict</code> <p>The same dictionary with a subset of points (and aligned per-point attributes) kept, if dropout is applied.</p> Source code in <code>src\\augmentation_class.py</code> <pre><code>def __call__(self, data_dict: dict) -&gt; dict:\n    \"\"\"Apply random point dropout to coords and aligned attributes.\n\n    Args:\n        data_dict (dict): Input dictionary that must contain a `\"coord\"` key with a NumPy array of shape (N, 3).\n            Any other entry whose value is a NumPy array or `Sequence` of length N and whose key does not contain\n            `\"origin\"` will also be subsampled.\n\n    Returns:\n        dict: The same dictionary with a subset of points (and aligned per-point attributes) kept, if dropout is applied.\n    \"\"\"\n    if random.random() &gt; self.apply_p:\n        return data_dict\n\n    if \"coord\" in data_dict.keys():\n        n = len(data_dict[\"coord\"])\n        ratio = np.random.uniform(0, self.max_dropout_ratio)\n        size = int(n * (1 - ratio))\n        assert size &gt; 0\n        idx = np.random.choice(n, size, replace=False)\n        for key, value in data_dict.items():\n            if isinstance(value, (np.ndarray, Sequence)) and len(value) == n and \"origin\" not in key:\n                data_dict[key] = value[idx]\n\n    return data_dict\n</code></pre>"},{"location":"coord/#shufflepoint","title":"ShufflePoint","text":"<p>Randomly permute the order of points (and aligned per-point attributes).</p> <p>This transform expects a dictionary containing:</p> <ul> <li><code>\"coord\"</code>: NumPy array of shape (N, 3) with point coordinates.</li> <li>Optionally other per-point arrays (e.g., <code>\"norm\"</code>, <code>\"color\"</code>, <code>\"label\"</code>) that have length N along the first dimension.</li> </ul> <p>All per-point arrays of matching length are shuffled with the same permutation, preserving correspondence between them.</p> <p>Parameters:</p> Name Type Description Default <code>apply_p</code> <code>float</code> <p>Probability of applying the shuffling. Defaults to 1.0.</p> <code>1.0</code> Source code in <code>src\\augmentation_class.py</code> <pre><code>@TRANSFORMS.register()\nclass ShufflePoint:\n    \"\"\"Randomly permute the order of points (and aligned per-point attributes).\n\n    This transform expects a dictionary containing:\n\n    * `\"coord\"`: NumPy array of shape (N, 3) with point coordinates.\n    * Optionally other per-point arrays (e.g., `\"norm\"`, `\"color\"`, `\"label\"`) that have length N along the first dimension.\n\n    All per-point arrays of matching length are shuffled with the same\n    permutation, preserving correspondence between them.\n\n    Args:\n        apply_p (float, optional):\n            Probability of applying the shuffling.\n            Defaults to 1.0.\n    \"\"\"\n    def __init__(self, apply_p: float = 1.0):\n        self.apply_p = apply_p\n\n    def __call__(self, data_dict: dict) -&gt; dict:\n        \"\"\"Shuffle the order of points and aligned per-point attributes.\n\n        Args:\n            data_dict (dict): Input dictionary that must contain a `\"coord\"` key with a NumPy array of shape (N, 3).\n                Any other entry whose value is a NumPy array or `Sequence` of length N and whose key does not contain\n                `\"origin\"` will be permuted with the same shuffle indices.\n\n        Returns:\n            dict: The same dictionary with `\"coord\"` and aligned per-point attributes shuffled in order, if applied.\n        \"\"\"\n        if random.random() &gt; self.apply_p:\n            return data_dict\n\n        if \"coord\" in data_dict.keys():\n            shuffle_index = np.arange(data_dict[\"coord\"].shape[0])\n            np.random.shuffle(shuffle_index)\n            n_pts = len(shuffle_index)\n            # print(data_dict[\"noise_index\"])\n            for key, val in data_dict.items():\n                if isinstance(val, (np.ndarray, Sequence)) and len(val) == n_pts and \"origin\" not in key:\n                    data_dict[key] = val[shuffle_index]\n            # print(data_dict[\"noise_index\"])\n        return data_dict\n</code></pre>"},{"location":"coord/#augmentation_class.ShufflePoint.__call__","title":"<code>__call__(data_dict)</code>","text":"<p>Shuffle the order of points and aligned per-point attributes.</p> <p>Parameters:</p> Name Type Description Default <code>data_dict</code> <code>dict</code> <p>Input dictionary that must contain a <code>\"coord\"</code> key with a NumPy array of shape (N, 3). Any other entry whose value is a NumPy array or <code>Sequence</code> of length N and whose key does not contain <code>\"origin\"</code> will be permuted with the same shuffle indices.</p> required <p>Returns:</p> Name Type Description <code>dict</code> <code>dict</code> <p>The same dictionary with <code>\"coord\"</code> and aligned per-point attributes shuffled in order, if applied.</p> Source code in <code>src\\augmentation_class.py</code> <pre><code>def __call__(self, data_dict: dict) -&gt; dict:\n    \"\"\"Shuffle the order of points and aligned per-point attributes.\n\n    Args:\n        data_dict (dict): Input dictionary that must contain a `\"coord\"` key with a NumPy array of shape (N, 3).\n            Any other entry whose value is a NumPy array or `Sequence` of length N and whose key does not contain\n            `\"origin\"` will be permuted with the same shuffle indices.\n\n    Returns:\n        dict: The same dictionary with `\"coord\"` and aligned per-point attributes shuffled in order, if applied.\n    \"\"\"\n    if random.random() &gt; self.apply_p:\n        return data_dict\n\n    if \"coord\" in data_dict.keys():\n        shuffle_index = np.arange(data_dict[\"coord\"].shape[0])\n        np.random.shuffle(shuffle_index)\n        n_pts = len(shuffle_index)\n        # print(data_dict[\"noise_index\"])\n        for key, val in data_dict.items():\n            if isinstance(val, (np.ndarray, Sequence)) and len(val) == n_pts and \"origin\" not in key:\n                data_dict[key] = val[shuffle_index]\n        # print(data_dict[\"noise_index\"])\n    return data_dict\n</code></pre>"},{"location":"coord/#pointclip","title":"PointClip","text":"<p>Randomly clip a local region around a randomly chosen point.</p> <p>This transform expects a dictionary containing:</p> <ul> <li><code>\"coord\"</code>: NumPy array of shape (N, 3) with point coordinates.</li> <li>Optionally other per-point arrays (e.g., <code>\"norm\"</code>, <code>\"color\"</code>, <code>\"label\"</code>)   that have length N along the first dimension.</li> </ul> <p>A random point index is selected and its coordinate is used as the center:</p> <pre><code>center = coord[center_idx]\n</code></pre> <p>Then it builds either:</p> <ul> <li>a spherical region of radius <code>radius</code> around <code>center</code> if <code>use_sphere=True</code>, or</li> <li>an axis-aligned box centered at <code>center</code> with half-extent <code>box_range</code>   if <code>use_sphere=False</code>.</li> </ul> <p>Only points inside this region are kept; all others are dropped. All aligned per-point attributes are filtered with the same mask.</p> <p>Parameters:</p> Name Type Description Default <code>use_sphere</code> <code>bool</code> <p>If True, use a spherical region. For each point <code>p</code>, compute squared distance:</p> <pre><code>dist2 = ||p - center||^2\n</code></pre> <p>and keep points with <code>dist2 &lt;= radius^2</code>. If False, use an axis-aligned box instead. Defaults to True.</p> <code>True</code> <code>radius</code> <code>float</code> <p>Radius of the sphere used when <code>use_sphere=True</code>. The clipped region is:</p> <pre><code>{ p : ||p - center|| &lt;= radius }\n</code></pre> <p>Defaults to 1.0.</p> <code>1.0</code> <code>box_range</code> <code>tuple[float, float, float]</code> <p>Half-extent of the axis-aligned box along each axis, used when <code>use_sphere=False</code>. Interpreted as <code>(rx, ry, rz)</code>. The box is defined as:</p> <ul> <li><code>x_min, y_min, z_min = center - box_range</code></li> <li><code>x_max, y_max, z_max = center + box_range</code></li> </ul> <p>A point <code>p = (x, y, z)</code> is kept if:</p> <pre><code>x_min &lt;= x &lt;= x_max\ny_min &lt;= y &lt;= y_max\nz_min &lt;= z &lt;= z_max\n</code></pre> <p>Defaults to <code>(0.0, 0.0, 0.0)</code>.</p> <code>(0.0, 0.0, 0.0)</code> <code>apply_p</code> <code>float</code> <p>Probability of applying the clipping. Defaults to 1.0.</p> <code>1.0</code> Source code in <code>src\\augmentation_class.py</code> <pre><code>@TRANSFORMS.register()\nclass PointClip:\n    \"\"\"Randomly clip a local region around a randomly chosen point.\n\n    This transform expects a dictionary containing:\n\n    * `\"coord\"`: NumPy array of shape (N, 3) with point coordinates.\n    * Optionally other per-point arrays (e.g., `\"norm\"`, `\"color\"`, `\"label\"`)\n      that have length N along the first dimension.\n\n    A random point index is selected and its coordinate is used as the center:\n\n        center = coord[center_idx]\n\n    Then it builds either:\n\n    * a spherical region of radius `radius` around `center` if `use_sphere=True`, or\n    * an axis-aligned box centered at `center` with half-extent `box_range`\n      if `use_sphere=False`.\n\n    Only points inside this region are kept; all others are dropped. All aligned per-point attributes are filtered with\n    the same mask.\n\n    Args:\n        use_sphere (bool, optional):\n            If True, use a spherical region. For each point `p`, compute squared distance:\n\n                dist2 = ||p - center||^2\n\n            and keep points with `dist2 &lt;= radius^2`. If False, use an axis-aligned box instead.\n            Defaults to True.\n        radius (float, optional): Radius of the sphere used when `use_sphere=True`. The clipped region is:\n\n                { p : ||p - center|| &lt;= radius }\n\n            Defaults to 1.0.\n        box_range (tuple[float, float, float], optional): Half-extent of the axis-aligned box along each axis,\n            used when `use_sphere=False`. Interpreted as `(rx, ry, rz)`. The box is defined as:\n\n            * `x_min, y_min, z_min = center - box_range`\n            * `x_max, y_max, z_max = center + box_range`\n\n            A point `p = (x, y, z)` is kept if:\n\n                x_min &lt;= x &lt;= x_max\n                y_min &lt;= y &lt;= y_max\n                z_min &lt;= z &lt;= z_max\n\n            Defaults to `(0.0, 0.0, 0.0)`.\n        apply_p (float, optional):\n            Probability of applying the clipping.\n            Defaults to 1.0.\n    \"\"\"\n    def __init__(self, use_sphere: bool = True, radius: float = 1.0, box_range: tuple = (0.0, 0.0, 0.0),\n                 apply_p: float = 1.0):\n        self.use_sphere = use_sphere\n        self.radius = radius\n        self.box_range = np.array(box_range)\n        self.apply_p = apply_p\n\n    def __call__(self, data_dict: dict) -&gt; dict:\n        \"\"\"Apply a local region crop (sphere or box) around a random center.\n\n        Args:\n            data_dict (dict): Input dictionary that must contain a `\"coord\"` key with a NumPy array of shape (N, 3).\n                Any other entry whose value is a NumPy array or `Sequence` of length N and whose key does not contain\n                `\"origin\"` will also be masked.\n\n        Returns:\n            dict: The same dictionary with `\"coord\"` and aligned per-point attributes cropped to a local region, if applied.\n        \"\"\"\n        if random.random() &gt; self.apply_p:\n            return data_dict\n\n        if \"coord\" in data_dict.keys():\n            coord = data_dict[\"coord\"]\n            n = len(coord)\n            center_idx = np.random.randint(low=0, high=n)\n            center = coord[center_idx]\n            if self.use_sphere:\n                diff = coord - center[np.newaxis, :]\n                dist2 = np.sum(diff * diff, axis=1)\n                mask = dist2 &lt;= self.radius ** 2\n            else:\n                x, y, z = coord[:, 0], coord[:, 1], coord[:, 2]\n                # x_min, x_max, y_min, y_max, z_min, z_max = self.box_range + np.repeat(center, 2)\n                x_min, y_min, z_min = -self.box_range + center\n                x_max, y_max, z_max = self.box_range + center\n                # print(x_min, x_max, y_min, y_max, z_min, z_max)\n                mask = (x &gt;= x_min) &amp; (x &lt;= x_max) &amp; (y &gt;= y_min) &amp; (y &lt;= y_max) &amp; (z &gt;= z_min) &amp; (z &lt;= z_max)\n\n            for key, value in data_dict.items():\n                if isinstance(value, (np.ndarray, Sequence)) and len(value) == n and \"origin\" not in key:\n                    data_dict[key] = value[mask]\n        return data_dict\n</code></pre> <p>Clip PC</p> <p> </p>"},{"location":"coord/#augmentation_class.PointClip.__call__","title":"<code>__call__(data_dict)</code>","text":"<p>Apply a local region crop (sphere or box) around a random center.</p> <p>Parameters:</p> Name Type Description Default <code>data_dict</code> <code>dict</code> <p>Input dictionary that must contain a <code>\"coord\"</code> key with a NumPy array of shape (N, 3). Any other entry whose value is a NumPy array or <code>Sequence</code> of length N and whose key does not contain <code>\"origin\"</code> will also be masked.</p> required <p>Returns:</p> Name Type Description <code>dict</code> <code>dict</code> <p>The same dictionary with <code>\"coord\"</code> and aligned per-point attributes cropped to a local region, if applied.</p> Source code in <code>src\\augmentation_class.py</code> <pre><code>def __call__(self, data_dict: dict) -&gt; dict:\n    \"\"\"Apply a local region crop (sphere or box) around a random center.\n\n    Args:\n        data_dict (dict): Input dictionary that must contain a `\"coord\"` key with a NumPy array of shape (N, 3).\n            Any other entry whose value is a NumPy array or `Sequence` of length N and whose key does not contain\n            `\"origin\"` will also be masked.\n\n    Returns:\n        dict: The same dictionary with `\"coord\"` and aligned per-point attributes cropped to a local region, if applied.\n    \"\"\"\n    if random.random() &gt; self.apply_p:\n        return data_dict\n\n    if \"coord\" in data_dict.keys():\n        coord = data_dict[\"coord\"]\n        n = len(coord)\n        center_idx = np.random.randint(low=0, high=n)\n        center = coord[center_idx]\n        if self.use_sphere:\n            diff = coord - center[np.newaxis, :]\n            dist2 = np.sum(diff * diff, axis=1)\n            mask = dist2 &lt;= self.radius ** 2\n        else:\n            x, y, z = coord[:, 0], coord[:, 1], coord[:, 2]\n            # x_min, x_max, y_min, y_max, z_min, z_max = self.box_range + np.repeat(center, 2)\n            x_min, y_min, z_min = -self.box_range + center\n            x_max, y_max, z_max = self.box_range + center\n            # print(x_min, x_max, y_min, y_max, z_min, z_max)\n            mask = (x &gt;= x_min) &amp; (x &lt;= x_max) &amp; (y &gt;= y_min) &amp; (y &lt;= y_max) &amp; (z &gt;= z_min) &amp; (z &lt;= z_max)\n\n        for key, value in data_dict.items():\n            if isinstance(value, (np.ndarray, Sequence)) and len(value) == n and \"origin\" not in key:\n                data_dict[key] = value[mask]\n    return data_dict\n</code></pre>"},{"location":"coord/#clipgaussianjitter","title":"ClipGaussianJitter","text":"<p>Add clipped multivariate Gaussian noise to 3D coordinates.</p> <p>This transform expects a dictionary containing: * <code>\"coord\"</code>: NumPy array of shape (N, 3) with point coordinates.</p> <p>Unlike a simple per-axis jitter (RandomJitter) with independent 1D Gaussians, this transform uses a multivariate normal distribution, allowing you to encode correlations between axes via the covariance matrix. It samples 3D Gaussian noise from a multivariate normal, normalizes and clips it using a <code>quantile</code> parameter, scales it by <code>scalar</code>, and adds it to the coordinates in place.</p> <p>In the default setting:</p> <ul> <li><code>mean = [0.0, 0.0, 0.0]</code></li> <li><code>cov = I_3</code> (3\u00d73 identity matrix \u2192 isotropic Gaussian)</li> </ul> <p>A raw sample is drawn as:</p> <pre><code>jitter_raw ~ N(mean, cov)\n</code></pre> <p>Then it is transformed as:</p> <pre><code>jitter = scalar * clip(jitter_raw / quantile, -1, 1)\n</code></pre> <p>Intuition:</p> <ul> <li>For a standard normal, most values lie within \u00b1<code>quantile</code>   (e.g., 1.96 \u2248 97.5% quantile).</li> <li>Dividing by <code>quantile</code> and clipping to [-1, 1] effectively bounds   each component before scaling, so typical magnitudes are on the   order of <code>\u00b1scalar</code>.</li> </ul> <p>Parameters:</p> Name Type Description Default <code>quantile</code> <code>float</code> <p>Normalization factor used before clipping. Noise is divided by <code>quantile</code> and then clipped to [-1, 1]. For <code>quantile=1.96</code>, about 95\u201397.5% of standard normal samples fall in [-1.96, 1.96], so after dividing most samples lie in [-1, 1] before clipping. Increasing <code>quantile</code> makes the effective jitter slightly smaller; decreasing it makes it larger (and more aggressively clipped). Defaults to 1.96.</p> <code>1.96</code> <code>scalar</code> <code>float</code> <p>Overall scale factor for the jitter after clipping. Roughly controls the maximum perturbation per coordinate (since final values are typically in approximately<code>[-scalar, scalar]</code>). Defaults to 0.02.</p> <code>0.02</code> <code>apply_p</code> <code>float</code> <p>Probability of applying the jitter. Defaults to 1.0.</p> <code>1.0</code> Source code in <code>src\\augmentation_class.py</code> <pre><code>@TRANSFORMS.register()\nclass ClipGaussianJitter:\n    \"\"\"Add clipped multivariate Gaussian noise to 3D coordinates.\n\n    This transform expects a dictionary containing:\n    * `\"coord\"`: NumPy array of shape (N, 3) with point coordinates.\n\n    Unlike a simple per-axis jitter (RandomJitter) with independent 1D Gaussians, this transform uses a\n    **multivariate normal distribution**, allowing you to encode correlations between axes via the covariance matrix.\n    It samples 3D Gaussian noise from a multivariate normal, normalizes and clips it using a `quantile` parameter, scales\n    it by `scalar`, and adds it to the coordinates in place.\n\n    In the default setting:\n\n    * `mean = [0.0, 0.0, 0.0]`\n    * `cov = I_3` (3\u00d73 identity matrix \u2192 isotropic Gaussian)\n\n    A raw sample is drawn as:\n\n        jitter_raw ~ N(mean, cov)\n\n    Then it is transformed as:\n\n        jitter = scalar * clip(jitter_raw / quantile, -1, 1)\n\n    Intuition:\n\n    * For a standard normal, most values lie within \u00b1`quantile`\n      (e.g., 1.96 \u2248 97.5% quantile).\n    * Dividing by `quantile` and clipping to [-1, 1] effectively bounds\n      each component before scaling, so typical magnitudes are on the\n      order of `\u00b1scalar`.\n\n    Args:\n        quantile (float, optional):\n            Normalization factor used before clipping. Noise is divided by `quantile` and then clipped to [-1, 1].\n            For `quantile=1.96`, about 95\u201397.5% of standard normal samples fall in [-1.96, 1.96], so after dividing most\n            samples lie in [-1, 1] before clipping.\n            Increasing `quantile` makes the effective jitter slightly smaller; decreasing it makes it larger (and more aggressively clipped).\n            Defaults to 1.96.\n        scalar (float, optional):\n            Overall scale factor for the jitter after clipping. Roughly controls the maximum perturbation per coordinate\n            (since final values are typically in approximately`[-scalar, scalar]`).\n            Defaults to 0.02.\n        apply_p (float, optional):\n            Probability of applying the jitter.\n            Defaults to 1.0.\n    \"\"\"\n    def __init__(self, quantile: float = 1.96, scalar: float = 0.02, apply_p: float = 1.0):\n        self.mean = [0.0, 0.0, 0.0]\n        self.conv = np.identity(3)\n        self.quantile = quantile\n        self.scalar = scalar\n        self.apply_p = apply_p\n\n    def __call__(self, data_dict: dict) -&gt; dict:\n        \"\"\"Apply clipped multivariate Gaussian jitter to the point coordinates.\n\n        Args:\n            data_dict (dict): Input dictionary that must contain a `\"coord\"` key with a NumPy array of shape (N, 3)\n                representing point coordinates.\n\n        Returns:\n            dict: The same dictionary with `\"coord\"` perturbed by clipped multivariate Gaussian noise, if applied.\n        \"\"\"\n        if random.random() &gt; self.apply_p:\n            return data_dict\n\n        if \"coord\" in data_dict.keys():\n            # [data_dict[\"coord\"].shape[0], len(self.mean)]\n            jitter = np.random.multivariate_normal(self.mean, self.conv, data_dict[\"coord\"].shape[0])\n            jitter = self.scalar * np.clip(jitter / self.quantile, -1, 1)\n            data_dict[\"coord\"] += jitter\n\n        return data_dict\n</code></pre> <p>Clip Gaussian Jitter on PC</p> <p> </p>"},{"location":"coord/#augmentation_class.ClipGaussianJitter.__call__","title":"<code>__call__(data_dict)</code>","text":"<p>Apply clipped multivariate Gaussian jitter to the point coordinates.</p> <p>Parameters:</p> Name Type Description Default <code>data_dict</code> <code>dict</code> <p>Input dictionary that must contain a <code>\"coord\"</code> key with a NumPy array of shape (N, 3) representing point coordinates.</p> required <p>Returns:</p> Name Type Description <code>dict</code> <code>dict</code> <p>The same dictionary with <code>\"coord\"</code> perturbed by clipped multivariate Gaussian noise, if applied.</p> Source code in <code>src\\augmentation_class.py</code> <pre><code>def __call__(self, data_dict: dict) -&gt; dict:\n    \"\"\"Apply clipped multivariate Gaussian jitter to the point coordinates.\n\n    Args:\n        data_dict (dict): Input dictionary that must contain a `\"coord\"` key with a NumPy array of shape (N, 3)\n            representing point coordinates.\n\n    Returns:\n        dict: The same dictionary with `\"coord\"` perturbed by clipped multivariate Gaussian noise, if applied.\n    \"\"\"\n    if random.random() &gt; self.apply_p:\n        return data_dict\n\n    if \"coord\" in data_dict.keys():\n        # [data_dict[\"coord\"].shape[0], len(self.mean)]\n        jitter = np.random.multivariate_normal(self.mean, self.conv, data_dict[\"coord\"].shape[0])\n        jitter = self.scalar * np.clip(jitter / self.quantile, -1, 1)\n        data_dict[\"coord\"] += jitter\n\n    return data_dict\n</code></pre>"},{"location":"coord/#elasticdistortion","title":"ElasticDistortion","text":"<p>Apply elastic distortion to 3D point coordinates.</p> <p>This transform expects a dictionary containing:</p> <ul> <li><code>\"coord\"</code>: NumPy array of shape (N, 3) with point coordinates.</li> </ul> <p>The distortion is implemented by:</p> <ol> <li>Creating a coarse 3D grid of Gaussian noise with resolution determined    by <code>granularity</code>.</li> <li>Smoothing the noise with separable 3D convolutions.</li> <li>Trilinearly interpolating the smoothed noise at each input coordinate.</li> <li>Adding the interpolated noise (scaled by <code>magnitude</code>) to the original    coordinates.</li> </ol> <p>Multiple <code>(granularity, magnitude)</code> pairs can be applied sequentially to produce multi-scale elastic deformations.</p> <p>Parameters:</p> Name Type Description Default <code>distortion_params</code> <code>list[list[float]] | list[tuple[float, float]] | None</code> <p>List of <code>(granularity, magnitude)</code> pairs controlling the elastic fields to apply. Each pair is:</p> <ul> <li><code>granularity</code> (float):     Size of the noise grid in the same units as the coordinates (e.g., meters or centimeters).     Larger values \u2192 smoother, more global distortions.</li> <li><code>magnitude</code> (float):     Amplitude of the noise displacement added to the coordinates.</li> </ul> <p>If <code>None</code>, a default two-scale configuration is used: <code>[[0.2, 0.4], [0.8, 1.6]]</code>. Defaults to <code>None</code>.</p> <code>None</code> <code>apply_p</code> <code>float</code> <p>Probability of applying the elastic Defaults to 1.0.</p> <code>1.0</code> Source code in <code>src\\augmentation_class.py</code> <pre><code>@TRANSFORMS.register()\nclass ElasticDistortion:\n    \"\"\"Apply elastic distortion to 3D point coordinates.\n\n    This transform expects a dictionary containing:\n\n    * `\"coord\"`: NumPy array of shape (N, 3) with point coordinates.\n\n    The distortion is implemented by:\n\n    1. Creating a coarse 3D grid of Gaussian noise with resolution determined\n       by `granularity`.\n    2. Smoothing the noise with separable 3D convolutions.\n    3. Trilinearly interpolating the smoothed noise at each input coordinate.\n    4. Adding the interpolated noise (scaled by `magnitude`) to the original\n       coordinates.\n\n    Multiple `(granularity, magnitude)` pairs can be applied sequentially to\n    produce multi-scale elastic deformations.\n\n    Args:\n        distortion_params (list[list[float]] | list[tuple[float, float]] | None, optional):\n            List of `(granularity, magnitude)` pairs controlling the elastic fields to apply. Each pair is:\n\n            * `granularity` (float):\n                Size of the noise grid in the same units as the coordinates (e.g., meters or centimeters).\n                Larger values \u2192 smoother, more global distortions.\n            * `magnitude` (float):\n                Amplitude of the noise displacement added to the coordinates.\n\n            If ``None``, a default two-scale configuration is used: ``[[0.2, 0.4], [0.8, 1.6]]``.\n            Defaults to ``None``.\n        apply_p (float, optional):\n            Probability of applying the elastic\n            Defaults to 1.0.\n    \"\"\"\n    def __init__(self, distortion_params=None, apply_p: float = 1.0):\n        self.distortion_params = [[0.2, 0.4], [0.8, 1.6]] if distortion_params is None else distortion_params\n        self.apply_p = apply_p\n\n    @staticmethod\n    def elastic_distortion(coord, granularity, magnitude):\n        \"\"\"\n        Apply a single elastic distortion field to coordinates.\n\n        Args:\n            coord (np.ndarray):\n                Array of shape (N, D) with point coordinates. The first 3 dimensions are treated as spatial coordinates.\n            granularity (float):\n                Size of the noise grid in the same units as `coord` (e.g., meters or centimeters).Controls the spatial\n                smoothness of the distortion.\n            magnitude (float):\n                Noise multiplier that scales the interpolated noise displacement added to `coord`.\n\n        Returns:\n            np.ndarray:\n            The same coordinate array, distorted in place and also returned for convenience.\n        \"\"\"\n        blurx = np.ones((3, 1, 1, 1)).astype(\"float32\") / 3\n        blury = np.ones((1, 3, 1, 1)).astype(\"float32\") / 3\n        blurz = np.ones((1, 1, 3, 1)).astype(\"float32\") / 3\n        coords_min = coord.min(0)\n\n        # Create Gaussian noise tensor of the size given by granularity.\n        noise_dim = ((coord - coords_min).max(0) // granularity).astype(int) + 3\n        noise = np.random.randn(*noise_dim, 3).astype(np.float32)\n\n        # Smoothing.\n        for _ in range(2):\n            noise = scipy.ndimage.filters.convolve(noise, blurx, mode=\"constant\", cval=0)\n            noise = scipy.ndimage.filters.convolve(noise, blury, mode=\"constant\", cval=0)\n            noise = scipy.ndimage.filters.convolve(noise, blurz, mode=\"constant\", cval=0)\n\n        # Trilinear interpolate noise filters for each spatial dimensions.\n        ax = [np.linspace(d_min, d_max, d) for d_min, d_max, d in zip(coords_min - granularity,\n                                                                      coords_min + granularity * (noise_dim - 2),\n                                                                      noise_dim)\n              ]\n        interp = scipy.interpolate.RegularGridInterpolator(\n            ax, noise, bounds_error=False, fill_value=0\n        )\n        coord += interp(coord) * magnitude\n        return coord\n\n    def __call__(self, data_dict: dict) -&gt; dict:\n        \"\"\"Apply elastic distortion(s) to `\"coord\"` in `data_dict`.\n\n        Args:\n            data_dict (dict): Input dictionary that must contain a `\"coord\"` key with a NumPy array of shape (N, 3)\n                representing point coordinates.\n\n        Returns:\n            dict: The same dictionary with `\"coord\"` distorted in place, if applied.\n        \"\"\"\n        if random.random() &gt; self.apply_p:\n            return data_dict\n\n        if \"coord\" in data_dict.keys() and self.distortion_params is not None:\n            for granularity, magnitude in self.distortion_params:\n                data_dict[\"coord\"] = self.elastic_distortion(data_dict[\"coord\"], granularity, magnitude)\n        return data_dict\n</code></pre> <p>Elastic Distortion on PC</p> <p> </p>"},{"location":"coord/#augmentation_class.ElasticDistortion.__call__","title":"<code>__call__(data_dict)</code>","text":"<p>Apply elastic distortion(s) to <code>\"coord\"</code> in <code>data_dict</code>.</p> <p>Parameters:</p> Name Type Description Default <code>data_dict</code> <code>dict</code> <p>Input dictionary that must contain a <code>\"coord\"</code> key with a NumPy array of shape (N, 3) representing point coordinates.</p> required <p>Returns:</p> Name Type Description <code>dict</code> <code>dict</code> <p>The same dictionary with <code>\"coord\"</code> distorted in place, if applied.</p> Source code in <code>src\\augmentation_class.py</code> <pre><code>def __call__(self, data_dict: dict) -&gt; dict:\n    \"\"\"Apply elastic distortion(s) to `\"coord\"` in `data_dict`.\n\n    Args:\n        data_dict (dict): Input dictionary that must contain a `\"coord\"` key with a NumPy array of shape (N, 3)\n            representing point coordinates.\n\n    Returns:\n        dict: The same dictionary with `\"coord\"` distorted in place, if applied.\n    \"\"\"\n    if random.random() &gt; self.apply_p:\n        return data_dict\n\n    if \"coord\" in data_dict.keys() and self.distortion_params is not None:\n        for granularity, magnitude in self.distortion_params:\n            data_dict[\"coord\"] = self.elastic_distortion(data_dict[\"coord\"], granularity, magnitude)\n    return data_dict\n</code></pre>"},{"location":"noise/","title":"Noise","text":"<p>Classes for adding noise into point cloud</p>"},{"location":"noise/#addoutlier","title":"AddOutlier","text":"<p>Add synthetic outlier points (and attributes) around a point cloud.</p> <p>This transform expects a dictionary containing:</p> <ul> <li><code>\"coord\"</code>: NumPy array of shape (N, 3) with point coordinates.</li> <li>Optionally <code>\"norm\"</code>: per-point normals of shape (N, 3).</li> <li>Optionally <code>\"color\"</code>: per-point colors of shape (N, C).</li> <li>Optionally <code>\"noise_index\"</code>: 1D array of length N indicating noise labels (existing noise index).</li> </ul> <p>It augments the point cloud by sampling additional points in a spherical shell around the existing point cloud and appends them (and their attributes) to the existing arrays.</p> <p>The N number of outliers is:</p> <pre><code>N = int(max_ratio * n_pts)\n</code></pre> <p>where <code>n_pts</code> is the original number of points. If this is 0, the transform does nothing.</p> <p>Behavior of <code>fixed</code>:</p> <ul> <li>If <code>fixed=False</code>:</li> <li>Use all <code>N</code> generated outliers.</li> <li>If <code>fixed=True</code>:</li> <li> <p>Randomly choose a subset of the outliers with size:</p> <pre><code>N_used \u223c Uniform{ N // 2, ..., N }\n</code></pre> <p>and only append this subset.</p> </li> </ul> <p>Outliers are sampled inside a spherical shell defined from the centroid and bounding radius:</p> <ol> <li> <p>Compute the centroid:</p> <p>center = mean(coord, axis=0)</p> </li> <li> <p>Compute the maximum radius from the centroid:</p> <p>r_max = max(||coord[i] - center||)</p> </li> <li> <p>Define a spherical shell with inner radius:</p> <p>r_min = radius_min * r_max</p> </li> </ol> <p>and outer radius:</p> <pre><code>   r_max_shell = r_max\n</code></pre> <ol> <li>Sample directions uniformly on the sphere and radii uniformly in volume within <code>[r_min, r_max_shell]</code>,    then map back to world coordinates.</li> </ol> <p>For each outlier point, a random unit normal is generated (if <code>\"norm\"</code> exists), and random colors are generated (if <code>\"color\"</code> exists).</p> <p>The <code>\"noise_index\"</code> field is updated as follows:</p> <ul> <li>If <code>\"noise_index\"</code> does not exist:</li> <li>A new array of length <code>N + N_used</code> is created, filled with 0 for original points and 3   (indication of outlier type noise) for new outliers.</li> <li>If <code>\"noise_index\"</code> exists:</li> <li>It is extended to length <code>N + N_used</code>, keeping existing values and setting all new entries to 3.</li> </ul> <p>Parameters:</p> Name Type Description Default <code>max_ratio</code> <code>float</code> <p>Maximum ratio of outliers to original points. The N number of generated outliers is:</p> <pre><code>N = int(max_ratio * n_pts)\n</code></pre> <p>where n_pts is the original point count. Defaults to 0.2.</p> <code>0.2</code> <code>fixed</code> <code>bool</code> <p>Controls whether to subsample the generated outliers:</p> <ul> <li>False \u2192 use all generated outliers (<code>N</code>).</li> <li>True \u2192 randomly select a subset of size between <code>N // 2</code> and <code>N</code> (inclusive). Defaults to False.</li> </ul> <code>False</code> <code>radius_min</code> <code>float</code> <p>Fraction of the maximum radius used as the inner radius of the sampling shell. The shell is defined as <code>[radius_min * r_max, r_max]</code>. Defaults to 0.5.</p> <code>0.5</code> <code>range255</code> <code>bool</code> <p>Whether <code>\"color\"</code> values are in <code>[0, 255]</code>. If True, outlier colors are sampled as integers in <code>[0, 255]</code>. If False, they are sampled as floats in <code>[0, 1]</code>. Defaults to False.</p> <code>False</code> <code>apply_p</code> <code>float</code> <p>Probability of applying the adding outliers. Defaults to 1.0.</p> <code>1.0</code> Source code in <code>src\\augmentation_class.py</code> <pre><code>@TRANSFORMS.register()\nclass AddOutlier:\n    \"\"\"Add synthetic outlier points (and attributes) around a point cloud.\n\n    This transform expects a dictionary containing:\n\n    * `\"coord\"`: NumPy array of shape (N, 3) with point coordinates.\n    * Optionally `\"norm\"`: per-point normals of shape (N, 3).\n    * Optionally `\"color\"`: per-point colors of shape (N, C).\n    * Optionally `\"noise_index\"`: 1D array of length N indicating noise labels (existing noise index).\n\n    It augments the point cloud by sampling additional points in a spherical shell around the existing point cloud\n    and appends them (and their attributes) to the existing arrays.\n\n    The N number of outliers is:\n\n        N = int(max_ratio * n_pts)\n\n    where ``n_pts`` is the original number of points. If this is 0, the transform\n    does nothing.\n\n    Behavior of ``fixed``:\n\n    * If ``fixed=False``:\n      - Use **all** `N` generated outliers.\n    * If ``fixed=True``:\n      - Randomly choose a subset of the outliers with size:\n\n            N_used \u223c Uniform{ N // 2, ..., N }\n\n        and only append this subset.\n\n    Outliers are sampled inside a spherical shell defined from the centroid\n    and bounding radius:\n\n    1. Compute the centroid:\n\n           center = mean(coord, axis=0)\n\n    2. Compute the maximum radius from the centroid:\n\n           r_max = max(||coord[i] - center||)\n\n    3. Define a spherical shell with inner radius:\n\n           r_min = radius_min * r_max\n\n       and outer radius:\n\n           r_max_shell = r_max\n\n    4. Sample directions uniformly on the sphere and radii uniformly in **volume** within `[r_min, r_max_shell]`,\n       then map back to world coordinates.\n\n    For each outlier point, a random unit normal is generated (if `\"norm\"` exists), and random colors are generated\n    (if `\"color\"` exists).\n\n    The `\"noise_index\"` field is updated as follows:\n\n    * If `\"noise_index\"` does not exist:\n      - A new array of length `N + N_used` is created, filled with 0 for original points and 3\n      (indication of outlier type noise) for new outliers.\n    * If `\"noise_index\"` exists:\n      - It is extended to length `N + N_used`, keeping existing values and setting all new entries to 3.\n\n    Args:\n        max_ratio (float, optional):\n            Maximum ratio of outliers to original points. The N number of generated outliers is:\n\n                N = int(max_ratio * n_pts)\n\n            where n_pts is the original point count.\n            Defaults to 0.2.\n        fixed (bool, optional):\n            Controls whether to subsample the generated outliers:\n\n            * False \u2192 use all generated outliers (`N`).\n            * True \u2192 randomly select a subset of size between `N // 2` and `N` (inclusive).\n            Defaults to False.\n        radius_min (float, optional):\n            Fraction of the maximum radius used as the inner radius of the sampling shell. The shell is defined as\n            `[radius_min * r_max, r_max]`.\n            Defaults to 0.5.\n        range255 (bool, optional): Whether `\"color\"` values are in `[0, 255]`. If True, outlier colors are sampled as\n            integers in `[0, 255]`. If False, they are sampled as floats in `[0, 1]`.\n            Defaults to False.\n        apply_p (float, optional):\n            Probability of applying the adding outliers.\n            Defaults to 1.0.\n    \"\"\"\n    def __init__(self, max_ratio=0.2, fixed=False, radius_min=0.5, range255=False, apply_p=1.0):\n        self.max_ratio = max_ratio\n        self.fixed = fixed\n        self.radius_min = radius_min\n        self.range255 = range255\n        self.apply_p = apply_p\n\n\n    def __call__(self, data_dict: dict) -&gt; dict:\n        \"\"\"Add outlier points and update aligned per-point attributes.\n\n        Args:\n            data_dict (dict): Input dictionary containing `\"coord\"` and optionally `\"norm\"`, `\"color\"`, and `\"noise_index\"`.\n\n        Returns:\n            dict: The same dictionary with additional outlier points and updated attributes, if adding outliers is applied.\n        \"\"\"\n        if random.random() &gt; self.apply_p:\n            return data_dict\n\n        if \"coord\" not in data_dict.keys():\n            return data_dict\n\n        coord = data_dict[\"coord\"]\n        if \"noise_index\" in data_dict:\n            coord = coord[np.logical_not(data_dict[\"noise_index\"])]\n        n_pts = len(coord)\n\n        # how many outliers to add\n        N = int(self.max_ratio * n_pts)\n        if N &lt;= 0:\n            return data_dict\n\n        # --- define a bounding sphere from current coords ---\n        center = coord.mean(axis=0, keepdims=True)  # (1,3)\n        rel = coord - center  # (N,3)\n        r_max = np.linalg.norm(rel, axis=1).max() + 1e-6  # avoid zero\n\n        r_min = self.radius_min * r_max\n        r_max_shell = r_max  # you can change to &gt; r_max if you want truly outside\n        # --- sample directions uniformly on sphere ---\n        noise_dir = np.random.normal(size=(N, 3))  # Gaussian\n        noise_dir /= np.linalg.norm(noise_dir, axis=-1, keepdims=True)  # normalize\n        # --- sample radii uniformly in the volume shell [r_min, r_max_shell] ---\n        u = np.random.uniform(low=0.0, high=1.0, size=N)\n        # uniform in [r_min^3, r_max^3], then cube root \u2192 uniform in volume\n        r = (r_min ** 3 + u * (r_max_shell ** 3 - r_min ** 3)) ** (1.0 / 3.0)\n        noise = noise_dir * r[:, None]  # (N,3) in bounding shell\n        noise_coord = center + noise  # map back to world coords\n\n        # add normal\n        rand_dir = np.random.normal(size=noise_coord.shape)  # gaussian noise\n        # normalize to unit vectors\n        norm_len = np.linalg.norm(rand_dir, axis=-1, keepdims=True) + 1e-8\n        noise_normal = (rand_dir / norm_len).astype(np.float32)\n        # noise_normal = noise_dir              # or use direction as \"normal\"\n\n\n        if not self.fixed and N &gt; 1:\n            # choose subset size between N // 2 and N (inclusive)\n            k_min = max(1, N // 2)\n            k = np.random.randint(k_min, N + 1)\n            idx_sel = np.random.choice(N, size=k, replace=False)\n            noise_coord = noise_coord[idx_sel]\n            noise_normal = noise_normal[idx_sel]\n            N = k\n\n        # ----- add coords -----\n        data_dict[\"coord\"] = np.concatenate([data_dict[\"coord\"], noise_coord], axis=0)\n        # ----- add normals (if present) -----\n        if \"norm\" in data_dict:\n            data_dict[\"norm\"] = np.concatenate([data_dict[\"norm\"], noise_normal], axis=0)\n        # ----- add color for outliers (if present) -----\n        if \"color\" in data_dict:\n            orig_color = data_dict[\"color\"]\n            C = orig_color.shape[1]\n            dtype = orig_color.dtype\n            if self.range255:\n                noise_color = np.random.randint(0, 256, size=(N, C)).astype(dtype)\n            else:\n                noise_color = np.random.rand(N, C).astype(dtype)\n            data_dict[\"color\"] = np.concatenate([data_dict[\"color\"], noise_color], axis=0)\n\n        # ----- update noise_index -----\n        if \"noise_index\" not in data_dict:\n            noise_index = np.zeros(len(data_dict[\"coord\"]), dtype=int)\n            noise_index[-N:] = 3  # mark new outliers as 3\n            data_dict[\"noise_index\"] = noise_index\n        else:\n            old_len = len(data_dict[\"noise_index\"])\n            new_len = len(data_dict[\"coord\"])\n            tmp = np.ones(new_len, dtype=int) * 3\n            tmp[:old_len] = data_dict[\"noise_index\"]\n            data_dict[\"noise_index\"] = tmp\n\n        return data_dict\n</code></pre> <p>Adding Outlier Noise</p> <p> </p>"},{"location":"noise/#augmentation_class.AddOutlier.__call__","title":"<code>__call__(data_dict)</code>","text":"<p>Add outlier points and update aligned per-point attributes.</p> <p>Parameters:</p> Name Type Description Default <code>data_dict</code> <code>dict</code> <p>Input dictionary containing <code>\"coord\"</code> and optionally <code>\"norm\"</code>, <code>\"color\"</code>, and <code>\"noise_index\"</code>.</p> required <p>Returns:</p> Name Type Description <code>dict</code> <code>dict</code> <p>The same dictionary with additional outlier points and updated attributes, if adding outliers is applied.</p> Source code in <code>src\\augmentation_class.py</code> <pre><code>def __call__(self, data_dict: dict) -&gt; dict:\n    \"\"\"Add outlier points and update aligned per-point attributes.\n\n    Args:\n        data_dict (dict): Input dictionary containing `\"coord\"` and optionally `\"norm\"`, `\"color\"`, and `\"noise_index\"`.\n\n    Returns:\n        dict: The same dictionary with additional outlier points and updated attributes, if adding outliers is applied.\n    \"\"\"\n    if random.random() &gt; self.apply_p:\n        return data_dict\n\n    if \"coord\" not in data_dict.keys():\n        return data_dict\n\n    coord = data_dict[\"coord\"]\n    if \"noise_index\" in data_dict:\n        coord = coord[np.logical_not(data_dict[\"noise_index\"])]\n    n_pts = len(coord)\n\n    # how many outliers to add\n    N = int(self.max_ratio * n_pts)\n    if N &lt;= 0:\n        return data_dict\n\n    # --- define a bounding sphere from current coords ---\n    center = coord.mean(axis=0, keepdims=True)  # (1,3)\n    rel = coord - center  # (N,3)\n    r_max = np.linalg.norm(rel, axis=1).max() + 1e-6  # avoid zero\n\n    r_min = self.radius_min * r_max\n    r_max_shell = r_max  # you can change to &gt; r_max if you want truly outside\n    # --- sample directions uniformly on sphere ---\n    noise_dir = np.random.normal(size=(N, 3))  # Gaussian\n    noise_dir /= np.linalg.norm(noise_dir, axis=-1, keepdims=True)  # normalize\n    # --- sample radii uniformly in the volume shell [r_min, r_max_shell] ---\n    u = np.random.uniform(low=0.0, high=1.0, size=N)\n    # uniform in [r_min^3, r_max^3], then cube root \u2192 uniform in volume\n    r = (r_min ** 3 + u * (r_max_shell ** 3 - r_min ** 3)) ** (1.0 / 3.0)\n    noise = noise_dir * r[:, None]  # (N,3) in bounding shell\n    noise_coord = center + noise  # map back to world coords\n\n    # add normal\n    rand_dir = np.random.normal(size=noise_coord.shape)  # gaussian noise\n    # normalize to unit vectors\n    norm_len = np.linalg.norm(rand_dir, axis=-1, keepdims=True) + 1e-8\n    noise_normal = (rand_dir / norm_len).astype(np.float32)\n    # noise_normal = noise_dir              # or use direction as \"normal\"\n\n\n    if not self.fixed and N &gt; 1:\n        # choose subset size between N // 2 and N (inclusive)\n        k_min = max(1, N // 2)\n        k = np.random.randint(k_min, N + 1)\n        idx_sel = np.random.choice(N, size=k, replace=False)\n        noise_coord = noise_coord[idx_sel]\n        noise_normal = noise_normal[idx_sel]\n        N = k\n\n    # ----- add coords -----\n    data_dict[\"coord\"] = np.concatenate([data_dict[\"coord\"], noise_coord], axis=0)\n    # ----- add normals (if present) -----\n    if \"norm\" in data_dict:\n        data_dict[\"norm\"] = np.concatenate([data_dict[\"norm\"], noise_normal], axis=0)\n    # ----- add color for outliers (if present) -----\n    if \"color\" in data_dict:\n        orig_color = data_dict[\"color\"]\n        C = orig_color.shape[1]\n        dtype = orig_color.dtype\n        if self.range255:\n            noise_color = np.random.randint(0, 256, size=(N, C)).astype(dtype)\n        else:\n            noise_color = np.random.rand(N, C).astype(dtype)\n        data_dict[\"color\"] = np.concatenate([data_dict[\"color\"], noise_color], axis=0)\n\n    # ----- update noise_index -----\n    if \"noise_index\" not in data_dict:\n        noise_index = np.zeros(len(data_dict[\"coord\"]), dtype=int)\n        noise_index[-N:] = 3  # mark new outliers as 3\n        data_dict[\"noise_index\"] = noise_index\n    else:\n        old_len = len(data_dict[\"noise_index\"])\n        new_len = len(data_dict[\"coord\"])\n        tmp = np.ones(new_len, dtype=int) * 3\n        tmp[:old_len] = data_dict[\"noise_index\"]\n        data_dict[\"noise_index\"] = tmp\n\n    return data_dict\n</code></pre>"},{"location":"noise/#addbackgroundnoise","title":"AddBackgroundNoise","text":"<p>Add structured background noise patches around a point cloud.</p> <p>This transform expects a dictionary containing:</p> <ul> <li><code>\"coord\"</code>: NumPy array of shape (N, 3) with point coordinates.</li> <li>Optionally <code>\"norm\"</code>: per-point normals of shape (N, 3).</li> <li>Optionally <code>\"color\"</code>: per-point colors of shape (N, C).</li> <li>Optionally <code>\"noise_index\"</code>: 1D array of length N indicating noise labels (existing noise index).</li> </ul> <p>It generates several small 3D regions (up to <code>max_regions</code>), each containing up to <code>region_max_k</code> random points. These regions are anchored to the bounding box of the (non-noise) point cloud and then added as background clutter:</p> <pre><code>1. Compute the axis-aligned bounding box (AABB) from points with ``noise_index == 0`` (or all points if ``noise_index`` is absent).\n2. Sample up to ``max_regions`` random centers inside the box (with behavior controlled by ``mode``).\n3. For each region, sample points uniformly in a cube of side length ``region_size`` around the center.\n4. Snap one coordinate of each region to one face of the bounding box, so that noise patches lie on or around the box surface.\n5. Generate random unit normals for these noise points.\n6. Optionally subsample a random subset of regions/points when ``fixed=False``.\n7. Concatenate noise coordinates, normals, and colors (if present) to the existing arrays, and update ``noise_index`` to mark them asbackground noise (label 2).\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>max_regions</code> <code>int</code> <p>Maximum number of noise regions to generate. Each region is a local cube of sampled noise points. Defaults to 8.</p> <code>8</code> <code>region_max_k</code> <code>int</code> <p>Maximum number of points per region before optional subsampling. Total initial noise points are roughly <code>max_regions * region_max_k</code> before any reduction. Defaults to 128.</p> <code>128</code> <code>region_size</code> <code>float</code> <p>Side length of each cubic noise region. Points are sampled uniformly in a cube of side <code>region_size</code> centered at each region center. Defaults to 0.5.</p> <code>0.5</code> <code>fixed</code> <code>bool</code> <p>Controls randomness and subsampling of the generated noise: * If <code>False</code>:   - Randomly choose a number of regions between 1 and <code>max_regions</code>.   - Flatten all noise points from those regions.   - Randomly select a subset of points, with size between roughly 1/8 of all region points and the full set. * If <code>True</code>:   - Use all <code>max_regions * region_max_k</code> points (no region or point subsampling).</p> <p>Defaults to False.</p> <code>False</code> <code>range255</code> <code>bool</code> <p>Whether color values are in the range <code>[0, 255]</code>. If True, noise colors are sampled as integers in <code>[0, 255]</code>. If False, noise colors are sampled as floats in <code>[0, 1]</code>. Defaults to False.</p> <code>False</code> <code>mode</code> <code>{outside, inside}</code> <p>Controls how the region centers are chosen relative to the bounding box:</p> <ul> <li><code>\"inside\"</code>:</li> <li>Region centers are chosen so that the entire noise cube (of side <code>region_size</code>) lies strictly inside the bounding     box, as much as possible. This ensures all noise points stay on/within the box volume.</li> <li><code>\"outside\"</code>:</li> <li>Region centers are sampled anywhere inside the bounding box, and one coordinate of each region is snapped to a box face.     Some noise points may lie slightly outside the box, mimicking more realistic background clutter.</li> </ul> <p>Defaults to <code>\"outside\"</code>.</p> <code>'outside'</code> <code>apply_p</code> <code>float</code> <p>Probability of applying the background Defaults to 1.0.</p> <code>1.0</code> Source code in <code>src\\augmentation_class.py</code> <pre><code>@TRANSFORMS.register()\nclass AddBackgroundNoise:\n    \"\"\"Add structured background noise patches around a point cloud.\n\n    This transform expects a dictionary containing:\n\n    * `\"coord\"`: NumPy array of shape (N, 3) with point coordinates.\n    * Optionally `\"norm\"`: per-point normals of shape (N, 3).\n    * Optionally `\"color\"`: per-point colors of shape (N, C).\n    * Optionally `\"noise_index\"`: 1D array of length N indicating noise labels (existing noise index).\n\n    It generates several small 3D regions (up to ``max_regions``), each containing up to ``region_max_k`` random points.\n    These regions are anchored to the bounding box of the (non-noise) point cloud and then added as background clutter:\n\n        1. Compute the axis-aligned bounding box (AABB) from points with ``noise_index == 0`` (or all points if ``noise_index`` is absent).\n        2. Sample up to ``max_regions`` random centers inside the box (with behavior controlled by ``mode``).\n        3. For each region, sample points uniformly in a cube of side length ``region_size`` around the center.\n        4. Snap one coordinate of each region to one face of the bounding box, so that noise patches lie on or around the box surface.\n        5. Generate random unit normals for these noise points.\n        6. Optionally subsample a random subset of regions/points when ``fixed=False``.\n        7. Concatenate noise coordinates, normals, and colors (if present) to the existing arrays, and update ``noise_index`` to mark them asbackground noise (label 2).\n\n    Args:\n        max_regions (int, optional):\n            Maximum number of noise regions to generate. Each region is a local cube of sampled noise points.\n            Defaults to 8.\n        region_max_k (int, optional):\n            Maximum number of points per region before optional subsampling. Total initial noise points are\n            roughly ``max_regions * region_max_k`` before any reduction.\n            Defaults to 128.\n        region_size (float, optional):\n            Side length of each cubic noise region. Points are sampled uniformly in a cube of side ``region_size``\n            centered at each region center.\n            Defaults to 0.5.\n        fixed (bool, optional):\n            Controls randomness and subsampling of the generated noise:\n            * If ``False``:\n              - Randomly choose a number of regions between 1 and ``max_regions``.\n              - Flatten all noise points from those regions.\n              - Randomly select a subset of points, with size between roughly 1/8 of all region points and the full set.\n            * If ``True``:\n              - Use all ``max_regions * region_max_k`` points (no region or point subsampling).\n\n            Defaults to False.\n        range255 (bool, optional):\n            Whether color values are in the range ``[0, 255]``. If True, noise colors are sampled as integers in\n            ``[0, 255]``. If False, noise colors are sampled as floats in ``[0, 1]``.\n            Defaults to False.\n        mode ({\"outside\", \"inside\"}, optional): Controls how the region\n            centers are chosen relative to the bounding box:\n\n            * ``\"inside\"``:\n              - Region centers are chosen so that the entire noise cube (of side ``region_size``) lies strictly inside the bounding\n                box, as much as possible. This ensures all noise points stay on/within the box volume.\n            * ``\"outside\"``:\n              - Region centers are sampled anywhere inside the bounding box, and one coordinate of each region is snapped to a box face.\n                Some noise points may lie slightly outside the box, mimicking more realistic background clutter.\n\n            Defaults to ``\"outside\"``.\n        apply_p (float, optional):\n            Probability of applying the background\n            Defaults to 1.0.\n    \"\"\"\n    def __init__(self, max_regions: int =8, region_max_k: int =128, region_size: float=0.5, fixed:bool=False, range255: bool=False, mode: str=\"outside\", apply_p: float=1.0):\n        self.max_regions = max_regions\n        self.region_max_k = region_max_k\n        self.fixed = fixed\n        self.region_size = region_size\n        self.range255 = range255\n        self.apply_p = apply_p\n        assert mode in [\"outside\", \"inside\"]\n        # \"inside\" is to make sure all noise are on the bounding box, \"outside\" only guarantee the center is on the\n        # bounding box, some noise might be outside the box, \"inside\" is for nice for segmentation / denoising. But\n        # \"outside\" is more like real background clutter.\n        self.mode = mode\n\n    def __call__(self, data_dict: dict) -&gt; dict:\n        \"\"\"Add background noise regions and update aligned per-point attributes.\n\n        Args:\n            data_dict (dict): Input dictionary containing at least `\"coord\"`. May also contain `\"norm\"`, `\"color\"`, and `\"noise_index\"`.\n                Any existing `\"noise_index\" &gt; 0` points are excluded when computing the bounding box used to place new regions.\n\n        Returns:\n            dict: The same dictionary with added background noise points (coords, normals, colors if present) and an updated\n            `\"noise_index\"` marking these new points with label 2.\n        \"\"\"\n        if random.random() &gt; self.apply_p:\n            return data_dict\n\n        if \"coord\" not in data_dict.keys():\n            return data_dict\n\n        coord = data_dict[\"coord\"]\n        if \"noise_index\" in data_dict:\n            coord = coord[np.logical_not(data_dict[\"noise_index\"])]\n        max_value, min_value = np.max(coord, axis=0), np.min(coord, axis=0)\n        bounding_box = np.stack((min_value, max_value), axis=1)\n\n        half = self.region_size / 2.0\n        if self.mode == \"inside\":\n            span = max_value - min_value\n            inner_min = min_value + np.minimum(half, np.maximum(span / 2.0 - 1e-6, 0.0))\n            inner_max = max_value - np.minimum(half, np.maximum(span / 2.0 - 1e-6, 0.0))\n        else:\n            inner_min = min_value\n            inner_max = max_value\n\n        random_x = np.random.uniform(inner_min[0], inner_max[0], self.max_regions)  # [max_regions]\n        random_y = np.random.uniform(inner_min[1], inner_max[1], self.max_regions)  # [max_regions]\n        random_z = np.random.uniform(inner_min[2], inner_max[2], self.max_regions)  # [max_regions]\n        random_point_center = np.stack((random_x, random_y, random_z), axis=1)  # [max_regions, 3]\n\n        # [max_regions, region_max_k, 3]\n        noise = np.random.uniform(low=-half, high=half, size=(len(random_point_center), self.region_max_k, 3))\n        random_point = random_point_center[:, np.newaxis, :] + noise  # [max_regions, 1, 3] + [max_regions, region_max_k, 3]\n        # random_point_normal = np.zeros_like(random_point)  # [max_regions, region_max_k, 3]\n        # tmp_normal = np.stack((np.eye(3), np.eye(3) * -1), axis=1)  # [3, 2, 3]\n\n        random_face = np.random.choice(6, self.max_regions, replace=True)\n        for i, val in enumerate(random_face):\n            divide = val // 2\n            mod = val % 2\n            random_point[i, :, divide] = bounding_box[divide][mod]\n            # random_point_normal[i, :] = tmp_normal[divide][mod]\n\n        # ----- RANDOM NORMALS INSTEAD OF FACE NORMALS -----\n        # shape (R, K, 3)\n        rand_dir = np.random.normal(size=random_point.shape)  # gaussian noise\n        # normalize to unit vectors\n        norm_len = np.linalg.norm(rand_dir, axis=-1, keepdims=True) + 1e-8\n        random_point_normal = (rand_dir / norm_len).astype(np.float32)\n\n        if not self.fixed:\n            region_size = np.random.randint(1, self.max_regions + 1)\n            random_point = random_point[:region_size].reshape(-1, 3)\n            random_point_normal = random_point_normal[:region_size].reshape(-1, 3)\n            total_size = np.random.randint(max(1, len(random_point) // 8), len(random_point) + 1)\n\n            shuffle_idx = np.arange(len(random_point))\n            np.random.shuffle(shuffle_idx)\n            shuffle_idx = shuffle_idx[:total_size]\n            random_point = random_point[shuffle_idx]\n            random_point_normal = random_point_normal[shuffle_idx]\n        else:\n            random_point = random_point.reshape(-1, 3)\n            random_point_normal = random_point_normal.reshape(-1, 3)\n\n        # ----- ADD COLOR FOR NOISE -----\n        if \"color\" in data_dict:\n            orig_color = data_dict[\"color\"]\n            C = orig_color.shape[1]\n            dtype = orig_color.dtype\n            if self.range255:\n                noise_color = np.random.randint(0, 256, size=(random_point.shape[0], C)).astype(dtype)\n            else:\n                noise_color = np.random.rand(random_point.shape[0], C).astype(dtype)\n\n        # ----- CONCATENATE -----\n        data_dict[\"coord\"] = np.concatenate((data_dict[\"coord\"], random_point), axis=0)\n        if \"norm\" in data_dict:\n            data_dict[\"norm\"] = np.concatenate((data_dict[\"norm\"], random_point_normal), axis=0)\n\n        if \"color\" in data_dict:\n            data_dict[\"color\"] = np.concatenate((data_dict[\"color\"], noise_color), axis=0)\n\n        # ----- UPDATE noise_index -----\n        num_new = random_point.shape[0]\n        if \"noise_index\" not in data_dict:\n            noise_index = np.zeros(len(data_dict[\"coord\"]), dtype=int)\n            noise_index[-num_new:] = 2  # mark new as noise\n            data_dict[\"noise_index\"] = noise_index\n        else:\n            old_len = len(data_dict[\"noise_index\"])\n            new_len = len(data_dict[\"coord\"])\n            tmp = np.ones(new_len, dtype=int) * 2\n            tmp[:old_len] = data_dict[\"noise_index\"]\n            data_dict[\"noise_index\"] = tmp\n\n        return data_dict\n</code></pre> <p>Adding Background Noise</p> <p> </p>"},{"location":"noise/#augmentation_class.AddBackgroundNoise.__call__","title":"<code>__call__(data_dict)</code>","text":"<p>Add background noise regions and update aligned per-point attributes.</p> <p>Parameters:</p> Name Type Description Default <code>data_dict</code> <code>dict</code> <p>Input dictionary containing at least <code>\"coord\"</code>. May also contain <code>\"norm\"</code>, <code>\"color\"</code>, and <code>\"noise_index\"</code>. Any existing <code>\"noise_index\" &gt; 0</code> points are excluded when computing the bounding box used to place new regions.</p> required <p>Returns:</p> Name Type Description <code>dict</code> <code>dict</code> <p>The same dictionary with added background noise points (coords, normals, colors if present) and an updated</p> <code>dict</code> <p><code>\"noise_index\"</code> marking these new points with label 2.</p> Source code in <code>src\\augmentation_class.py</code> <pre><code>def __call__(self, data_dict: dict) -&gt; dict:\n    \"\"\"Add background noise regions and update aligned per-point attributes.\n\n    Args:\n        data_dict (dict): Input dictionary containing at least `\"coord\"`. May also contain `\"norm\"`, `\"color\"`, and `\"noise_index\"`.\n            Any existing `\"noise_index\" &gt; 0` points are excluded when computing the bounding box used to place new regions.\n\n    Returns:\n        dict: The same dictionary with added background noise points (coords, normals, colors if present) and an updated\n        `\"noise_index\"` marking these new points with label 2.\n    \"\"\"\n    if random.random() &gt; self.apply_p:\n        return data_dict\n\n    if \"coord\" not in data_dict.keys():\n        return data_dict\n\n    coord = data_dict[\"coord\"]\n    if \"noise_index\" in data_dict:\n        coord = coord[np.logical_not(data_dict[\"noise_index\"])]\n    max_value, min_value = np.max(coord, axis=0), np.min(coord, axis=0)\n    bounding_box = np.stack((min_value, max_value), axis=1)\n\n    half = self.region_size / 2.0\n    if self.mode == \"inside\":\n        span = max_value - min_value\n        inner_min = min_value + np.minimum(half, np.maximum(span / 2.0 - 1e-6, 0.0))\n        inner_max = max_value - np.minimum(half, np.maximum(span / 2.0 - 1e-6, 0.0))\n    else:\n        inner_min = min_value\n        inner_max = max_value\n\n    random_x = np.random.uniform(inner_min[0], inner_max[0], self.max_regions)  # [max_regions]\n    random_y = np.random.uniform(inner_min[1], inner_max[1], self.max_regions)  # [max_regions]\n    random_z = np.random.uniform(inner_min[2], inner_max[2], self.max_regions)  # [max_regions]\n    random_point_center = np.stack((random_x, random_y, random_z), axis=1)  # [max_regions, 3]\n\n    # [max_regions, region_max_k, 3]\n    noise = np.random.uniform(low=-half, high=half, size=(len(random_point_center), self.region_max_k, 3))\n    random_point = random_point_center[:, np.newaxis, :] + noise  # [max_regions, 1, 3] + [max_regions, region_max_k, 3]\n    # random_point_normal = np.zeros_like(random_point)  # [max_regions, region_max_k, 3]\n    # tmp_normal = np.stack((np.eye(3), np.eye(3) * -1), axis=1)  # [3, 2, 3]\n\n    random_face = np.random.choice(6, self.max_regions, replace=True)\n    for i, val in enumerate(random_face):\n        divide = val // 2\n        mod = val % 2\n        random_point[i, :, divide] = bounding_box[divide][mod]\n        # random_point_normal[i, :] = tmp_normal[divide][mod]\n\n    # ----- RANDOM NORMALS INSTEAD OF FACE NORMALS -----\n    # shape (R, K, 3)\n    rand_dir = np.random.normal(size=random_point.shape)  # gaussian noise\n    # normalize to unit vectors\n    norm_len = np.linalg.norm(rand_dir, axis=-1, keepdims=True) + 1e-8\n    random_point_normal = (rand_dir / norm_len).astype(np.float32)\n\n    if not self.fixed:\n        region_size = np.random.randint(1, self.max_regions + 1)\n        random_point = random_point[:region_size].reshape(-1, 3)\n        random_point_normal = random_point_normal[:region_size].reshape(-1, 3)\n        total_size = np.random.randint(max(1, len(random_point) // 8), len(random_point) + 1)\n\n        shuffle_idx = np.arange(len(random_point))\n        np.random.shuffle(shuffle_idx)\n        shuffle_idx = shuffle_idx[:total_size]\n        random_point = random_point[shuffle_idx]\n        random_point_normal = random_point_normal[shuffle_idx]\n    else:\n        random_point = random_point.reshape(-1, 3)\n        random_point_normal = random_point_normal.reshape(-1, 3)\n\n    # ----- ADD COLOR FOR NOISE -----\n    if \"color\" in data_dict:\n        orig_color = data_dict[\"color\"]\n        C = orig_color.shape[1]\n        dtype = orig_color.dtype\n        if self.range255:\n            noise_color = np.random.randint(0, 256, size=(random_point.shape[0], C)).astype(dtype)\n        else:\n            noise_color = np.random.rand(random_point.shape[0], C).astype(dtype)\n\n    # ----- CONCATENATE -----\n    data_dict[\"coord\"] = np.concatenate((data_dict[\"coord\"], random_point), axis=0)\n    if \"norm\" in data_dict:\n        data_dict[\"norm\"] = np.concatenate((data_dict[\"norm\"], random_point_normal), axis=0)\n\n    if \"color\" in data_dict:\n        data_dict[\"color\"] = np.concatenate((data_dict[\"color\"], noise_color), axis=0)\n\n    # ----- UPDATE noise_index -----\n    num_new = random_point.shape[0]\n    if \"noise_index\" not in data_dict:\n        noise_index = np.zeros(len(data_dict[\"coord\"]), dtype=int)\n        noise_index[-num_new:] = 2  # mark new as noise\n        data_dict[\"noise_index\"] = noise_index\n    else:\n        old_len = len(data_dict[\"noise_index\"])\n        new_len = len(data_dict[\"coord\"])\n        tmp = np.ones(new_len, dtype=int) * 2\n        tmp[:old_len] = data_dict[\"noise_index\"]\n        data_dict[\"noise_index\"] = tmp\n\n    return data_dict\n</code></pre>"},{"location":"noise/#addnoise","title":"AddNoise","text":"<p>Add local noise clusters around randomly chosen points.</p> <p>This transform expects a dictionary containing:</p> <ul> <li><code>\"coord\"</code>: NumPy array of shape (N, 3) with point coordinates.</li> <li>Optionally <code>\"norm\"</code>: per-point normals of shape (N, 3), required if   <code>method=\"custom\"</code>.</li> <li>Optionally <code>\"color\"</code>: per-point colors of shape (N, C).</li> <li>Optionally <code>\"noise_index\"</code>: 1D array of length N indicating existing noise labels.</li> </ul> <p>The transform works by:</p> <ol> <li> <p>Selecting a subset of points as noise centers.    The number of centers is:</p> <p>noise_center_count = int(N * noise_size_ratio)</p> </li> </ol> <p>(clamped to <code>[1, N]</code>). If this is 0, no noise is added. 2. For each center, generating up to <code>noise_max_k</code> noise points in its    local neighborhood (cluster), according to the chosen <code>method</code> and <code>boundary</code>. 3. Optionally subsampling the generated noise when <code>fixed=False</code>. 4. Mapping the local offsets to world coordinates and appending them (and their normals/colors) to the existing arrays. 5. Updating <code>noise_index</code> to mark the new points as local noise (value 1).</p> <p>Noise generation is controlled by two knobs:</p> <ul> <li><code>method</code>: defines how offsets are sampled:<ul> <li><code>\"uniform\"</code>:</li> <li>If <code>boundary=\"sphere\"</code>: sample directions uniformly and radii uniformly in volume within a ball of radius <code>ball_r</code>.</li> <li>If <code>boundary=\"cube\"</code>: sample coordinates uniformly in <code>[low, high]^3</code>.</li> <li><code>\"gaussian\"</code>:</li> <li>If <code>boundary=\"sphere\"</code>: Gaussian around the center, clamped to lie within a ball of radius <code>ball_r</code>.</li> <li>If <code>boundary=\"cube\"</code>: Gaussian in a cube, then clipped to the interval <code>[low, high]</code> per axis.</li> <li><code>\"custom\"</code>:</li> <li>Requires a <code>\"norm\"</code> field.</li> <li>For each center, uses its normal as a base direction and applies directional + radial jitter (using <code>ball_r</code> as scale) to create     offsets in a \u201ctube-like\u201d pattern around the surface.</li> </ul> </li> <li><code>boundary</code>: defines the shape of the local region:<ul> <li><code>\"sphere\"</code>: offsets lie in or near a ball of radius <code>ball_r</code>.</li> <li><code>\"cube\"</code>: offsets lie in or near a cube with side approximately <code>high - low</code> (for uniform/gaussian).</li> </ul> </li> </ul> <p>Colors for noise points are derived from the center colors:</p> <ul> <li>For <code>\"uniform\"</code> and <code>\"gaussian\"</code> methods:</li> <li>Noise points inherit exactly the color of their center.</li> <li>For <code>\"custom\"</code>:</li> <li>Optionally add Gaussian jitter in color space (scale depends on whether <code>range255</code> is True or False),   then clip to valid range.</li> </ul> <p>The number of final noise points is controlled by <code>fixed</code>:</p> <ul> <li>If <code>fixed=True</code>:</li> <li>Use all generated noise: <code>noise_center_count * noise_max_k</code> points.</li> <li>If <code>fixed=False</code>:</li> <li>Randomly shuffle all noise points and keep a random subset of size     between approximately one-eighth and the full generated count.</li> </ul> <p>Parameters:</p> Name Type Description Default <code>noise_size_ratio</code> <code>float</code> <p>Fraction of non-noise points to use as noise centers. The number of centers is:</p> <pre><code>noise_center_count = int(N * noise_size_ratio)\n</code></pre> <p>Defaults to 1./64.</p> <code>1.0 / 64</code> <code>noise_max_k</code> <code>int</code> <p>Maximum number of noise points generated per center before optional subsampling. Defaults to 16.</p> <code>16</code> <code>fixed</code> <code>bool</code> <p>Whether to keep all generated noise points or randomly subsample them:</p> <ul> <li>True  \u2192 keep all <code>noise_center_count * noise_max_k</code> noise points.</li> <li>False \u2192 shuffle and randomly keep a subset of those points.</li> </ul> <p>Defaults to True.</p> <code>True</code> <code>method</code> <code>{uniform, gaussian, custom}</code> <p>Noise sampling strategy. See above for details. <code>\"custom\"</code> requires <code>\"norm\"</code> in <code>data_dict</code>. Defaults to <code>\"uniform\"</code>.</p> <code>'uniform'</code> <code>boundary</code> <code>{sphere, cube}</code> <p>Shape of the local region in which noise is sampled. Interacts with <code>method</code> as described above. Defaults to <code>\"sphere\"</code>.</p> <code>'sphere'</code> <code>low</code> <code>float</code> <p>Lower bound for cube-based offsets (used for <code>boundary=\"cube\"</code> in <code>\"uniform\"</code> and <code>\"gaussian\"</code>). Defaults to -0.1.</p> <code>-0.1</code> <code>high</code> <code>float</code> <p>Upper bound for cube-based offsets. Defaults to 0.1.</p> <code>0.1</code> <code>ball_r</code> <code>float</code> <p>Radius of the spherical neighborhood for <code>boundary=\"sphere\"</code> methods; also used as a scale for radial jitter in the <code>\"custom\"</code> method. Defaults to 0.1.</p> <code>0.1</code> <code>range255</code> <code>bool</code> <p>Whether colors are stored in <code>[0, 255]</code> (integer-like). If True, color jitter in the <code>\"custom\"</code> method is done in that range. If False, colors are assumed in <code>[0, 1]</code>. Defaults to False.</p> <code>False</code> <code>apply_p</code> <code>float</code> <p>Probability of applying the noise Defaults to 1.0.</p> <code>1.0</code> Source code in <code>src\\augmentation_class.py</code> <pre><code>@TRANSFORMS.register()\nclass AddNoise:\n    \"\"\"Add local noise clusters around randomly chosen points.\n\n    This transform expects a dictionary containing:\n\n    * ``\"coord\"``: NumPy array of shape (N, 3) with point coordinates.\n    * Optionally ``\"norm\"``: per-point normals of shape (N, 3), required if\n      ``method=\"custom\"``.\n    * Optionally ``\"color\"``: per-point colors of shape (N, C).\n    * Optionally ``\"noise_index\"``: 1D array of length N indicating existing noise labels.\n\n    The transform works by:\n\n    1. Selecting a subset of points as **noise centers**.\n       The number of centers is:\n\n           noise_center_count = int(N * noise_size_ratio)\n\n       (clamped to ``[1, N]``). If this is 0, no noise is added.\n    2. For each center, generating up to ``noise_max_k`` noise points in its\n       local neighborhood (cluster), according to the chosen ``method`` and ``boundary``.\n    3. Optionally subsampling the generated noise when ``fixed=False``.\n    4. Mapping the local offsets to world coordinates and appending them (and their normals/colors) to the existing arrays.\n    5. Updating ``noise_index`` to mark the new points as local noise (value 1).\n\n    Noise generation is controlled by two knobs:\n\n    * ``method``: defines *how* offsets are sampled:\n        - ``\"uniform\"``:\n          * If ``boundary=\"sphere\"``: sample directions uniformly and radii uniformly in volume within a ball of radius ``ball_r``.\n          * If ``boundary=\"cube\"``: sample coordinates uniformly in ``[low, high]^3``.\n        - ``\"gaussian\"``:\n          * If ``boundary=\"sphere\"``: Gaussian around the center, clamped to lie within a ball of radius ``ball_r``.\n          * If ``boundary=\"cube\"``: Gaussian in a cube, then clipped to the interval ``[low, high]`` per axis.\n        - ``\"custom\"``:\n          * Requires a ``\"norm\"`` field.\n          * For each center, uses its normal as a base direction and applies directional + radial jitter (using ``ball_r`` as scale) to create\n            offsets in a \u201ctube-like\u201d pattern around the surface.\n    * ``boundary``: defines the *shape* of the local region:\n        - ``\"sphere\"``: offsets lie in or near a ball of radius ``ball_r``.\n        - ``\"cube\"``: offsets lie in or near a cube with side approximately ``high - low`` (for uniform/gaussian).\n\n    Colors for noise points are derived from the center colors:\n\n    * For ``\"uniform\"`` and ``\"gaussian\"`` methods:\n      - Noise points inherit exactly the color of their center.\n    * For ``\"custom\"``:\n      - Optionally add Gaussian jitter in color space (scale depends on whether ``range255`` is True or False),\n      then clip to valid range.\n\n    The number of **final** noise points is controlled by ``fixed``:\n\n    * If ``fixed=True``:\n      - Use all generated noise: ``noise_center_count * noise_max_k`` points.\n    * If ``fixed=False``:\n      - Randomly shuffle all noise points and keep a random subset of size\n        between approximately one-eighth and the full generated count.\n\n    Args:\n        noise_size_ratio (float, optional):\n            Fraction of non-noise points to use as noise centers. The number of centers is:\n\n                noise_center_count = int(N * noise_size_ratio)\n\n            Defaults to 1./64.\n        noise_max_k (int, optional):\n            Maximum number of noise points generated per center before optional subsampling.\n            Defaults to 16.\n        fixed (bool, optional):\n            Whether to keep all generated noise points or randomly subsample them:\n\n            * True  \u2192 keep all ``noise_center_count * noise_max_k`` noise points.\n            * False \u2192 shuffle and randomly keep a subset of those points.\n\n            Defaults to True.\n        method ({\"uniform\", \"gaussian\", \"custom\"}, optional):\n            Noise sampling strategy. See above for details. ``\"custom\"`` requires\n            ``\"norm\"`` in ``data_dict``.\n            Defaults to ``\"uniform\"``.\n        boundary ({\"sphere\", \"cube\"}, optional):\n            Shape of the local region in which noise is sampled. Interacts with ``method`` as described above.\n            Defaults to ``\"sphere\"``.\n        low (float, optional):\n            Lower bound for cube-based offsets (used for ``boundary=\"cube\"`` in ``\"uniform\"`` and ``\"gaussian\"``).\n            Defaults to -0.1.\n        high (float, optional):\n            Upper bound for cube-based offsets.\n            Defaults to 0.1.\n        ball_r (float, optional):\n            Radius of the spherical neighborhood for ``boundary=\"sphere\"`` methods; also used as a scale for radial\n            jitter in the ``\"custom\"`` method.\n            Defaults to 0.1.\n        range255 (bool, optional):\n            Whether colors are stored in ``[0, 255]`` (integer-like). If True, color jitter in the ``\"custom\"`` method\n            is done in that range. If False, colors are assumed in ``[0, 1]``.\n            Defaults to False.\n        apply_p (float, optional):\n            Probability of applying the noise\n            Defaults to 1.0.\n\n    \"\"\"\n    def __init__(self, noise_size_ratio:float=1./64, noise_max_k:int=16, fixed:bool=True, method:str=\"uniform\", boundary:str=\"sphere\",\n                 low:float=-0.1, high:float=0.1, ball_r:float=0.1, range255:bool=False, apply_p:float=1.0):\n        self.noise_size_ratio = noise_size_ratio\n        self.noise_max_k = noise_max_k\n        self.fixed = fixed\n        assert method in [\"uniform\", \"gaussian\", \"custom\"]\n        self.method = method\n        assert boundary in [\"sphere\", \"cube\"]\n        self.boundary = boundary\n        self.low, self.high = low, high\n        self.ball_r = ball_r\n        self.range255 = range255\n        self.apply_p = apply_p\n\n    def __call__(self, data_dict: dict) -&gt; dict:\n        \"\"\"Apply local noise cluster augmentation to a point cloud dictionary.\n\n        Args:\n            data_dict (dict): Input dictionary containing at least ``\"coord\"`` (NumPy array of shape (N, 3)).\n                May also contain ``\"norm\"``, ``\"color\"``, and ``\"noise_index\"``. For ``method=\"custom\"``, ``\"norm\"`` must be present.\n\n        Returns:\n            dict: The same dictionary with additional noise points appended to the relevant per-point fields and an updated ``\"noise_index\"`` marking newly added noise points with label 1.\n        \"\"\"\n        if random.random() &gt; self.apply_p:\n            return data_dict\n        if \"coord\" not in data_dict.keys():\n            return data_dict\n\n        coord = data_dict[\"coord\"]\n        if \"noise_index\" in data_dict:\n            coord = coord[np.logical_not(data_dict[\"noise_index\"])]\n        N = coord.shape[0]\n\n        # how many centers\n        noise_center_count = int(N * self.noise_size_ratio)\n        if noise_center_count &lt;= 0:\n            return data_dict\n        noise_center_count = min(noise_center_count, N)\n\n        # choose centers\n        center_idx = np.random.choice(N, noise_center_count, replace=False)\n        centers = coord[center_idx]  # (C, 3)\n        C = noise_center_count\n        K = self.noise_max_k\n\n        # ----------------- generate offsets (noise in local coords) -----------------\n        noise_offsets = None  # (C, K, 3)\n        noise_normals = None  # (C, K, 3) or None\n\n        # helper: random unit directions\n        def random_unit_vectors(shape):\n            v = np.random.normal(size=shape)\n            norm = np.linalg.norm(v, axis=-1, keepdims=True) + 1e-8\n            return v / norm\n\n        if self.method == \"uniform\":\n            if self.boundary == \"sphere\":\n                # uniform in ball of radius ball_r\n                dirs = random_unit_vectors((C, K, 3))\n                u = np.random.rand(C, K)\n                radii = (u ** (1.0 / 3.0)) * self.ball_r  # uniform in volume\n                noise_offsets = dirs * radii[..., None]\n                noise_normals = dirs  # can use direction as \"normal\"\n            elif self.boundary == \"cube\":\n                noise_offsets = np.random.uniform(low=self.low, high=self.high, size=(C, K, 3))\n                noise_normals = random_unit_vectors((C, K, 3))\n\n        elif self.method == \"gaussian\":\n            if self.boundary == \"sphere\":\n                # sample Gaussian around center\n                offsets = np.random.normal(loc=0.0, scale=self.ball_r / 3.0, size=(C, K, 3))\n                # radii of those offsets\n                radii = np.linalg.norm(offsets, axis=-1, keepdims=True) + 1e-8  # (C, K, 1)\n                # clamp radius to ball_r by scaling each vector\n                # scale = 1 if inside, ball_r / r if outside\n                scale = np.minimum(1.0, self.ball_r / radii)  # (C, K, 1), broadcasts over last dim\n                offsets = offsets * scale  # (C, K, 3)\n                noise_offsets = offsets\n                # recompute or reuse direction as normals\n                new_radii = np.linalg.norm(offsets, axis=-1, keepdims=True) + 1e-8\n                noise_normals = offsets / new_radii\n            elif self.boundary == \"cube\":\n                # Gaussian in a cube, then clipped to [low, high]\n                scale = (self.high - self.low) / 6.0  # ~99.7% in [low, high]\n                offsets = np.random.normal(loc=0.0, scale=scale, size=(C, K, 3))\n                offsets = np.clip(offsets, self.low, self.high)\n                noise_offsets = offsets\n                noise_normals = random_unit_vectors((C, K, 3))\n\n        elif self.method == \"custom\":\n            assert \"norm\" in data_dict, \"custom method requires 'norm' in data_dict.\"\n\n            noise_size = len(center_idx)  # N' centers\n            K = self.noise_max_k\n\n            # ---- center normals ----\n            normal_centers = np.asarray(data_dict[\"norm\"], dtype=np.float32)[center_idx]  # (N', 3)\n            # make sure they are unit vectors\n            normal_centers /= (np.linalg.norm(normal_centers, axis=-1, keepdims=True) + 1e-8)\n\n            # [N', K, 3] repeat normals per patch\n            repeat_normals = np.repeat(normal_centers[:, np.newaxis, :], K, axis=1)  # (N', K, 3)\n\n            # =====================================================\n            # 1) JITTER FOR NORMAL DIRECTION (directional jitter)\n            # =====================================================\n            # small Gaussian noise added to the normal, then renormalized\n            dir_sigma = 2  # strength of direction jitter (tune if needed)\n            dir_jitter = np.random.normal(\n                loc=0.0,\n                scale=dir_sigma,\n                size=(noise_size, K, 3)\n            )\n\n            perturbed_dir = repeat_normals + dir_jitter  # (N', K, 3)\n            dir_norm = np.linalg.norm(perturbed_dir, axis=-1, keepdims=True) + 1e-8\n            dir_unit = perturbed_dir / dir_norm  # (N', K, 3), unit direction per noise point\n\n            # =====================================================\n            # 2) JITTER FOR DISTANCE TO CENTER (radial jitter)\n            # =====================================================\n            # base radius in [0, ball_r], biased toward outer region (your original idea)\n            u = np.random.rand(noise_size, K)  # (N', K)\n            base_radius = (u ** (1.0 / 3.0)) * self.ball_r  # (N', K), &gt;= 0\n\n            # additive jitter around base_radius\n            dist_sigma = 1.  # in *absolute* units of ball_r (tune this)\n            jitter = np.random.normal(\n                loc=0.0,\n                scale=dist_sigma * self.ball_r,\n                size=(noise_size, K)\n            )  # (N', K)\n\n            r = base_radius + jitter  # (N', K)\n            r = np.clip(r, self.ball_r / 4.0, self.ball_r)  # keep in [0, ball_r]\n            r = r[:, :, None]  # (N', K, 1)\n\n            # =====================================================\n            # FINAL OFFSETS &amp; NORMALS (LOCAL COORDS)\n            # =====================================================\n            # offset from center = jittered direction * jittered distance\n            noise_offsets = dir_unit * r  # (N', K, 3)\n            noise_normals = dir_unit  # (N', K, 3)\n        else:\n            return data_dict\n\n        # ----------------- COLOR: center-based -----------------\n        noise_colors = None\n        if \"color\" in data_dict:\n            orig_color = np.asarray(data_dict[\"color\"])\n            center_colors = orig_color[center_idx]  # (C, Cc)\n            base_colors = np.repeat(center_colors[:, None, :], K, axis=1)  # (C, K, Cc)\n\n            if self.method in (\"uniform\", \"gaussian\"):\n                # exactly same color as center\n                noise_colors = base_colors.astype(orig_color.dtype)\n\n            elif self.method == \"custom\":\n                if self.range255:\n                    color_jitter = np.random.normal(loc=0.0, scale=10.0, size=base_colors.shape)\n                    noise_colors = base_colors + color_jitter\n                    noise_colors = np.clip(noise_colors, 0, 255).round().astype(orig_color.dtype)\n                else:\n                    color_jitter = np.random.normal(loc=0.0, scale=0.05, size=base_colors.shape)\n                    noise_colors = base_colors + color_jitter\n                    noise_colors = np.clip(noise_colors, 0.0, 1.0).astype(orig_color.dtype)\n\n        # ----------------- map to world coords -----------------\n        noise_points = noise_offsets + centers[:, None, :]  # (C, K, 3)\n\n        # flatten\n        noise_points = noise_points.reshape(-1, 3)\n        if noise_normals is not None:\n            noise_normals = noise_normals.reshape(-1, 3)\n        if noise_colors is not None:\n            noise_colors = noise_colors.reshape(-1, noise_colors.shape[-1])\n\n        # ----------------- optional subsampling -----------------\n        if not self.fixed:\n            idx = np.arange(len(noise_points))\n            np.random.shuffle(idx)\n            total = np.random.randint(max(1, len(noise_points) // 8), len(noise_points) + 1)\n            idx = idx[:total]\n\n            noise_points = noise_points[idx]\n            if noise_normals is not None:\n                noise_normals = noise_normals[idx]\n            if noise_colors is not None:\n                noise_colors = noise_colors[idx]\n\n        # ----------------- append to data_dict -----------------\n        data_dict[\"coord\"] = np.concatenate([data_dict[\"coord\"], noise_points], axis=0)\n\n        if \"norm\" in data_dict and noise_normals is not None:\n            data_dict[\"norm\"] = np.concatenate([data_dict[\"norm\"], noise_normals], axis=0)\n\n        if \"color\" in data_dict and noise_colors is not None:\n            data_dict[\"color\"] = np.concatenate([data_dict[\"color\"], noise_colors], axis=0)\n\n        # ----------------- noise_index -----------------\n        num_noise = noise_points.shape[0]\n        if \"noise_index\" not in data_dict:\n            ni = np.zeros(len(data_dict[\"coord\"]), dtype=int)\n            ni[-num_noise:] = 1\n            data_dict[\"noise_index\"] = ni\n        else:\n            old_len = len(data_dict[\"noise_index\"])\n            new_len = len(data_dict[\"coord\"])\n            ni = np.ones(new_len, dtype=int) * 1\n            ni[:old_len] = data_dict[\"noise_index\"]\n            data_dict[\"noise_index\"] = ni\n\n        return data_dict\n</code></pre> <p>Adding Noise</p> <p> </p>"},{"location":"noise/#augmentation_class.AddNoise.__call__","title":"<code>__call__(data_dict)</code>","text":"<p>Apply local noise cluster augmentation to a point cloud dictionary.</p> <p>Parameters:</p> Name Type Description Default <code>data_dict</code> <code>dict</code> <p>Input dictionary containing at least <code>\"coord\"</code> (NumPy array of shape (N, 3)). May also contain <code>\"norm\"</code>, <code>\"color\"</code>, and <code>\"noise_index\"</code>. For <code>method=\"custom\"</code>, <code>\"norm\"</code> must be present.</p> required <p>Returns:</p> Name Type Description <code>dict</code> <code>dict</code> <p>The same dictionary with additional noise points appended to the relevant per-point fields and an updated <code>\"noise_index\"</code> marking newly added noise points with label 1.</p> Source code in <code>src\\augmentation_class.py</code> <pre><code>def __call__(self, data_dict: dict) -&gt; dict:\n    \"\"\"Apply local noise cluster augmentation to a point cloud dictionary.\n\n    Args:\n        data_dict (dict): Input dictionary containing at least ``\"coord\"`` (NumPy array of shape (N, 3)).\n            May also contain ``\"norm\"``, ``\"color\"``, and ``\"noise_index\"``. For ``method=\"custom\"``, ``\"norm\"`` must be present.\n\n    Returns:\n        dict: The same dictionary with additional noise points appended to the relevant per-point fields and an updated ``\"noise_index\"`` marking newly added noise points with label 1.\n    \"\"\"\n    if random.random() &gt; self.apply_p:\n        return data_dict\n    if \"coord\" not in data_dict.keys():\n        return data_dict\n\n    coord = data_dict[\"coord\"]\n    if \"noise_index\" in data_dict:\n        coord = coord[np.logical_not(data_dict[\"noise_index\"])]\n    N = coord.shape[0]\n\n    # how many centers\n    noise_center_count = int(N * self.noise_size_ratio)\n    if noise_center_count &lt;= 0:\n        return data_dict\n    noise_center_count = min(noise_center_count, N)\n\n    # choose centers\n    center_idx = np.random.choice(N, noise_center_count, replace=False)\n    centers = coord[center_idx]  # (C, 3)\n    C = noise_center_count\n    K = self.noise_max_k\n\n    # ----------------- generate offsets (noise in local coords) -----------------\n    noise_offsets = None  # (C, K, 3)\n    noise_normals = None  # (C, K, 3) or None\n\n    # helper: random unit directions\n    def random_unit_vectors(shape):\n        v = np.random.normal(size=shape)\n        norm = np.linalg.norm(v, axis=-1, keepdims=True) + 1e-8\n        return v / norm\n\n    if self.method == \"uniform\":\n        if self.boundary == \"sphere\":\n            # uniform in ball of radius ball_r\n            dirs = random_unit_vectors((C, K, 3))\n            u = np.random.rand(C, K)\n            radii = (u ** (1.0 / 3.0)) * self.ball_r  # uniform in volume\n            noise_offsets = dirs * radii[..., None]\n            noise_normals = dirs  # can use direction as \"normal\"\n        elif self.boundary == \"cube\":\n            noise_offsets = np.random.uniform(low=self.low, high=self.high, size=(C, K, 3))\n            noise_normals = random_unit_vectors((C, K, 3))\n\n    elif self.method == \"gaussian\":\n        if self.boundary == \"sphere\":\n            # sample Gaussian around center\n            offsets = np.random.normal(loc=0.0, scale=self.ball_r / 3.0, size=(C, K, 3))\n            # radii of those offsets\n            radii = np.linalg.norm(offsets, axis=-1, keepdims=True) + 1e-8  # (C, K, 1)\n            # clamp radius to ball_r by scaling each vector\n            # scale = 1 if inside, ball_r / r if outside\n            scale = np.minimum(1.0, self.ball_r / radii)  # (C, K, 1), broadcasts over last dim\n            offsets = offsets * scale  # (C, K, 3)\n            noise_offsets = offsets\n            # recompute or reuse direction as normals\n            new_radii = np.linalg.norm(offsets, axis=-1, keepdims=True) + 1e-8\n            noise_normals = offsets / new_radii\n        elif self.boundary == \"cube\":\n            # Gaussian in a cube, then clipped to [low, high]\n            scale = (self.high - self.low) / 6.0  # ~99.7% in [low, high]\n            offsets = np.random.normal(loc=0.0, scale=scale, size=(C, K, 3))\n            offsets = np.clip(offsets, self.low, self.high)\n            noise_offsets = offsets\n            noise_normals = random_unit_vectors((C, K, 3))\n\n    elif self.method == \"custom\":\n        assert \"norm\" in data_dict, \"custom method requires 'norm' in data_dict.\"\n\n        noise_size = len(center_idx)  # N' centers\n        K = self.noise_max_k\n\n        # ---- center normals ----\n        normal_centers = np.asarray(data_dict[\"norm\"], dtype=np.float32)[center_idx]  # (N', 3)\n        # make sure they are unit vectors\n        normal_centers /= (np.linalg.norm(normal_centers, axis=-1, keepdims=True) + 1e-8)\n\n        # [N', K, 3] repeat normals per patch\n        repeat_normals = np.repeat(normal_centers[:, np.newaxis, :], K, axis=1)  # (N', K, 3)\n\n        # =====================================================\n        # 1) JITTER FOR NORMAL DIRECTION (directional jitter)\n        # =====================================================\n        # small Gaussian noise added to the normal, then renormalized\n        dir_sigma = 2  # strength of direction jitter (tune if needed)\n        dir_jitter = np.random.normal(\n            loc=0.0,\n            scale=dir_sigma,\n            size=(noise_size, K, 3)\n        )\n\n        perturbed_dir = repeat_normals + dir_jitter  # (N', K, 3)\n        dir_norm = np.linalg.norm(perturbed_dir, axis=-1, keepdims=True) + 1e-8\n        dir_unit = perturbed_dir / dir_norm  # (N', K, 3), unit direction per noise point\n\n        # =====================================================\n        # 2) JITTER FOR DISTANCE TO CENTER (radial jitter)\n        # =====================================================\n        # base radius in [0, ball_r], biased toward outer region (your original idea)\n        u = np.random.rand(noise_size, K)  # (N', K)\n        base_radius = (u ** (1.0 / 3.0)) * self.ball_r  # (N', K), &gt;= 0\n\n        # additive jitter around base_radius\n        dist_sigma = 1.  # in *absolute* units of ball_r (tune this)\n        jitter = np.random.normal(\n            loc=0.0,\n            scale=dist_sigma * self.ball_r,\n            size=(noise_size, K)\n        )  # (N', K)\n\n        r = base_radius + jitter  # (N', K)\n        r = np.clip(r, self.ball_r / 4.0, self.ball_r)  # keep in [0, ball_r]\n        r = r[:, :, None]  # (N', K, 1)\n\n        # =====================================================\n        # FINAL OFFSETS &amp; NORMALS (LOCAL COORDS)\n        # =====================================================\n        # offset from center = jittered direction * jittered distance\n        noise_offsets = dir_unit * r  # (N', K, 3)\n        noise_normals = dir_unit  # (N', K, 3)\n    else:\n        return data_dict\n\n    # ----------------- COLOR: center-based -----------------\n    noise_colors = None\n    if \"color\" in data_dict:\n        orig_color = np.asarray(data_dict[\"color\"])\n        center_colors = orig_color[center_idx]  # (C, Cc)\n        base_colors = np.repeat(center_colors[:, None, :], K, axis=1)  # (C, K, Cc)\n\n        if self.method in (\"uniform\", \"gaussian\"):\n            # exactly same color as center\n            noise_colors = base_colors.astype(orig_color.dtype)\n\n        elif self.method == \"custom\":\n            if self.range255:\n                color_jitter = np.random.normal(loc=0.0, scale=10.0, size=base_colors.shape)\n                noise_colors = base_colors + color_jitter\n                noise_colors = np.clip(noise_colors, 0, 255).round().astype(orig_color.dtype)\n            else:\n                color_jitter = np.random.normal(loc=0.0, scale=0.05, size=base_colors.shape)\n                noise_colors = base_colors + color_jitter\n                noise_colors = np.clip(noise_colors, 0.0, 1.0).astype(orig_color.dtype)\n\n    # ----------------- map to world coords -----------------\n    noise_points = noise_offsets + centers[:, None, :]  # (C, K, 3)\n\n    # flatten\n    noise_points = noise_points.reshape(-1, 3)\n    if noise_normals is not None:\n        noise_normals = noise_normals.reshape(-1, 3)\n    if noise_colors is not None:\n        noise_colors = noise_colors.reshape(-1, noise_colors.shape[-1])\n\n    # ----------------- optional subsampling -----------------\n    if not self.fixed:\n        idx = np.arange(len(noise_points))\n        np.random.shuffle(idx)\n        total = np.random.randint(max(1, len(noise_points) // 8), len(noise_points) + 1)\n        idx = idx[:total]\n\n        noise_points = noise_points[idx]\n        if noise_normals is not None:\n            noise_normals = noise_normals[idx]\n        if noise_colors is not None:\n            noise_colors = noise_colors[idx]\n\n    # ----------------- append to data_dict -----------------\n    data_dict[\"coord\"] = np.concatenate([data_dict[\"coord\"], noise_points], axis=0)\n\n    if \"norm\" in data_dict and noise_normals is not None:\n        data_dict[\"norm\"] = np.concatenate([data_dict[\"norm\"], noise_normals], axis=0)\n\n    if \"color\" in data_dict and noise_colors is not None:\n        data_dict[\"color\"] = np.concatenate([data_dict[\"color\"], noise_colors], axis=0)\n\n    # ----------------- noise_index -----------------\n    num_noise = noise_points.shape[0]\n    if \"noise_index\" not in data_dict:\n        ni = np.zeros(len(data_dict[\"coord\"]), dtype=int)\n        ni[-num_noise:] = 1\n        data_dict[\"noise_index\"] = ni\n    else:\n        old_len = len(data_dict[\"noise_index\"])\n        new_len = len(data_dict[\"coord\"])\n        ni = np.ones(new_len, dtype=int) * 1\n        ni[:old_len] = data_dict[\"noise_index\"]\n        data_dict[\"noise_index\"] = ni\n\n    return data_dict\n</code></pre>"},{"location":"norm/","title":"Normal","text":"<p>Classes for point normal</p>"},{"location":"norm/#normalizenormal","title":"NormalizeNormal","text":"<p>Normalize normal vectors to unit length for a point cloud.</p> <p>This transform expects a dictionary containing: * <code>\"coord\"</code>: NumPy array of shape (N, 3) with point coordinates.</p> Source code in <code>src\\augmentation_class.py</code> <pre><code>@TRANSFORMS.register()\nclass NormalizeNormal:\n    \"\"\"Normalize normal vectors to unit length for a point cloud.\n\n    This transform expects a dictionary containing:\n    * `\"coord\"`: NumPy array of shape (N, 3) with point coordinates.\n    \"\"\"\n    def __call__(self, data_dict: dict) -&gt; dict:\n        \"\"\"Normalizes normal vectors to unit length.\n        Args:\n            data_dict (dict): Input dictionary that must contain a \"norm\" key\n                        with a NumPy array of shape (N, 3) representing normal vectors.\n\n        Returns:\n            dict: The same dictionary with \"norm\" normalized to unit length.\n        \"\"\"\n        if \"norm\" in data_dict.keys():\n            # preprocess.normalize handles zero divisor\n            data_dict[\"norm\"] = preprocessing.normalize(data_dict[\"norm\"], norm='l2')\n\n        return data_dict\n</code></pre>"},{"location":"norm/#augmentation_class.NormalizeNormal.__call__","title":"<code>__call__(data_dict)</code>","text":"<p>Normalizes normal vectors to unit length. Args:     data_dict (dict): Input dictionary that must contain a \"norm\" key                 with a NumPy array of shape (N, 3) representing normal vectors.</p> <p>Returns:</p> Name Type Description <code>dict</code> <code>dict</code> <p>The same dictionary with \"norm\" normalized to unit length.</p> Source code in <code>src\\augmentation_class.py</code> <pre><code>def __call__(self, data_dict: dict) -&gt; dict:\n    \"\"\"Normalizes normal vectors to unit length.\n    Args:\n        data_dict (dict): Input dictionary that must contain a \"norm\" key\n                    with a NumPy array of shape (N, 3) representing normal vectors.\n\n    Returns:\n        dict: The same dictionary with \"norm\" normalized to unit length.\n    \"\"\"\n    if \"norm\" in data_dict.keys():\n        # preprocess.normalize handles zero divisor\n        data_dict[\"norm\"] = preprocessing.normalize(data_dict[\"norm\"], norm='l2')\n\n    return data_dict\n</code></pre>"},{"location":"sample/","title":"SamplingPC","text":"<p>Classes for point cloud sampling</p>"},{"location":"sample/#sampling","title":"Sampling","text":"<p>Subsample points (and aligned attributes) using random or FPS-based indices.</p> <p>This transform expects a dictionary containing:</p> <ul> <li><code>\"coord\"</code>: NumPy array of shape (N, 3) with point coordinates.</li> <li>Optionally other per-point arrays (e.g., <code>\"norm\"</code>, <code>\"color\"</code>, <code>\"label\"</code>) that have length N along the first dimension.</li> <li>For FPS-based methods (<code>\"random_fps\"</code> and <code>\"fps\"</code>), a key <code>\"fps_index\"</code> is also required, containing a 1D array of   precomputed farthest-point-sampling indices into <code>\"coord\"</code>.</li> </ul> <p>If the requested number of points <code>n_pts</code> is less than the current number of points <code>N</code>, it selects a subset of indices and applies the same index selection to all aligned per-point fields (except keys containing <code>\"origin\"</code>). If <code>n_pts &gt;= N</code>, no subsampling is applied.</p> <p>The sampling strategy is controlled by <code>method</code>:</p> <ul> <li><code>\"random\"</code>:</li> <li>Uniformly sample <code>n_pts</code> indices from <code>[0, N)</code> without replacement.</li> <li><code>\"random_fps\"</code>:</li> <li>Sample <code>n_pts</code> indices from <code>fps_index</code> without replacement, then map the index to get the final subset.   (it is for better augmentation instead of fixed fps index each time despite not guarantee perfect uniform coverage)</li> <li><code>\"fps\"</code>:</li> <li>Directly use the first <code>n_pts</code> entries from <code>data_dict[\"fps_index\"]</code>.</li> </ul> <p>Parameters:</p> Name Type Description Default <code>n_pts</code> <code>int</code> <p>Target number of points after sampling. If <code>n_pts &gt;= N</code>, no sampling is applied. Defaults to 1024.</p> <code>1024</code> <code>method</code> <code>str</code> <p>Sampling strategy. One of:</p> <ul> <li><code>\"random\"</code>: uniform random sampling.</li> <li><code>\"random_fps\"</code>: random subset of precomputed FPS indices.</li> <li><code>\"fps\"</code>: first <code>n_pts</code> precomputed FPS indices.</li> </ul> <p>Defaults to <code>\"fps\"</code>.</p> <code>'fps'</code> Source code in <code>src\\augmentation_class.py</code> <pre><code>@TRANSFORMS.register()\nclass Sampling:\n    \"\"\"Subsample points (and aligned attributes) using random or FPS-based indices.\n\n    This transform expects a dictionary containing:\n\n    * `\"coord\"`: NumPy array of shape (N, 3) with point coordinates.\n    * Optionally other per-point arrays (e.g., `\"norm\"`, `\"color\"`, `\"label\"`) that have length N along the first dimension.\n    * For FPS-based methods (`\"random_fps\"` and `\"fps\"`), a key `\"fps_index\"` is also required, containing a 1D array of\n      precomputed farthest-point-sampling indices into `\"coord\"`.\n\n    If the requested number of points `n_pts` is **less** than the current number of points `N`, it selects a subset of\n    indices and applies the same index selection to all aligned per-point fields (except keys containing `\"origin\"`).\n    If `n_pts &gt;= N`, no subsampling is applied.\n\n    The sampling strategy is controlled by `method`:\n\n    * `\"random\"`:\n      - Uniformly sample `n_pts` indices from `[0, N)` without replacement.\n    * `\"random_fps\"`:\n      - Sample `n_pts` indices from `fps_index` without replacement, then map the index to get the final subset.\n      (it is for better augmentation instead of fixed fps index each time despite not guarantee perfect uniform coverage)\n    * `\"fps\"`:\n      - Directly use the first `n_pts` entries from `data_dict[\"fps_index\"]`.\n\n    Args:\n        n_pts (int, optional):\n            Target number of points after sampling. If `n_pts &gt;= N`, no sampling is applied. Defaults to 1024.\n        method (str, optional):\n            Sampling strategy. One of:\n\n            * `\"random\"`: uniform random sampling.\n            * `\"random_fps\"`: random subset of precomputed FPS indices.\n            * `\"fps\"`: first `n_pts` precomputed FPS indices.\n\n            Defaults to `\"fps\"`.\n    \"\"\"\n    def __init__(self, n_pts=1024, method=\"fps\"):\n        self.n_pts = n_pts\n        self.method = method\n        assert method in [\"random\", \"random_fps\", \"fps\"]\n\n    def __call__(self, data_dict: dict) -&gt; dict:\n        \"\"\"Subsample points and aligned fields according to the chosen method.\n\n        Args:\n            data_dict (dict): Input dictionary that must contain a `\"coord\"` key with a NumPy array of shape (N, 3).\n                Any other entry whose value is a NumPy array or `Sequence` of length N and whose key does not contain\n                `\"origin\"` will be permuted with the same shuffle indices.\n\n        Returns:\n            dict: The same dictionary with `\"coord\"` and aligned per-point attributes subsampled to at most `n_pts` points, if applied.\n        \"\"\"\n        # print(data_dict.keys())\n        if \"coord\" in data_dict.keys():\n            N = len(data_dict[\"coord\"])\n            if self.n_pts &lt; N :\n                if self.method == \"random\":\n                    idx = np.random.choice(N, self.n_pts, replace=False)\n                elif self.method == \"random_fps\":\n                    assert self.n_pts &lt;= len(data_dict[\"fps_index\"])\n                    idx = np.random.choice(len(data_dict[\"fps_index\"]), self.n_pts, replace=False)\n                    idx = data_dict[\"fps_index\"][idx]\n                elif self.method == \"fps\":\n                    assert self.n_pts &lt;= len(data_dict[\"fps_index\"])\n                    idx = data_dict[\"fps_index\"][:self.n_pts]\n                else:\n                    raise NotImplementedError(f\"method {self.method} is not supported.\")\n\n                for key, val in data_dict.items():\n                    if isinstance(val, (np.ndarray, Sequence)) and len(val) == N and \"origin\" not in key:\n                        data_dict[key] = val[idx]\n\n        return data_dict\n</code></pre> <p>FPS PC with 4096 points</p> <p> </p>"},{"location":"sample/#augmentation_class.Sampling.__call__","title":"<code>__call__(data_dict)</code>","text":"<p>Subsample points and aligned fields according to the chosen method.</p> <p>Parameters:</p> Name Type Description Default <code>data_dict</code> <code>dict</code> <p>Input dictionary that must contain a <code>\"coord\"</code> key with a NumPy array of shape (N, 3). Any other entry whose value is a NumPy array or <code>Sequence</code> of length N and whose key does not contain <code>\"origin\"</code> will be permuted with the same shuffle indices.</p> required <p>Returns:</p> Name Type Description <code>dict</code> <code>dict</code> <p>The same dictionary with <code>\"coord\"</code> and aligned per-point attributes subsampled to at most <code>n_pts</code> points, if applied.</p> Source code in <code>src\\augmentation_class.py</code> <pre><code>def __call__(self, data_dict: dict) -&gt; dict:\n    \"\"\"Subsample points and aligned fields according to the chosen method.\n\n    Args:\n        data_dict (dict): Input dictionary that must contain a `\"coord\"` key with a NumPy array of shape (N, 3).\n            Any other entry whose value is a NumPy array or `Sequence` of length N and whose key does not contain\n            `\"origin\"` will be permuted with the same shuffle indices.\n\n    Returns:\n        dict: The same dictionary with `\"coord\"` and aligned per-point attributes subsampled to at most `n_pts` points, if applied.\n    \"\"\"\n    # print(data_dict.keys())\n    if \"coord\" in data_dict.keys():\n        N = len(data_dict[\"coord\"])\n        if self.n_pts &lt; N :\n            if self.method == \"random\":\n                idx = np.random.choice(N, self.n_pts, replace=False)\n            elif self.method == \"random_fps\":\n                assert self.n_pts &lt;= len(data_dict[\"fps_index\"])\n                idx = np.random.choice(len(data_dict[\"fps_index\"]), self.n_pts, replace=False)\n                idx = data_dict[\"fps_index\"][idx]\n            elif self.method == \"fps\":\n                assert self.n_pts &lt;= len(data_dict[\"fps_index\"])\n                idx = data_dict[\"fps_index\"][:self.n_pts]\n            else:\n                raise NotImplementedError(f\"method {self.method} is not supported.\")\n\n            for key, val in data_dict.items():\n                if isinstance(val, (np.ndarray, Sequence)) and len(val) == N and \"origin\" not in key:\n                    data_dict[key] = val[idx]\n\n    return data_dict\n</code></pre>"},{"location":"sample/#samplingdynamic","title":"SamplingDynamic","text":"<p>Dynamically choose the number of sampled points based on a scalar attribute.</p> <p>This transform expects a dictionary containing:</p> <ul> <li><code>\"coord\"</code>: NumPy array of shape (N, 3) with point coordinates.</li> <li>Optionally other per-point arrays (e.g., <code>\"norm\"</code>, <code>\"color\"</code>, <code>\"label\"</code>) that have length N along the first dimension.</li> <li><code>\"fps_index\"</code>: 1D NumPy array of precomputed farthest-point-sampling indices into <code>\"coord\"</code>.</li> <li>A scalar entry <code>key</code> (default <code>\"area\"</code>) used to determine how many points to sample.</li> </ul> <p>The number of target points is computed as:</p> <pre><code>pts = int(data_dict[key] * pts_ratio)\n</code></pre> <p>Then, from <code>\"fps_index\"</code> it selects:</p> <ul> <li>The first <code>pts</code> indices if <code>len(fps_index) &gt; pts</code>, or</li> <li>All of <code>fps_index</code> otherwise.</li> </ul> <p>All per-point arrays of length <code>N</code> (except those whose key contains <code>\"origin\"</code>) are then indexed with this subset.</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>str</code> <p>Name of the scalar field in <code>data_dict</code> used to determine the dynamic number of points. Common choices might include <code>\"area\"</code>, <code>\"volume\"</code>, etc. Defaults to <code>\"area\"</code>.</p> <code>'area'</code> <code>pts_ratio</code> <code>float</code> <p>Multiplicative factor that maps the scalar value <code>data_dict[key]</code> to a target number of points:</p> <pre><code>pts = int(data_dict[key] * pts_ratio)\n</code></pre> <p>For example, if <code>data_dict[\"area\"] = 1.8</code> and <code>pts_ratio</code> is <code>8192 / 1.8</code>, then <code>pts \u2248 8192</code>. Defaults to <code>8192 / 1.8</code>.</p> <code>8192 / 1.8</code> Source code in <code>src\\augmentation_class.py</code> <pre><code>@TRANSFORMS.register()\nclass SamplingDynamic:\n    \"\"\"Dynamically choose the number of sampled points based on a scalar attribute.\n\n    This transform expects a dictionary containing:\n\n    * `\"coord\"`: NumPy array of shape (N, 3) with point coordinates.\n    * Optionally other per-point arrays (e.g., `\"norm\"`, `\"color\"`, `\"label\"`) that have length N along the first dimension.\n    * `\"fps_index\"`: 1D NumPy array of precomputed farthest-point-sampling indices into `\"coord\"`.\n    * A scalar entry `key` (default `\"area\"`) used to determine how many points to sample.\n\n    The number of target points is computed as:\n\n        pts = int(data_dict[key] * pts_ratio)\n\n    Then, from `\"fps_index\"` it selects:\n\n    * The first `pts` indices if `len(fps_index) &gt; pts`, or\n    * All of `fps_index` otherwise.\n\n    All per-point arrays of length `N` (except those whose key contains `\"origin\"`) are then indexed with this subset.\n\n    Args:\n        key (str, optional):\n            Name of the scalar field in `data_dict` used to determine the dynamic number of points. Common choices might\n            include `\"area\"`, `\"volume\"`, etc.\n            Defaults to `\"area\"`.\n        pts_ratio (float, optional):\n            Multiplicative factor that maps the scalar value `data_dict[key]` to a target number of points:\n\n                pts = int(data_dict[key] * pts_ratio)\n\n            For example, if `data_dict[\"area\"] = 1.8` and `pts_ratio` is `8192 / 1.8`, then `pts \u2248 8192`.\n            Defaults to `8192 / 1.8`.\n    \"\"\"\n    def __init__(self, key=\"area\", pts_ratio=8192/1.8):\n        self.pts_ratio = pts_ratio\n        self.key = key\n\n    def __call__(self, data_dict: dict) -&gt; dict:\n        \"\"\"Apply dynamic FPS-based subsampling to `\"coord\"` and aligned fields.\n\n        Args:\n            data_dict (dict): Input dictionary containing at least `\"coord\"`, `self.key`, and `\"fps_index\"`.\n\n        Returns:\n            dict: The same dictionary with `\"coord\"` and aligned per-point attributes subsampled according to the\n            dynamically chosen number of points.\n        \"\"\"\n        if \"coord\" in data_dict.keys():\n            N = len(data_dict[\"coord\"])\n            assert self.key in data_dict\n            assert \"fps_index\" in data_dict\n\n            pts = int(data_dict[self.key] * self.pts_ratio)\n            if len(data_dict[\"fps_index\"]) &gt; pts:\n                idx = data_dict[\"fps_index\"][:pts]\n            else:\n                idx = data_dict[\"fps_index\"]\n\n            for key, val in data_dict.items():\n                if isinstance(val, (np.ndarray, Sequence)) and len(val) == N and \"origin\" not in key:\n                    data_dict[key] = val[idx]\n\n        return data_dict\n</code></pre> <p>FPS PC with surface area adjusted points</p> <p> </p>"},{"location":"sample/#augmentation_class.SamplingDynamic.__call__","title":"<code>__call__(data_dict)</code>","text":"<p>Apply dynamic FPS-based subsampling to <code>\"coord\"</code> and aligned fields.</p> <p>Parameters:</p> Name Type Description Default <code>data_dict</code> <code>dict</code> <p>Input dictionary containing at least <code>\"coord\"</code>, <code>self.key</code>, and <code>\"fps_index\"</code>.</p> required <p>Returns:</p> Name Type Description <code>dict</code> <code>dict</code> <p>The same dictionary with <code>\"coord\"</code> and aligned per-point attributes subsampled according to the</p> <code>dict</code> <p>dynamically chosen number of points.</p> Source code in <code>src\\augmentation_class.py</code> <pre><code>def __call__(self, data_dict: dict) -&gt; dict:\n    \"\"\"Apply dynamic FPS-based subsampling to `\"coord\"` and aligned fields.\n\n    Args:\n        data_dict (dict): Input dictionary containing at least `\"coord\"`, `self.key`, and `\"fps_index\"`.\n\n    Returns:\n        dict: The same dictionary with `\"coord\"` and aligned per-point attributes subsampled according to the\n        dynamically chosen number of points.\n    \"\"\"\n    if \"coord\" in data_dict.keys():\n        N = len(data_dict[\"coord\"])\n        assert self.key in data_dict\n        assert \"fps_index\" in data_dict\n\n        pts = int(data_dict[self.key] * self.pts_ratio)\n        if len(data_dict[\"fps_index\"]) &gt; pts:\n            idx = data_dict[\"fps_index\"][:pts]\n        else:\n            idx = data_dict[\"fps_index\"]\n\n        for key, val in data_dict.items():\n            if isinstance(val, (np.ndarray, Sequence)) and len(val) == N and \"origin\" not in key:\n                data_dict[key] = val[idx]\n\n    return data_dict\n</code></pre>"},{"location":"sample/#spherecrop","title":"SphereCrop","text":"<p>Crop a point cloud to a fixed number of points using a spherical region.</p> <p>This transform expects a dictionary containing:</p> <ul> <li><code>\"coord\"</code>: NumPy array of shape (N, 3) with point coordinates.</li> <li>Optionally other per-point arrays (e.g., <code>\"norm\"</code>, <code>\"color\"</code>, <code>\"label\"</code>) that have length N along the first dimension.</li> </ul> <p>The target number of points can be controlled either by an absolute cap (<code>point_max</code>) or a relative rate (<code>sample_rate</code>):</p> <ul> <li>If <code>sample_rate</code> is not <code>None</code>, the effective maximum is <code>point_max_eff = int(sample_rate * N)</code>.</li> <li>Otherwise, the fixed <code>point_max</code> value is used.</li> </ul> <p>The center of the crop is chosen according to <code>mode</code>:</p> <ul> <li><code>\"random\"</code>: use a randomly selected point as center.</li> <li><code>\"center\"</code>: use the point at index <code>N // 2</code> as center (e.g., middle in   the current ordering).</li> </ul> <p>If <code>N &lt;= point_max_eff</code>, no cropping is applied.</p> <p>Parameters:</p> Name Type Description Default <code>point_max</code> <code>int</code> <p>Maximum number of points to keep if<code>sample_rate</code> is <code>None</code>. Defaults to 80,000.</p> <code>80000</code> <code>sample_rate</code> <code>float | None</code> <p>If provided, the effective maximum number of points is computed as:</p> <pre><code>point_max_eff = int(sample_rate * N)\n</code></pre> <p>where <code>N</code> is the current number of points. This allows dataset-dependent cropping. If <code>None</code>, the fixed <code>point_max</code> is used instead. Defaults to <code>None</code>.</p> <code>None</code> <code>mode</code> <code>str</code> <p>Strategy to select the crop center. Must be <code>\"random\"</code> or <code>\"center\"</code>.</p> <ul> <li><code>\"random\"</code>: center is a random point from <code>\"coord\"</code>.</li> <li><code>\"center\"</code>: center is <code>coord[N // 2]</code>.</li> </ul> <p>Defaults to <code>\"random\"</code>.</p> <code>'random'</code> Source code in <code>src\\augmentation_class.py</code> <pre><code>@TRANSFORMS.register()\nclass SphereCrop:\n    \"\"\"Crop a point cloud to a fixed number of points using a spherical region.\n\n    This transform expects a dictionary containing:\n\n    * `\"coord\"`: NumPy array of shape (N, 3) with point coordinates.\n    * Optionally other per-point arrays (e.g., `\"norm\"`, `\"color\"`, `\"label\"`) that have length N along the first dimension.\n\n    The target number of points can be controlled either by an absolute cap (`point_max`) or a relative rate (`sample_rate`):\n\n    * If `sample_rate` is not ``None``, the effective maximum is `point_max_eff = int(sample_rate * N)`.\n    * Otherwise, the fixed `point_max` value is used.\n\n    The center of the crop is chosen according to `mode`:\n\n    * `\"random\"`: use a randomly selected point as center.\n    * `\"center\"`: use the point at index `N // 2` as center (e.g., middle in\n      the current ordering).\n\n    If `N &lt;= point_max_eff`, no cropping is applied.\n\n    Args:\n        point_max (int, optional):\n            Maximum number of points to keep if`sample_rate` is ``None``.\n            Defaults to 80,000.\n        sample_rate (float | None, optional):\n            If provided, the effective maximum number of points is computed as:\n\n                point_max_eff = int(sample_rate * N)\n\n            where `N` is the current number of points. This allows dataset-dependent cropping. If ``None``, the fixed `point_max`\n            is used instead.\n            Defaults to ``None``.\n        mode (str, optional):\n            Strategy to select the crop center. Must be `\"random\"` or `\"center\"`.\n\n            * `\"random\"`: center is a random point from `\"coord\"`.\n            * `\"center\"`: center is `coord[N // 2]`.\n\n            Defaults to `\"random\"`.\n    \"\"\"\n    def __init__(self, point_max: int = 80000, sample_rate: float = None, mode: str = \"random\"):\n        self.point_max = point_max\n        self.sample_rate = sample_rate\n        assert mode in [\"random\", \"center\"]\n        self.mode = mode\n\n    def __call__(self, data_dict: dict) -&gt; dict:\n        \"\"\"Apply spherical cropping to the `\"coord\"` entry in `data_dict`.\n\n        Args:\n            data_dict (dict): Input dictionary that must contain a `\"coord\"` key with a NumPy array of shape (N, 3).\n                Any other entry whose value is a NumPy array or `Sequence` of length N and whose key does not contain\n                `\"origin\"` will be permuted with the same shuffle indices.\n\n        Returns:\n            dict: The same dictionary with `\"coord\"` and aligned per-point attributes cropped to at most `point_max_eff`\n            points, if applied.\n        \"\"\"\n        if \"coord\" in data_dict.keys():\n            n = len(data_dict[\"coord\"])\n            if self.sample_rate is not None:\n                point_max = int(self.sample_rate * n)\n            else:\n                point_max = self.point_max\n\n            # mode is \"random\" or \"center\"\n            if n &gt; point_max:\n                if self.mode == \"random\":\n                    center = data_dict[\"coord\"][np.random.randint(n)]\n                elif self.mode == \"center\":\n                    center = data_dict[\"coord\"][n // 2]\n                else:\n                    raise NotImplementedError\n\n                idx = np.argsort(np.sum(np.square(data_dict[\"coord\"] - center), 1))[: point_max]\n                for key, value in data_dict.items():\n                    if isinstance(value, (np.ndarray, Sequence)) and len(value) == n and \"origin\" not in key:\n                        data_dict[key] = value[idx]\n\n        return data_dict\n</code></pre> <p>Sphere Crop PC</p> <p> </p>"},{"location":"sample/#augmentation_class.SphereCrop.__call__","title":"<code>__call__(data_dict)</code>","text":"<p>Apply spherical cropping to the <code>\"coord\"</code> entry in <code>data_dict</code>.</p> <p>Parameters:</p> Name Type Description Default <code>data_dict</code> <code>dict</code> <p>Input dictionary that must contain a <code>\"coord\"</code> key with a NumPy array of shape (N, 3). Any other entry whose value is a NumPy array or <code>Sequence</code> of length N and whose key does not contain <code>\"origin\"</code> will be permuted with the same shuffle indices.</p> required <p>Returns:</p> Name Type Description <code>dict</code> <code>dict</code> <p>The same dictionary with <code>\"coord\"</code> and aligned per-point attributes cropped to at most <code>point_max_eff</code></p> <code>dict</code> <p>points, if applied.</p> Source code in <code>src\\augmentation_class.py</code> <pre><code>def __call__(self, data_dict: dict) -&gt; dict:\n    \"\"\"Apply spherical cropping to the `\"coord\"` entry in `data_dict`.\n\n    Args:\n        data_dict (dict): Input dictionary that must contain a `\"coord\"` key with a NumPy array of shape (N, 3).\n            Any other entry whose value is a NumPy array or `Sequence` of length N and whose key does not contain\n            `\"origin\"` will be permuted with the same shuffle indices.\n\n    Returns:\n        dict: The same dictionary with `\"coord\"` and aligned per-point attributes cropped to at most `point_max_eff`\n        points, if applied.\n    \"\"\"\n    if \"coord\" in data_dict.keys():\n        n = len(data_dict[\"coord\"])\n        if self.sample_rate is not None:\n            point_max = int(self.sample_rate * n)\n        else:\n            point_max = self.point_max\n\n        # mode is \"random\" or \"center\"\n        if n &gt; point_max:\n            if self.mode == \"random\":\n                center = data_dict[\"coord\"][np.random.randint(n)]\n            elif self.mode == \"center\":\n                center = data_dict[\"coord\"][n // 2]\n            else:\n                raise NotImplementedError\n\n            idx = np.argsort(np.sum(np.square(data_dict[\"coord\"] - center), 1))[: point_max]\n            for key, value in data_dict.items():\n                if isinstance(value, (np.ndarray, Sequence)) and len(value) == n and \"origin\" not in key:\n                    data_dict[key] = value[idx]\n\n    return data_dict\n</code></pre>"},{"location":"sample/#gridsample","title":"GridSample","text":"<p>Grid-based voxelization and optional per-voxel sampling/pooling.</p> <p>This transform expects a dictionary containing:</p> <ul> <li><code>\"coord\"</code>: NumPy array of shape (N, 3) with point coordinates.</li> <li>Optionally per-point attributes (e.g. <code>\"norm\"</code>, <code>\"color\"</code>, <code>\"label\"</code>) that have length N along the first dimension.</li> </ul> <p>It first normalizes coordinates by subtracting the global minimum so that all coordinates are non-negative, then assigns each point to a 3D grid cell (voxel) either by:</p> <ul> <li>a fixed cell size (<code>grid_size</code>), or</li> <li>a fixed number of cells per axis (<code>grid_number</code>).</li> </ul> <p>The per-point integer voxel index is stored in <code>\"grid_coord\"</code>.</p> <p>Optionally, it can:</p> <ul> <li> <p>Store per-point relative coordinates within each voxel in <code>\"relative_coord\"</code>, normalized to approximately <code>[-1, 1]</code> per axis.</p> </li> <li> <p>Perform voxel-level sampling/aggregation:</p> </li> <li> <p><code>method=\"random\"</code>:</p> <ul> <li><code>mode=\"train\"</code>: pick one random point per voxel.</li> <li><code>mode=\"test\"</code>: generate up to <code>max_count</code> \u201cviews\u201d, each view containing one point per voxel (cycling through the points in each voxel). Returns a list of dictionaries.</li> </ul> </li> <li> <p><code>method=\"mean\"</code>:</p> <ul> <li>Average features per voxel and replace <code>\"coord\"</code>, <code>\"norm\"</code>, <code>\"color\"</code> accordingly.</li> <li>For <code>\"label\"</code>:</li> <li>If integer dtype \u2192 take majority vote per voxel.</li> <li>Else \u2192 average values per voxel.</li> </ul> </li> </ul> <p>Parameters:</p> Name Type Description Default <code>grid_size</code> <code>float</code> <p>Fixed grid cell size along each axis when <code>grid_number</code> is <code>None</code>. The same size is used for x, y, z. Coordinates are voxelized as:</p> <pre><code>grid_coord = floor((coord - coord_min) / grid_size)\n</code></pre> <p>Defaults to 0.02.</p> <code>0.02</code> <code>grid_number</code> <code>tuple[int] | None</code> <p>If not <code>None</code>, use a fixed number of cells per axis instead of a fixed size. In that case, the effective grid size is computed as:</p> <pre><code>grid_size = coord_norm.max(axis=0) / grid_number\n</code></pre> <p>and voxel indices are clipped to <code>[0, grid_number-1]</code>. Defaults to <code>None</code>.</p> <code>None</code> <code>sampling</code> <code>bool</code> <p>Whether to perform per-voxel sampling or pooling. If False, the transform only computes <code>\"grid_coord\"</code> (and <code>\"relative_coord\"</code> if <code>return_relative=True</code>) and does not change the number of points. Defaults to True.</p> <code>True</code> <code>method</code> <code>str</code> <p>Sampling/pooling strategy when <code>sampling=True</code>. Supported values:</p> <ul> <li><code>\"random\"</code>: per-voxel random selection.</li> <li><code>\"mean\"</code>: per-voxel averaging of features (and label fusion).</li> </ul> <p>Defaults to <code>\"random\"</code>.</p> <code>'random'</code> <code>return_relative</code> <code>bool</code> <p>If True, adds <code>\"relative_coord\"</code> to <code>data_dict</code>, containing per-point offsets relative to the voxel center, normalized to approximately <code>[-1, 1]</code> per axis. Defaults to False.</p> <code>False</code> <code>mode</code> <code>str</code> <p>Behavior mode for <code>method=\"random\"</code>. * <code>\"train\"</code>: returns a single dictionary, selecting one random point per voxel. * <code>\"test\"</code>: returns a list of dictionaries, each containing one point per voxel, cycling through all points within each voxel.</p> <p>Defaults to <code>\"train\"</code>.</p> <code>'train'</code> Source code in <code>src\\augmentation_class.py</code> <pre><code>@TRANSFORMS.register()\nclass GridSample:\n    \"\"\"Grid-based voxelization and optional per-voxel sampling/pooling.\n\n    This transform expects a dictionary containing:\n\n    * `\"coord\"`: NumPy array of shape (N, 3) with point coordinates.\n    * Optionally per-point attributes (e.g. `\"norm\"`, `\"color\"`, `\"label\"`) that have length N along the first dimension.\n\n    It first normalizes coordinates by subtracting the global minimum so that all coordinates are non-negative,\n    then assigns each point to a 3D grid cell (voxel) either by:\n\n    * a fixed cell size (`grid_size`), or\n    * a fixed number of cells per axis (`grid_number`).\n\n    The per-point integer voxel index is stored in `\"grid_coord\"`.\n\n    Optionally, it can:\n\n    * Store per-point relative coordinates within each voxel in `\"relative_coord\"`, normalized to approximately `[-1, 1]` per axis.\n\n    * Perform voxel-level sampling/aggregation:\n\n      - `method=\"random\"`:\n        * `mode=\"train\"`: pick one random point per voxel.\n        * `mode=\"test\"`: generate up to `max_count` \u201cviews\u201d, each view containing one point per voxel\n        (cycling through the points in each voxel). Returns a list of dictionaries.\n\n      - `method=\"mean\"`:\n        * Average features per voxel and replace `\"coord\"`, `\"norm\"`, `\"color\"` accordingly.\n        * For `\"label\"`:\n          - If integer dtype \u2192 take majority vote per voxel.\n          - Else \u2192 average values per voxel.\n\n    Args:\n        grid_size (float, optional):\n            Fixed grid cell size along each axis when `grid_number` is ``None``. The\n            same size is used for x, y, z. Coordinates are voxelized as:\n\n                grid_coord = floor((coord - coord_min) / grid_size)\n\n            Defaults to 0.02.\n        grid_number (tuple[int] | None, optional):\n            If not ``None``, use a fixed number of cells per axis instead of a fixed size. In that case, the effective\n            grid size is computed as:\n\n                grid_size = coord_norm.max(axis=0) / grid_number\n\n            and voxel indices are clipped to `[0, grid_number-1]`.\n            Defaults to ``None``.\n        sampling (bool, optional):\n            Whether to perform per-voxel sampling or pooling. If False, the transform only computes `\"grid_coord\"`\n            (and `\"relative_coord\"` if `return_relative=True`) and does not change the number of points.\n            Defaults to True.\n        method (str, optional):\n            Sampling/pooling strategy when `sampling=True`. Supported values:\n\n            * `\"random\"`: per-voxel random selection.\n            * `\"mean\"`: per-voxel averaging of features (and label fusion).\n\n            Defaults to `\"random\"`.\n        return_relative (bool, optional):\n            If True, adds `\"relative_coord\"` to `data_dict`, containing per-point offsets relative to the voxel center,\n            normalized to approximately `[-1, 1]` per axis.\n            Defaults to False.\n        mode (str, optional):\n            Behavior mode for `method=\"random\"`.\n            * `\"train\"`: returns a single dictionary, selecting one random point per voxel.\n            * `\"test\"`: returns a list of dictionaries, each containing one point per voxel, cycling through all points within each voxel.\n\n            Defaults to `\"train\"`.\n    \"\"\"\n\n    def __init__(self, grid_size: float = 0.02, grid_number: tuple[int] = None, sampling: bool = True,\n                 method: str = \"random\", return_relative: bool = False, mode: str = \"train\"):\n        self.grid_number = grid_number\n        self.grid_size = grid_size\n        self.sampling = sampling\n        assert method in [\"random\", \"mean\"]\n        self.method = method\n        self.return_relative = return_relative\n        assert mode in [\"train\", \"test\"]\n        self.mode = mode\n\n    @staticmethod\n    def _ravel_3d(arr_grid):\n        \"\"\"Convert 3D integer grid coordinates to a 1D key via row-major flattening.\n\n        Given integer grid coordinates of shape (N, 3), this computes a unique 1D key for each voxel coordinate\n        such that points in the same voxel share the same key. This is used for grouping points by voxel\n        (e.g. for random voxel-wise sampling).\n\n        Args:\n            arr_grid (np.ndarray): Integer grid coordinates of shape (N, 3).\n\n        Returns:\n            np.ndarray: 1D array of length N containing raveled voxel keys.\n        \"\"\"\n        assert arr_grid.ndim == 2 and arr_grid.shape[-1] == 3\n        max_grid = np.max(arr_grid, axis=0)\n        keys = arr_grid[:, 0] + arr_grid[:, 1] * (max_grid[0] + 1) + arr_grid[:, 2] * (max_grid[0] + 1) * (\n                max_grid[1] + 1)\n        return keys\n\n    def __call__(self, data_dict: dict) -&gt; dict | list:\n        \"\"\"Apply grid voxelization and optional voxel-wise sampling/pooling.\n\n\n        Args:\n            data_dict (dict): Input dictionary that must contain `\"coord\"`.\n                Optionally `\"norm\"`, `\"color\"`, `\"label\"`, etc.\n\n        Returns:\n            dict | list[dict]:\n                * If `sampling=False` or `method=\"mean\"` or `mode=\"train\"`:\n                  returns a single modified `data_dict`.\n                * If `method=\"random\"` and `mode=\"test\"`: returns a list of dictionaries, each representing a\n                  different per-voxel sampling pass.\n        \"\"\"\n        if \"coord\" in data_dict.keys():\n            coord = data_dict[\"coord\"]\n            coord_min = coord.min(axis=0)\n            coord_norm = coord - coord_min\n            # kill tiny negative noise due to FP\n            coord_norm = np.clip(coord_norm, 0.0, None)  # everything &lt; 0 \u2192 0.0\n\n            if self.grid_number is None:\n                # fixed grid cell size\n                grid_size = self.grid_size\n                grid_coord = np.floor(coord_norm / grid_size).astype(int)\n            else:\n                # fixed number of cells per axis\n                grid_number = np.array(self.grid_number, dtype=np.int32)\n                grid_size = coord_norm.max(axis=0) / grid_number\n                # avoid division by zero in degenerate dims\n                grid_size[grid_size == 0] = 1e-6\n\n                grid_coord = np.floor(coord_norm / grid_size).astype(np.int32)\n                # floor() would give integers in [0, grid_number-1] except when coord_norm == max, you get exactly grid_number.\n                grid_coord = np.clip(grid_coord, a_min=0, a_max=grid_number - 1)\n\n            data_dict[\"grid_coord\"] = grid_coord\n\n            if self.return_relative:\n                grid_center = (grid_coord + 0.5) * grid_size\n                # normalized to -1, 1 range\n                data_dict[\"relative_coord\"] = (coord_norm - grid_center) * (2.0 / grid_size)\n\n            if not self.sampling:\n                return data_dict\n\n            N = len(data_dict[\"coord\"])\n            if self.method == \"random\":\n                key = self._ravel_3d(grid_coord)\n                idx_sort = np.argsort(key)  # [min_key_index, ... max_key_index]\n                key_sort = key[idx_sort]\n                unique_keys, inverse, count = np.unique(key_sort, return_inverse=True, return_counts=True)\n\n                if self.mode != \"test\":\n                    # idx_select = np.cumsum(np.insert(count, 0, 0)[0:-1]) + np.random.randint(0, count.max(),\n                    #                                                                          count.size) % count\n\n                    # TRAIN: pick 1 random point per voxel\n                    offsets = np.cumsum(np.insert(count, 0, 0))[:-1]\n                    # one random offset in [0, count_i) per voxel\n                    rand_offsets = np.random.randint(0, count.max(), size=count.size) % count\n                    idx_select = offsets + rand_offsets  # indices into sorted list\n\n                    idx_unique = idx_sort[idx_select]\n                    for key, value in data_dict.items():\n                        if isinstance(value, (np.ndarray, Sequence)) and len(value) == N and \"origin\" not in key:\n                            data_dict[key] = value[idx_unique]\n                else:\n                    data_part_list = []\n                    max_count = int(count.max())\n                    offsets = np.cumsum(np.insert(count, 0, 0))[:-1]\n\n                    for i in range(max_count):\n                        idx_select = offsets + (i % count)\n                        idx_unique = idx_sort[idx_select]\n\n                        data_part = dict(origin_index=idx_unique)\n                        for key, value in data_dict.items():\n                            if isinstance(value, (np.ndarray, Sequence)) and len(value) == N and \"origin\" not in key:\n                                data_part[key] = value[idx_unique]\n                            else:\n                                data_part[key] = data_dict[key]\n                        data_part_list.append(data_part)\n                    return data_part_list\n\n\n            elif self.method == \"mean\":\n                unique_keys, inverse, count = np.unique(grid_coord, return_inverse=True, return_counts=True, axis=0)\n                unique_sizes = len(unique_keys)\n\n                # ----- combine features along feature dimension -----\n                feat_parts = []\n                feat_slices = {}   # record where each feature lives in combined vector\n                start = 0\n                for name in [\"coord\", \"norm\", \"color\"]:\n                    if name in data_dict:\n                        arr = np.array(data_dict[name])\n                        dim = arr.shape[1]\n                        feat_parts.append(arr)\n                        feat_slices[name] = slice(start, start + dim)\n                        start += dim\n                if feat_parts:\n                    combined_feat = np.concat(feat_parts, axis=1)\n\n                    sum_feat = np.zeros((unique_sizes, combined_feat.shape[1]), dtype=combined_feat.dtype)\n                    np.add.at(sum_feat, inverse, combined_feat)\n                    avg_feat = sum_feat / count[:, np.newaxis]\n\n\n                    data_dict[\"grid_coord\"] = unique_keys\n                    # ----- write back per feature -----\n                    for key in feat_slices.keys():\n                        data_dict[key] = avg_feat[:, feat_slices[key]]\n\n                if \"label\" in data_dict and len(data_dict[\"label\"]) == N:\n                    labels = np.array(data_dict[\"label\"])\n                    if np.issubdtype(labels.dtype, np.integer):\n                        # treat as classification\n                        num_classes_tmp = int(labels.max()) + 1\n                        hist = np.zeros((unique_sizes, num_classes_tmp), dtype=np.int32)\n                        np.add.at(hist, (inverse, labels), 1)   # (inverse, labels) is the 2D index for the hist\n                        data_dict[\"label\"] = hist.argmax(axis=1)\n                    else:\n                        # treat as regression\n                        if labels.ndim == 1:\n                            labels = labels[:, np.newaxis]\n                        sum_label = np.zeros((unique_sizes, labels.shape[1]), dtype=np.float32)\n                        np.add.at(sum_label, inverse, labels)\n                        avg_label = sum_label / count[:, None]\n                        if labels.ndim == 1:\n                            avg_label = avg_label[:, 0]\n                        data_dict[\"label\"] = avg_label\n\n        return data_dict\n</code></pre> <p>Grid Sample on PC</p> <p>Original PC vs Grid Sample (random select, fixed grid size)</p> <p> </p> <p>Grid Sample (random select, fixed grid numbers) vs Grid Sample (mean, fixed grid size)</p> <p> </p>"},{"location":"sample/#augmentation_class.GridSample.__call__","title":"<code>__call__(data_dict)</code>","text":"<p>Apply grid voxelization and optional voxel-wise sampling/pooling.</p> <p>Parameters:</p> Name Type Description Default <code>data_dict</code> <code>dict</code> <p>Input dictionary that must contain <code>\"coord\"</code>. Optionally <code>\"norm\"</code>, <code>\"color\"</code>, <code>\"label\"</code>, etc.</p> required <p>Returns:</p> Type Description <code>dict | list</code> <p>dict | list[dict]: * If <code>sampling=False</code> or <code>method=\"mean\"</code> or <code>mode=\"train\"</code>:   returns a single modified <code>data_dict</code>. * If <code>method=\"random\"</code> and <code>mode=\"test\"</code>: returns a list of dictionaries, each representing a   different per-voxel sampling pass.</p> Source code in <code>src\\augmentation_class.py</code> <pre><code>def __call__(self, data_dict: dict) -&gt; dict | list:\n    \"\"\"Apply grid voxelization and optional voxel-wise sampling/pooling.\n\n\n    Args:\n        data_dict (dict): Input dictionary that must contain `\"coord\"`.\n            Optionally `\"norm\"`, `\"color\"`, `\"label\"`, etc.\n\n    Returns:\n        dict | list[dict]:\n            * If `sampling=False` or `method=\"mean\"` or `mode=\"train\"`:\n              returns a single modified `data_dict`.\n            * If `method=\"random\"` and `mode=\"test\"`: returns a list of dictionaries, each representing a\n              different per-voxel sampling pass.\n    \"\"\"\n    if \"coord\" in data_dict.keys():\n        coord = data_dict[\"coord\"]\n        coord_min = coord.min(axis=0)\n        coord_norm = coord - coord_min\n        # kill tiny negative noise due to FP\n        coord_norm = np.clip(coord_norm, 0.0, None)  # everything &lt; 0 \u2192 0.0\n\n        if self.grid_number is None:\n            # fixed grid cell size\n            grid_size = self.grid_size\n            grid_coord = np.floor(coord_norm / grid_size).astype(int)\n        else:\n            # fixed number of cells per axis\n            grid_number = np.array(self.grid_number, dtype=np.int32)\n            grid_size = coord_norm.max(axis=0) / grid_number\n            # avoid division by zero in degenerate dims\n            grid_size[grid_size == 0] = 1e-6\n\n            grid_coord = np.floor(coord_norm / grid_size).astype(np.int32)\n            # floor() would give integers in [0, grid_number-1] except when coord_norm == max, you get exactly grid_number.\n            grid_coord = np.clip(grid_coord, a_min=0, a_max=grid_number - 1)\n\n        data_dict[\"grid_coord\"] = grid_coord\n\n        if self.return_relative:\n            grid_center = (grid_coord + 0.5) * grid_size\n            # normalized to -1, 1 range\n            data_dict[\"relative_coord\"] = (coord_norm - grid_center) * (2.0 / grid_size)\n\n        if not self.sampling:\n            return data_dict\n\n        N = len(data_dict[\"coord\"])\n        if self.method == \"random\":\n            key = self._ravel_3d(grid_coord)\n            idx_sort = np.argsort(key)  # [min_key_index, ... max_key_index]\n            key_sort = key[idx_sort]\n            unique_keys, inverse, count = np.unique(key_sort, return_inverse=True, return_counts=True)\n\n            if self.mode != \"test\":\n                # idx_select = np.cumsum(np.insert(count, 0, 0)[0:-1]) + np.random.randint(0, count.max(),\n                #                                                                          count.size) % count\n\n                # TRAIN: pick 1 random point per voxel\n                offsets = np.cumsum(np.insert(count, 0, 0))[:-1]\n                # one random offset in [0, count_i) per voxel\n                rand_offsets = np.random.randint(0, count.max(), size=count.size) % count\n                idx_select = offsets + rand_offsets  # indices into sorted list\n\n                idx_unique = idx_sort[idx_select]\n                for key, value in data_dict.items():\n                    if isinstance(value, (np.ndarray, Sequence)) and len(value) == N and \"origin\" not in key:\n                        data_dict[key] = value[idx_unique]\n            else:\n                data_part_list = []\n                max_count = int(count.max())\n                offsets = np.cumsum(np.insert(count, 0, 0))[:-1]\n\n                for i in range(max_count):\n                    idx_select = offsets + (i % count)\n                    idx_unique = idx_sort[idx_select]\n\n                    data_part = dict(origin_index=idx_unique)\n                    for key, value in data_dict.items():\n                        if isinstance(value, (np.ndarray, Sequence)) and len(value) == N and \"origin\" not in key:\n                            data_part[key] = value[idx_unique]\n                        else:\n                            data_part[key] = data_dict[key]\n                    data_part_list.append(data_part)\n                return data_part_list\n\n\n        elif self.method == \"mean\":\n            unique_keys, inverse, count = np.unique(grid_coord, return_inverse=True, return_counts=True, axis=0)\n            unique_sizes = len(unique_keys)\n\n            # ----- combine features along feature dimension -----\n            feat_parts = []\n            feat_slices = {}   # record where each feature lives in combined vector\n            start = 0\n            for name in [\"coord\", \"norm\", \"color\"]:\n                if name in data_dict:\n                    arr = np.array(data_dict[name])\n                    dim = arr.shape[1]\n                    feat_parts.append(arr)\n                    feat_slices[name] = slice(start, start + dim)\n                    start += dim\n            if feat_parts:\n                combined_feat = np.concat(feat_parts, axis=1)\n\n                sum_feat = np.zeros((unique_sizes, combined_feat.shape[1]), dtype=combined_feat.dtype)\n                np.add.at(sum_feat, inverse, combined_feat)\n                avg_feat = sum_feat / count[:, np.newaxis]\n\n\n                data_dict[\"grid_coord\"] = unique_keys\n                # ----- write back per feature -----\n                for key in feat_slices.keys():\n                    data_dict[key] = avg_feat[:, feat_slices[key]]\n\n            if \"label\" in data_dict and len(data_dict[\"label\"]) == N:\n                labels = np.array(data_dict[\"label\"])\n                if np.issubdtype(labels.dtype, np.integer):\n                    # treat as classification\n                    num_classes_tmp = int(labels.max()) + 1\n                    hist = np.zeros((unique_sizes, num_classes_tmp), dtype=np.int32)\n                    np.add.at(hist, (inverse, labels), 1)   # (inverse, labels) is the 2D index for the hist\n                    data_dict[\"label\"] = hist.argmax(axis=1)\n                else:\n                    # treat as regression\n                    if labels.ndim == 1:\n                        labels = labels[:, np.newaxis]\n                    sum_label = np.zeros((unique_sizes, labels.shape[1]), dtype=np.float32)\n                    np.add.at(sum_label, inverse, labels)\n                    avg_label = sum_label / count[:, None]\n                    if labels.ndim == 1:\n                        avg_label = avg_label[:, 0]\n                    data_dict[\"label\"] = avg_label\n\n    return data_dict\n</code></pre>"},{"location":"sample_mesh/","title":"SamplingMesh","text":"<p>Functions to sample point cloud from the mesh</p>"},{"location":"sample_mesh/#farthest_point_sample","title":"farthest_point_sample","text":"<p>Select points using Farthest Point Sampling (FPS).</p> <p>This function selects <code>npoint</code> indices from an input point cloud such that each newly selected point is as far as possible (in Euclidean distance) from the already selected set. Only the first three dimensions of <code>point</code> are used as XYZ coordinates.</p> <p>Parameters:</p> Name Type Description Default <code>point</code> <code>ndarray</code> <p>np.ndarray Point cloud array of shape (N, D). Only the first three columns are interpreted as XYZ coordinates, so D must be at least 3.</p> required <code>npoint</code> <code>int</code> <p>np.ndarray Number of points to sample. Must satisfy 1 &lt;= npoint &lt;= N.</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>np.ndarray: Array of shape (npoint,) containing the indices of the sampled points (dtype int32).</p> <p>Raises:</p> Type Description <code>AssertionError</code> <p>If <code>npoint</code> is greater than the number of input points N.</p> Source code in <code>src\\utils.py</code> <pre><code>def farthest_point_sample(point: np.ndarray, npoint: int) -&gt; np.ndarray:\n    \"\"\"Select points using Farthest Point Sampling (FPS).\n\n    This function selects `npoint` indices from an input point cloud such that\n    each newly selected point is as far as possible (in Euclidean distance)\n    from the already selected set. Only the first three dimensions of\n    `point` are used as XYZ coordinates.\n\n    Args:\n        point: np.ndarray\n            Point cloud array of shape (N, D). Only the first three columns\n            are interpreted as XYZ coordinates, so D must be at least 3.\n        npoint: np.ndarray\n            Number of points to sample. Must satisfy 1 &lt;= npoint &lt;= N.\n\n    Returns:\n        np.ndarray:\n            Array of shape (npoint,) containing the indices of the\n            sampled points (dtype int32).\n\n    Raises:\n        AssertionError: If `npoint` is greater than the number of input points N.\n    \"\"\"\n    N, D = point.shape\n    assert N &gt;= npoint\n    xyz = point[:, :3]\n    centroids = np.zeros((npoint,))\n    distance = np.ones((N,)) * 1e10\n    farthest = np.random.randint(0, N)\n\n    for i in range(npoint):\n        centroids[i] = farthest\n        centroid = xyz[farthest, :]\n        dist = np.sum((xyz - centroid) ** 2, -1)\n        mask = dist &lt; distance\n        distance[mask] = dist[mask]\n        farthest = np.argmax(distance, -1)\n\n    return centroids.astype(np.int32)\n</code></pre> <p>View source on GitHub</p>"},{"location":"sample_mesh/#area_and_normal","title":"area_and_normal","text":"<p>Compute per-face normals and areas for a triangular mesh.</p> <p>Given mesh vertices and triangular faces, this function computes the outward face normals (unit vectors) and the corresponding face areas. Faces with zero area (degenerate triangles) receive a zero normal.</p> <p>Parameters:</p> Name Type Description Default <code>vertices</code> <code>ndarray</code> <p>np.ndarray Array of shape (N, 3) containing vertex coordinates (XYZ).</p> required <code>faces</code> <code>ndarray</code> <p>np.ndarray Array of shape (M, 3) containing vertex indices for each triangular face. Each row is a triplet of integer indices into <code>vertices</code>.</p> required <p>Returns:</p> Type Description <code>tuple[ndarray, ndarray]</code> <p>tuple[np.ndarray, np.ndarray]: - face_normals: Array of shape (M, 3) with unit normal vectors   for each face. Degenerate faces have a zero vector. - face_areas: Array of shape (M,) with the area of each face.</p> Source code in <code>src\\utils.py</code> <pre><code>def area_and_normal(vertices: np.ndarray, faces: np.ndarray) -&gt; tuple[np.ndarray, np.ndarray]:\n    \"\"\"Compute per-face normals and areas for a triangular mesh.\n\n    Given mesh vertices and triangular faces, this function computes the\n    outward face normals (unit vectors) and the corresponding face areas.\n    Faces with zero area (degenerate triangles) receive a zero normal.\n\n    Args:\n        vertices: np.ndarray\n            Array of shape (N, 3) containing vertex coordinates (XYZ).\n        faces: np.ndarray\n            Array of shape (M, 3) containing vertex indices for each\n            triangular face. Each row is a triplet of integer indices into ``vertices``.\n\n    Returns:\n        tuple[np.ndarray, np.ndarray]:\n            - face_normals: Array of shape (M, 3) with unit normal vectors\n              for each face. Degenerate faces have a zero vector.\n            - face_areas: Array of shape (M,) with the area of each face.\n    \"\"\"\n    cross_product = np.cross(vertices[faces[:, 1]] - vertices[faces[:, 0]],\n                             vertices[faces[:, 2]] - vertices[faces[:, 1]])   # [M, 3]\n    cross_product_normal = np.sqrt(np.sum(cross_product ** 2, axis=1))        # [M, ]\n    cross_product_normal_broadcast = cross_product_normal[:, np.newaxis]      # [M, 1]\n    # if cross product normal is 0, the result is zero\n    face_normals = np.divide(cross_product, cross_product_normal_broadcast,\n                             out=np.zeros_like(cross_product), where=cross_product_normal_broadcast != 0)   # [M ,3]\n    face_areas = cross_product_normal * 0.5   # [M, ]\n    return face_normals, face_areas\n</code></pre>"},{"location":"sample_mesh/#sample_points_with_normal_features","title":"sample_points_with_normal_features","text":"<p>Sample points on a mesh surface with associated face normals.</p> <p>Points are sampled on the triangular mesh defined by <code>vertices</code> and <code>faces</code>. Triangles are chosen with probability proportional to their surface area, and points are sampled uniformly within each selected triangle using random barycentric coordinates. The function returns both the sampled 3D points and the corresponding per-point normals, taken from the face normals.</p> <p>Parameters:</p> Name Type Description Default <code>vertices</code> <code>ndarray</code> <p>Array of shape (V, 3) containing the mesh vertex coordinates (XYZ).</p> required <code>faces</code> <code>ndarray</code> <p>Array of shape (F, 3) containing vertex indices for each triangular face. Each row is a triplet of integer indices into <code>vertices</code>.</p> required <code>face_normals</code> <code>ndarray</code> <p>Array of shape (F, 3) with the normal vector for each face, typically unit-length.</p> required <code>face_areas</code> <code>ndarray</code> <p>Array of shape (F,) with the area of each face.</p> required <code>n_points</code> <code>int</code> <p>Number of points to sample on the mesh surface.</p> required <p>Returns:</p> Type Description <code>tuple[ndarray, ndarray]</code> <p>tuple[np.ndarray, np.ndarray]: - sampled_points: Array of shape (n_points, 3) with the sampled   XYZ coordinates on the mesh surface. - sampled_normals: Array of shape (n_points, 3) with the   corresponding normal vectors (one per sampled point), copied   from the selected face normals.</p> Source code in <code>src\\utils.py</code> <pre><code>def sample_points_with_normal_features(vertices: np.ndarray, faces: np.ndarray, face_normals: np.ndarray,\n                                       face_areas: np.ndarray, n_points: int) -&gt; tuple[np.ndarray, np.ndarray]:\n    \"\"\"Sample points on a mesh surface with associated face normals.\n\n        Points are sampled on the triangular mesh defined by ``vertices`` and\n        ``faces``. Triangles are chosen with probability proportional to their\n        surface area, and points are sampled uniformly within each selected\n        triangle using random barycentric coordinates. The function returns\n        both the sampled 3D points and the corresponding per-point normals,\n        taken from the face normals.\n\n        Args:\n            vertices: Array of shape (V, 3) containing the mesh vertex\n                coordinates (XYZ).\n            faces: Array of shape (F, 3) containing vertex indices for each\n                triangular face. Each row is a triplet of integer indices into\n                ``vertices``.\n            face_normals: Array of shape (F, 3) with the normal vector for\n                each face, typically unit-length.\n            face_areas: Array of shape (F,) with the area of each face.\n            n_points: Number of points to sample on the mesh surface.\n\n        Returns:\n            tuple[np.ndarray, np.ndarray]:\n                - sampled_points: Array of shape (n_points, 3) with the sampled\n                  XYZ coordinates on the mesh surface.\n                - sampled_normals: Array of shape (n_points, 3) with the\n                  corresponding normal vectors (one per sampled point), copied\n                  from the selected face normals.\n        \"\"\"\n    prob = face_areas / np.sum(face_areas)\n    index = np.random.choice(faces.shape[0], size=n_points, replace=True, p=prob)\n    sampled_faces = faces[index]\n    sampled_face_normals = face_normals[index]  # [n_points, 3]\n\n    sampled_points = []\n    for sampled_face in sampled_faces:\n        v1_idx, v2_idx, v3_idx = sampled_face\n        v1, v2, v3 = vertices[v1_idx], vertices[v2_idx], vertices[v3_idx]\n        s, t = sorted([random.random(), random.random()])\n        f_v = lambda i: s * v1[i] + (t - s) * v2[i] + (1 - t) * v3[i]\n\n        sampled_points.append([f_v(0), f_v(1), f_v(2)])\n    sampled_points = np.array(sampled_points)\n    return sampled_points, sampled_face_normals\n</code></pre>"},{"location":"sample_mesh/#process_file","title":"process_file","text":"Source code in <code>src\\create_pc.py</code> <pre><code>def process_file(file_path, saved_folder, degrees=None, n_pts=10000, scale=10.0):\n    file_id = \"tmp\"\n    saved_path = os.path.join(str(saved_folder), f\"{file_id}.pth\")\n    ms = simple_clean(file_path)\n    ms.apply_filter(\"compute_matrix_from_scaling_or_normalization\",\n                    uniformflag=True, axisx=1. / scale, axisy=1. / scale, axisz=1. / scale, scalecenter=\"origin\")\n    ms.apply_filter(\"apply_matrix_freeze\")\n\n    data = meshlab_to_open3d(ms)\n    data.orient_triangles()\n    data.remove_unreferenced_vertices()\n    # center and rotate\n    data = move_to_center(data, middle=True, in_place=True)\n    if degrees:\n        for d in degrees:\n            data = rotate_data_3d(data, degrees=d, in_place=True)\n    data = move_to_center(data, middle=True, in_place=True)\n\n    vertices = np.array(data.vertices)\n    faces = np.array(data.triangles)\n    data.compute_vertex_normals()\n    normals = np.array(data.vertex_normals)\n    data.compute_triangle_normals()\n    face_normals = np.array(data.triangle_normals)\n    surface_area = data.get_surface_area()\n    _, face_areas = area_and_normal(vertices, faces)\n\n\n    N = vertices.shape[0]\n    original_index = np.arange(N)\n    if N &lt; n_pts:\n        sampled_points, sampled_face_normals = sample_points_with_normal_features(vertices, faces, face_normals, face_areas, n_points=n_pts - N)\n        coord = np.concatenate((vertices, sampled_points), axis=0)\n        norm = np.concatenate((normals, sampled_face_normals), axis=0)\n\n    else:\n        coord = vertices\n        norm = normals\n    # fps\n    fps_index = farthest_point_sample(coord, n_pts)\n    norm = preprocessing.normalize(norm, norm='l2')\n    res = dict(coord=coord, norm=norm, fps_index=fps_index, original_index=original_index, area=surface_area)\n    torch.save(res, saved_path)\n</code></pre> <p>Extract PC from Mesh</p> <p> </p>"},{"location":"tensor/","title":"Tensor","text":"<p>Classes for transferring point cloud (NumPy) -&gt; PyTorch Tensor</p>"},{"location":"tensor/#totensor","title":"ToTensor","text":"<p>Recursively convert NumPy arrays, scalars, and container structures to PyTorch tensors.</p> <p>This transform is designed to work on:</p> <ul> <li>Individual values:</li> <li><code>torch.Tensor</code>: returned as-is.</li> <li><code>int</code> \u2192 <code>LongTensor([value])</code>.</li> <li><code>float</code> \u2192 <code>FloatTensor([value])</code>.</li> <li><code>str</code>: returned as-is (strings are not converted).</li> <li><code>np.ndarray</code> with:<ul> <li>boolean dtype \u2192 <code>torch.from_numpy(arr)</code> (bool tensor),</li> <li>integer dtype \u2192 <code>torch.from_numpy(arr).long()</code>,</li> <li>float dtype \u2192 <code>torch.from_numpy(arr).float()</code>.</li> </ul> </li> <li>Containers:</li> <li><code>Mapping</code> (e.g. <code>dict</code>): converts each value recursively, preserving keys.</li> <li><code>Sequence</code> (e.g. <code>list</code>, <code>tuple</code>): converts each element recursively and     returns a Python <code>list</code> of tensors/converted items.</li> </ul> <p>Any unsupported type will raise a <code>TypeError</code>.</p> <p>Typical usage is at the end of a preprocessing pipeline, to convert a nested sample dictionary (coords, features, labels) from NumPy to tensors.</p>"},{"location":"tensor/#augmentation_class.ToTensor.__call__","title":"<code>__call__(data)</code>","text":"<p>Convert input data (and nested contents) to PyTorch tensors. Args:     data: Arbitrary input to convert. Can be a scalar, NumPy array,         tensor, mapping (e.g. dict), or sequence (e.g. list/tuple).</p> <p>Returns:</p> Type Description <code>Any</code> <p>Converted object where all supported leaves are PyTorch tensors,</p> <code>Any</code> <p>and the original container structure (dict/list) is preserved.</p> <p>Raises:</p> Type Description <code>TypeError</code> <p>If <code>data</code> (or some nested leaf) has a type that cannot be converted to a tensor.</p>"},{"location":"tensor/#finalfeatures","title":"FinalFeatures","text":"<p>Assemble a final feature tensor and manage bookkeeping fields in a sample dict.</p> <p>This transform is typically used at the end of a preprocessing pipeline to:</p> <ol> <li>Build a unified feature array under the key <code>\"feat\"</code> by selecting and    concatenating one or more existing fields from <code>data_dict</code>.</li> <li>Optionally remove some intermediate fields (e.g., <code>\"norm\"</code>,    auxiliary features) to save memory.</li> <li>Optionally add offset fields (<code>\"offset\"</code>, <code>\"fps_offset\"</code>) that are    useful when batching variable-length point clouds.</li> </ol> <p>Behavior:</p> <ul> <li>Feature construction:</li> <li>If <code>feat</code> is a string, <code>data_dict[\"feat\"]</code> is set to <code>data_dict[feat]</code>.</li> <li>If <code>feat</code> is a list/tuple of strings, the corresponding arrays are concatenated along the last dimension:<pre><code>feat = np.concatenate([data_dict[name] for name in feat], axis=-1)\n</code></pre> </li> </ul> <p>All specified feature names must exist in <code>data_dict</code>.</p> <ul> <li>Field removal:</li> <li>If <code>remove</code> is a string, that key is deleted from <code>data_dict</code>.</li> <li>If <code>remove</code> is a list/tuple of strings, each corresponding key is deleted.</li> <li> <p>All specified keys must exist in <code>data_dict</code>.</p> </li> <li> <p>Offsets:</p> </li> <li> <p>If <code>add_offset</code> is True and <code>\"offset\"</code> is not already present, then:</p> <pre><code>data_dict[\"offset\"] = len(data_dict[\"coord\"])\n</code></pre> <p>This is often interpreted as the number of points in this sample.   - If <code>add_fps_offset</code> is True and <code>\"fps_offset\"</code> is not present but <code>\"fps_index\"</code> exists, then:</p> <pre><code>data_dict[\"fps_offset\"] = len(data_dict[\"fps_index\"])\n</code></pre> <p>This is typically the number of FPS (farthest-point sampling) indices for this sample.</p> </li> </ul> <p>Parameters:</p> Name Type Description Default <code>feat</code> <code>str or sequence of str</code> <p>Name(s) of fields in <code>data_dict</code> to be used as final features. If a sequence, the corresponding arrays are concatenated along the last dimension and stored in <code>data_dict[\"feat\"]</code>. If <code>None</code>, no feature tensor is constructed. Defaults to <code>\"coord\"</code>.</p> <code>'coord'</code> <code>remove</code> <code>str or sequence of str</code> <p>Name(s) of fields to delete from <code>data_dict</code> after (optional) feature construction. This is useful to drop intermediate fields (e.g., <code>\"norm\"</code>) that are no longer needed. If <code>None</code>, no keys are removed. Defaults to <code>\"norm\"</code>.</p> <code>'norm'</code> <code>add_offset</code> <code>bool</code> <p>If True and <code>\"offset\"</code> is not already present, add an integer offset equal to <code>len(data_dict[\"coord\"])</code>. Defaults to True.</p> <code>True</code> <code>add_fps_offset</code> <code>bool</code> <p>If True, <code>\"fps_offset\"</code> is not present, and <code>\"fps_index\"</code> exists, add an integer offset equal to <code>len(data_dict[\"fps_index\"])</code>. Defaults to True.</p> <code>True</code>"},{"location":"tensor/#augmentation_class.FinalFeatures.__call__","title":"<code>__call__(data_dict)</code>","text":"<p>Construct the final feature array and update bookkeeping fields.</p> <p>Parameters:</p> Name Type Description Default <code>data_dict</code> <code>dict</code> <p>Sample dictionary containing at least the keys referenced by <code>self.feat</code> (if not <code>None</code>), plus <code>\"coord\"</code> (used for <code>offset</code>) and optionally <code>\"fps_index\"</code> (used for <code>fps_offset</code>).</p> required <p>Returns:</p> Name Type Description <code>dict</code> <code>dict</code> <p>The same dictionary, with: * a new <code>\"feat\"</code> field (if requested), * selected keys removed, * and optional <code>\"offset\"</code> / <code>\"fps_offset\"</code> fields added.</p>"}]}